{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vcYjx3HFUcw"
   },
   "source": [
    "# LoFTR demo with custom image pairs on Colab\n",
    "We provide an easier way to run LoFTR with a custom image pair without configuring a python environment with GPU support. Signing in your Google account is required to run this notebook in Colab.\n",
    "\n",
    "Start by clicking Runtime --> Run all (Ctrl/Cmd + F9). \n",
    "\n",
    "Upload your own image pair with the \"Choose Files\" button to appear in the first cell. Please use horizontal images (width > height) and assign the image type (indoor/outdoor) accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "YuVtYs4xXkDG",
    "outputId": "39082292-d480-478d-913f-35c8e72e4c5a"
   },
   "outputs": [],
   "source": [
    "# print(\"Please wait for ~8 seconds for the GPU session initialization. \\n \\\n",
    "# ==> Please select both images at the same time after clicking \\\"Choose Files\\\".\")\n",
    "# !mkdir -p /content/uploaded/ && rm -rf /content/uploaded/* # clear previously uploaded images\n",
    "# %cd /content/uploaded/\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for file_name in uploaded.keys():\n",
    "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#       name=file_name, length=len(uploaded[file_name])))\n",
    "# image_pair = ['/content/uploaded/' + f for f in list(uploaded.keys())]\n",
    "# %cd ..\n",
    "\n",
    "# # Change the image type here.\n",
    "# image_type = 'indoor'\n",
    "# image_type = 'outdoor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTsrgTXxqDzI"
   },
   "source": [
    "You can also choose to use the example image pair provided in the LoFTR repo (from ScanNet) by using this cell (uncommenting the last line).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZNO-OvDilNW"
   },
   "outputs": [],
   "source": [
    "# img0_pth = \"uploaded/0aafg-missing.jpg\"\n",
    "# img1_pth = \"uploaded/0aafg.jpg\"\n",
    "# image_pair = [img0_pth, img1_pth]\n",
    "# image_pair = [img1_pth, img0_pth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWjHASahGCjv",
    "outputId": "0fd98ae0-c46e-4027-dad7-ef48c8a37124"
   },
   "outputs": [],
   "source": [
    "# # Configure environment and grab LoFTR code.\n",
    "# # !rm -rf sample_data\n",
    "# # !pip install einops yacs kornia\n",
    "# # !git clone https://github.com/zju3dv/LoFTR --depth 1\n",
    "# # !mv LoFTR/* . && rm -rf LoFTR\n",
    "\n",
    "# # Download pretrained weights\n",
    "# !mkdir weights \n",
    "# %cd weights/\n",
    "# !gdown --id 1w1Qhea3WLRMS81Vod_k5rxS_GNRgIi-O  # indoor-ds\n",
    "# !gdown --id 1M-VD35-qdB5Iw-AtbDBCKC7hPolFW9UY  # outdoor-ds\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD9G7vCzFUc1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "from src.utils.plotting import make_matching_figure\n",
    "from src.loftr import LoFTR, default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsZjszEwyWBp",
    "outputId": "cce86963-42f7-4654-f444-19f3ff620101"
   },
   "outputs": [],
   "source": [
    "# #!pip install -qq aicrowd-cli\n",
    "# %load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DptHF8PUyYJs",
    "outputId": "be22377a-ecae-427a-d27d-259a78f86d31"
   },
   "outputs": [],
   "source": [
    "# %aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "cc88d04c38e04e468900cc76f5dc61a3",
      "332c938c3b694a308a6618a57e2ba08c",
      "bda647b6ad1c4aaab751514f71ae93a7",
      "aa706f13cb0e4cfbbb82adb1ac113d81",
      "428932d8c1ed41328835c1ef629dbfbf",
      "c9abfebdbc734f1bbffbcf40a2ce3142",
      "77236b0a3dfc442cb348eb24bd20cee4",
      "4e943007137d416e9528d77377ca88a3",
      "47060ed6884e4628b7b08d6bbd002c26",
      "b5583f14a45244ea9683297daf971802",
      "323911fe1a9748f386e8eeff14b99166",
      "1ad7f3e19fc7476fa3050ccd3b9a287d",
      "3028e85e05d9422a830bb781b5eeb294",
      "7afb4f207e0b4494843aa5f44c98d330",
      "217125c934b84b6ab9f5db8e3b75f975",
      "34b7ac4aef4549118e1cc29ea8e56896",
      "dd7986c585244278b3fb8d36c1ad4e1c",
      "d60dc193f81f484c9f206eb2348cb323",
      "38665f1200f24eb08d5ca6181ffc44d5",
      "b4ad49cffa434307a163df6ad95d32a7",
      "b4ee042c08344fc5a29feac490cb1eaf",
      "0d6d576843a24621830feaaf95c3aac0"
     ]
    },
    "id": "SRRYgkTKybP_",
    "outputId": "62060b88-1d46-442b-be3e-e291d3d7ac7e"
   },
   "outputs": [],
   "source": [
    "# %aicrowd ds dl -c face-recognition -o data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG1C6Sj2yfzO"
   },
   "outputs": [],
   "source": [
    "# !unzip data/data.zip -d /content/data > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tW7se0XykG9",
    "outputId": "5875241b-6bd9-4eb3-d939-7b3243a22abe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_ids = os.listdir(\"data/missing\")\n",
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UwI1O6XymKW"
   },
   "outputs": [],
   "source": [
    "def get_target_face(face_no, target_image):\n",
    "  ''' This function helps to retrieve the individual faces from the main patch of 100 images'''\n",
    "\n",
    "  x, y = (int(face_no[0]))*216, (int(face_no[1]))*216\n",
    "\n",
    "  target_face = target_image[x:x+216, y:y+216]\n",
    "\n",
    "  return target_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_cfg['match_coarse']['match_type'] = 'sinkhorn'\n",
    "default_cfg['match_coarse']['thr'] = 0.05\n",
    "\n",
    "for k in default_cfg['match_coarse'].keys():\n",
    "    print(k)\n",
    "    print(k, default_cfg['match_coarse'][k])\n",
    "    \n",
    "default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMqIOuSzFUc2"
   },
   "outputs": [],
   "source": [
    "# The default config uses dual-softmax.\n",
    "# The outdoor and indoor models share the same config.\n",
    "# You can change the default values like thr and coarse_match_type.\n",
    "matcher = LoFTR(config=default_cfg)\n",
    "\n",
    "matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "matcher = matcher.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue import log_optimal_transport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lthr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1XJcQEMyn-t",
    "outputId": "26bbbf9f-d971-4296-c64c-80da39ed9b2e"
   },
   "outputs": [],
   "source": [
    "predictions = {\"ImageID\":[], \"target\":[]}\n",
    "\n",
    "all_results=[]\n",
    "all_inliers=[]\n",
    "\n",
    "for img_id in tqdm(image_ids):\n",
    "    missing_image = cv2.imread(os.path.join(\"data/missing\", img_id))[100:412,100:412,:]\n",
    "    missing_image = cv2.resize(missing_image, (640, 480))\n",
    "    missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGR2GRAY) #convert to gray scale\n",
    "    missing = torch.from_numpy(missing_image)[None][None].cuda() / 255.\n",
    "\n",
    "    target_image = cv2.imread(os.path.join(\"data/target\", img_id))\n",
    "\n",
    "    matches = []\n",
    "    inliers = []\n",
    "\n",
    "    for face_no in range(100):\n",
    "        face_no = str(face_no)\n",
    "        face_no = face_no.zfill(2)\n",
    "\n",
    "        target_face = get_target_face(face_no, target_image)\n",
    "        target_face = cv2.cvtColor(target_face, cv2.COLOR_BGR2GRAY)\n",
    "        target_face = cv2.resize(target_face,(640,480))\n",
    "\n",
    "        face = torch.from_numpy(target_face)[None][None].cuda() / 255.\n",
    "        batch = {'image0': missing, 'image1': face}\n",
    "\n",
    "        # Inference with LoFTR and get prediction\n",
    "        with torch.no_grad():\n",
    "            matcher(batch)\n",
    "            mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "            mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "            mconf = batch['mconf'].cpu().numpy()\n",
    "\n",
    "        src_pts = np.float32(mkpts0).reshape(-1,1,2)\n",
    "        dst_pts = np.float32(mkpts1).reshape(-1,1,2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        inliers_cnt = sum(matchesMask)\n",
    "        percent = inliers_cnt/len(matchesMask)\n",
    "        \n",
    "        matches.append(len(mkpts0))\n",
    "        inliers.append(percent)\n",
    "    all_results.append(matches)\n",
    "    all_inliers.append(inliers)\n",
    "    best_id = int(np.argmax(np.array(inliers)*np.array(matches)))\n",
    "    print(img_id,best_id)\n",
    "    predictions['ImageID'].append(img_id.replace(\".jpg\", \"\"))\n",
    "    predictions['target'].append(best_id)\n",
    "\n",
    "    # target_face = get_target_face('%02d'%best_id, target_image)\n",
    "    # target_face = cv2.cvtColor(target_face, cv2.COLOR_BGR2GRAY)\n",
    "    # target_face = cv2.resize(target_face,(640,480))\n",
    "\n",
    "    # face = torch.from_numpy(target_face)[None][None].cuda() / 255.\n",
    "    # batch = {'image0': missing, 'image1': face}\n",
    "\n",
    "    # # Inference with LoFTR and get prediction\n",
    "    # with torch.no_grad():\n",
    "    #     matcher(batch)\n",
    "    #     mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "    #     mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "    #     mconf = batch['mconf'].cpu().numpy()\n",
    "    # # Draw \n",
    "    # color = cm.jet(mconf, alpha=0.7)\n",
    "    # text = [\n",
    "    #     'LoFTR',\n",
    "    #     'Matches: {}'.format(len(mkpts0)),\n",
    "    # ]\n",
    "    # fig = make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text)\n",
    "\n",
    "    # # A high-res PDF will also be downloaded automatically.\n",
    "    # make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text, path=\"LoFTR-colab-demo.pdf\")\n",
    "    # # files.download(\"LoFTR-colab-demo.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(all_results[0],label='matches');\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.array(all_inliers[0]),label='percent inliers');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=1\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(all_results[ii],label='matches');\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.array(all_inliers[ii]),label='percent inliers');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = np.array(all_results)\n",
    "all_inliers = np.array(all_inliers)\n",
    "all_results.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results,all_inliers,all_results*all_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_results.transpose());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_inliers.transpose());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "srtd = np.sort(all_results, axis=1)\n",
    "plt.imshow(srtd[:,-10:])\n",
    "plt.title('matches')\n",
    "print(srtd[:,-1]-srtd[:,-2])\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "srtd = np.sort(all_inliers, axis=1)\n",
    "plt.imshow(srtd[:,-10:])\n",
    "print(srtd[:,-1]-srtd[:,-2])\n",
    "plt.title('inliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best3 = all_results.argsort(axis=1)[:,-2:]\n",
    "# best3 = all_inliers.argsort(axis=1)[:,-2:]\n",
    "best3 = (all_results*all_inliers).argsort(axis=1)[:,-2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id,b3,res in list(zip(image_ids,best3,all_results)):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(3,2,1)\n",
    "    plt.plot(res)\n",
    "    print(img_id,b3)\n",
    "    missing_image = cv2.imread(os.path.join(\"data/missing\", img_id))[100:412,100:412,:]\n",
    "    print(missing_image.shape)\n",
    "    missing_image = cv2.resize(missing_image, (640, 480))\n",
    "#     missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGR2GRAY) #convert to gray scale\n",
    "#     missing = torch.from_numpy(missing_image)[None][None].cuda() / 255.\n",
    "\n",
    "    target_image = cv2.imread(os.path.join(\"data/target\", img_id))\n",
    "    for iii, best_id in enumerate(b3):\n",
    "        target_face = get_target_face('%02d'%best_id, target_image)\n",
    "#         target_face = cv2.cvtColor(target_face, cv2.COLOR_BGR2GRAY)\n",
    "        target_face = cv2.resize(target_face,(640,480))\n",
    "\n",
    "#         face = torch.from_numpy(target_face)[None][None].cuda() / 255.\n",
    "#         batch = {'image0': missing, 'image1': face}\n",
    "\n",
    "#         # Inference with LoFTR and get prediction\n",
    "#         with torch.no_grad():\n",
    "#             matcher(batch)\n",
    "#             mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "#             mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "#             mconf = batch['mconf'].cpu().numpy()\n",
    "#         # Draw \n",
    "#         color = cm.jet(mconf, alpha=0.7)\n",
    "#         text = [\n",
    "#             'LoFTR',\n",
    "#             'Matches: {}'.format(len(mkpts0)),\n",
    "#         ]\n",
    "        plt.subplot(3,2,3+2*iii)\n",
    "        plt.imshow(missing_image[:,:,::-1])\n",
    "        plt.subplot(3,2,4+2*iii)\n",
    "        plt.imshow(target_face[:,:,::-1])\n",
    "#     fig = make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text)\n",
    "        \n",
    "        # A high-res PDF will also be downloaded automatically.\n",
    "#         make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text)#, path=\"LoFTR-colab-demo.pdf\")\n",
    "        # files.download(\"LoFTR-colab-demo.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_face = get_target_face('%02d'%best_id, target_image)\n",
    "target_face = cv2.cvtColor(target_face, cv2.COLOR_BGR2GRAY)\n",
    "target_face = cv2.resize(target_face,(640,480))\n",
    "\n",
    "face = torch.from_numpy(target_face)[None][None].cuda() / 255.\n",
    "batch = {'image0': missing, 'image1': face}\n",
    "\n",
    "# Inference with LoFTR and get prediction\n",
    "with torch.no_grad():\n",
    "    matcher(batch)\n",
    "    mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "    mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "    mconf = batch['mconf'].cpu().numpy()\n",
    "# Draw \n",
    "color = cm.jet(mconf, alpha=0.7)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text)\n",
    "\n",
    "# A high-res PDF will also be downloaded automatically.\n",
    "make_matching_figure(missing_image, target_face, mkpts0, mkpts1, color, mkpts0, mkpts1, text, path=\"LoFTR-colab-demo.pdf\")\n",
    "# files.download(\"LoFTR-colab-demo.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkpts0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_pts = np.float32(mkpts0).reshape(-1,1,2)\n",
    "dst_pts = np.float32(mkpts1).reshape(-1,1,2)\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "matchesMask = mask.ravel().tolist()\n",
    "inliers = sum(matchesMask)\n",
    "percent = inliers/len(matchesMask)\n",
    "h,w,_ = missing_image.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts,M)\n",
    "img2 = cv2.polylines(target_face.copy(),[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "plt.imshow(img1[:,:,::-1])\n",
    "plt.figure()\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(matchesMask),percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "MIN_MATCH_COUNT = 10\n",
    "img1 = missing_image.copy()\n",
    "img2 = target_face.copy()\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "#     if m.distance < 0.7*n.distance:\n",
    "    good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w,_ = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf assets\n",
    "!mkdir assets\n",
    "submission.to_csv(os.path.join(\"assets\", \"submission.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aicrowd notebook submit -c face-recognition -a assets --no-verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdJ-G1CiFUc3",
    "outputId": "f5f7ade5-8e99-415c-ec0d-2d16d39216f0"
   },
   "outputs": [],
   "source": [
    "# # Rerun this cell (and below) if a new image pair is uploaded.\n",
    "# img0_raw = cv2.imread(image_pair[0], cv2.IMREAD_GRAYSCALE)\n",
    "# img1_raw = cv2.imread(image_pair[1], cv2.IMREAD_GRAYSCALE)\n",
    "# img0_raw = cv2.resize(img0_raw, (640, 480))\n",
    "# img1_raw = cv2.resize(img1_raw, (640, 480))\n",
    "\n",
    "# img0 = torch.from_numpy(img0_raw)[None][None].cuda() / 255.\n",
    "# img1 = torch.from_numpy(img1_raw)[None][None].cuda() / 255.\n",
    "# batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "# # Inference with LoFTR and get prediction\n",
    "# with torch.no_grad():\n",
    "#     matcher(batch)\n",
    "#     mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "#     mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "#     mconf = batch['mconf'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "BSBHOV3GFUc3",
    "outputId": "1f5724f4-0b08-44f1-abd2-390a84be667d"
   },
   "outputs": [],
   "source": [
    "# # Draw \n",
    "# color = cm.jet(mconf, alpha=0.7)\n",
    "# text = [\n",
    "#     'LoFTR',\n",
    "#     'Matches: {}'.format(len(mkpts0)),\n",
    "# ]\n",
    "# fig = make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, mkpts0, mkpts1, text)\n",
    "\n",
    "# # A high-res PDF will also be downloaded automatically.\n",
    "# make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, mkpts0, mkpts1, text, path=\"LoFTR-colab-demo.pdf\")\n",
    "# files.download(\"LoFTR-colab-demo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CChK3ciimW4r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LoFTR_demo_single_pair.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d6d576843a24621830feaaf95c3aac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ad7f3e19fc7476fa3050ccd3b9a287d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7afb4f207e0b4494843aa5f44c98d330",
       "IPY_MODEL_217125c934b84b6ab9f5db8e3b75f975",
       "IPY_MODEL_34b7ac4aef4549118e1cc29ea8e56896"
      ],
      "layout": "IPY_MODEL_3028e85e05d9422a830bb781b5eeb294"
     }
    },
    "217125c934b84b6ab9f5db8e3b75f975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4ad49cffa434307a163df6ad95d32a7",
      "max": 9024,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38665f1200f24eb08d5ca6181ffc44d5",
      "value": 9024
     }
    },
    "3028e85e05d9422a830bb781b5eeb294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "323911fe1a9748f386e8eeff14b99166": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "332c938c3b694a308a6618a57e2ba08c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34b7ac4aef4549118e1cc29ea8e56896": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d6d576843a24621830feaaf95c3aac0",
      "placeholder": "​",
      "style": "IPY_MODEL_b4ee042c08344fc5a29feac490cb1eaf",
      "value": " 9.02k/9.02k [00:00&lt;00:00, 203kB/s]"
     }
    },
    "38665f1200f24eb08d5ca6181ffc44d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "428932d8c1ed41328835c1ef629dbfbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_323911fe1a9748f386e8eeff14b99166",
      "placeholder": "​",
      "style": "IPY_MODEL_b5583f14a45244ea9683297daf971802",
      "value": " 747M/747M [01:00&lt;00:00, 12.6MB/s]"
     }
    },
    "47060ed6884e4628b7b08d6bbd002c26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e943007137d416e9528d77377ca88a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77236b0a3dfc442cb348eb24bd20cee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afb4f207e0b4494843aa5f44c98d330": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d60dc193f81f484c9f206eb2348cb323",
      "placeholder": "​",
      "style": "IPY_MODEL_dd7986c585244278b3fb8d36c1ad4e1c",
      "value": "sample_submission.csv: 100%"
     }
    },
    "aa706f13cb0e4cfbbb82adb1ac113d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47060ed6884e4628b7b08d6bbd002c26",
      "max": 746543871,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e943007137d416e9528d77377ca88a3",
      "value": 746543871
     }
    },
    "b4ad49cffa434307a163df6ad95d32a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4ee042c08344fc5a29feac490cb1eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5583f14a45244ea9683297daf971802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bda647b6ad1c4aaab751514f71ae93a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77236b0a3dfc442cb348eb24bd20cee4",
      "placeholder": "​",
      "style": "IPY_MODEL_c9abfebdbc734f1bbffbcf40a2ce3142",
      "value": "data.zip: 100%"
     }
    },
    "c9abfebdbc734f1bbffbcf40a2ce3142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc88d04c38e04e468900cc76f5dc61a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bda647b6ad1c4aaab751514f71ae93a7",
       "IPY_MODEL_aa706f13cb0e4cfbbb82adb1ac113d81",
       "IPY_MODEL_428932d8c1ed41328835c1ef629dbfbf"
      ],
      "layout": "IPY_MODEL_332c938c3b694a308a6618a57e2ba08c"
     }
    },
    "d60dc193f81f484c9f206eb2348cb323": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd7986c585244278b3fb8d36c1ad4e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
