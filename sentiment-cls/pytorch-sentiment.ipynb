{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReMrWg8l3mRU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2476,
     "status": "ok",
     "timestamp": 1643711675304,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "9uR1JofUJQKi",
    "outputId": "f071c14b-646e-4bad-8690-d77cbeb62464"
   },
   "outputs": [],
   "source": [
    "# Readging the csv \n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "val = pd.read_csv(\"data/val.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmyPFxjwOe1c"
   },
   "outputs": [],
   "source": [
    "# Getting the feature and labels from each set. \n",
    "\n",
    "\n",
    "X = np.array([literal_eval(embedding)  for embedding in train['embeddings'].values])\n",
    "y = np.array(train['label'].values)\n",
    "\n",
    "X_val = np.array([literal_eval(embedding)  for embedding in val['embeddings'].values])\n",
    "y_val = np.array(val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, X_val.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X,axis=0)\n",
    "std = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.errorbar(range(512), mean, std, linestyle='None', marker='^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y=='positive']=2\n",
    "y[y=='negative']=0\n",
    "y[y=='neutral']=1\n",
    "\n",
    "y_val[y_val=='positive']=2\n",
    "y_val[y_val=='negative']=0\n",
    "y_val[y_val=='neutral']=1\n",
    "\n",
    "y=y.astype(np.int32)\n",
    "y_val=y_val.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_X(X):\n",
    "    return (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = torch.Tensor(normalize_X(X))\n",
    "ty = torch.Tensor(y).long()\n",
    "\n",
    "tx_val = torch.Tensor(normalize_X(X_val))\n",
    "ty_val = torch.Tensor(y_val).long()\n",
    "\n",
    "ds_train = TensorDataset(tx,ty)\n",
    "# train_loader = DataLoader(ds_train, batch_size=1000)\n",
    "\n",
    "ds_val = TensorDataset(tx_val,ty_val)\n",
    "# val_loader = DataLoader(ds_val, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(use_cuda,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "batch_size=5000\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#label_smoothing=0.1)\n",
    "\n",
    "class NetDDD3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD3, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "    \n",
    "class NetDDD2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD2, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "\n",
    "class NetDDD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.m1 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(256,3))\n",
    "        \n",
    "        self.m2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(256,3))\n",
    "        self.m3 = nn.Sequential(nn.Linear(512, 3))\n",
    "\n",
    "        \n",
    "        self.m4 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(256,3))\n",
    "        \n",
    "        self.m5 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.8),\n",
    "                                   nn.Linear(256,3))\n",
    "\n",
    "        self.fc = nn.Linear(3*5,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.cat((self.m1(x),self.m2(x),self.m3(x),self.m4(x),self.m5(x)),1)\n",
    "        return self.fc(nn.Dropout(0.3)(nn.ReLU()(a)))\n",
    "\n",
    "# model = NetDDD3().to(device)\n",
    "# lr = 3e-2\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# #         scheduler.step()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             vl=criterion(output, target).item()\n",
    "#             val_loss += vl\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(train_losses, label='train loss')\n",
    "# plt.plot(val_losses, label='val loss')\n",
    "# plt.legend();\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(train_accs, label='train acc')\n",
    "# plt.plot(val_accs, label='val acc')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=100\n",
    "# batch_size=5000\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# model = NetDDD3().to(device)\n",
    "# lr = 1e-1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "# val_f1s = []\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             vl=criterion(output, target).item()\n",
    "#             val_loss += vl\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "#     val_f1s.append(val_f1)\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# # plt.subplot(1,2,1)\n",
    "# # plt.plot(train_losses, label='train loss')\n",
    "# # plt.plot(val_losses, label='val loss')\n",
    "# # plt.legend();\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.plot(train_accs, label='train acc')\n",
    "# # plt.plot(val_accs, label='val acc')\n",
    "# plt.plot(val_accs, label='val f1')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable, Optional\n",
    "import weakref\n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# Partially based on:\n",
    "# https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/training/moving_averages.py\n",
    "class ExponentialMovingAverage:\n",
    "    \"\"\"\n",
    "    Maintains (exponential) moving average of a set of parameters.\n",
    "    Args:\n",
    "        parameters: Iterable of `torch.nn.Parameter` (typically from\n",
    "            `model.parameters()`).\n",
    "            Note that EMA is computed on *all* provided parameters,\n",
    "            regardless of whether or not they have `requires_grad = True`;\n",
    "            this allows a single EMA object to be consistantly used even\n",
    "            if which parameters are trainable changes step to step.\n",
    "            If you want to some parameters in the EMA, do not pass them\n",
    "            to the object in the first place. For example:\n",
    "                ExponentialMovingAverage(\n",
    "                    parameters=[p for p in model.parameters() if p.requires_grad],\n",
    "                    decay=0.9\n",
    "                )\n",
    "            will ignore parameters that do not require grad.\n",
    "        decay: The exponential decay.\n",
    "        use_num_updates: Whether to use number of updates when computing\n",
    "            averages.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        parameters: Iterable[torch.nn.Parameter],\n",
    "        decay: float,\n",
    "        use_num_updates: bool = True\n",
    "    ):\n",
    "        if decay < 0.0 or decay > 1.0:\n",
    "            raise ValueError('Decay must be between 0 and 1')\n",
    "        self.decay = decay\n",
    "        self.num_updates = 0 if use_num_updates else None\n",
    "        parameters = list(parameters)\n",
    "        self.shadow_params = [\n",
    "            p.clone().detach()\n",
    "            for p in parameters\n",
    "        ]\n",
    "        self.collected_params = None\n",
    "        # By maintaining only a weakref to each parameter,\n",
    "        # we maintain the old GC behaviour of ExponentialMovingAverage:\n",
    "        # if the model goes out of scope but the ExponentialMovingAverage\n",
    "        # is kept, no references to the model or its parameters will be\n",
    "        # maintained, and the model will be cleaned up.\n",
    "        self._params_refs = [weakref.ref(p) for p in parameters]\n",
    "\n",
    "    def _get_parameters(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]]\n",
    "    ) -> Iterable[torch.nn.Parameter]:\n",
    "        if parameters is None:\n",
    "            parameters = [p() for p in self._params_refs]\n",
    "            if any(p is None for p in parameters):\n",
    "                raise ValueError(\n",
    "                    \"(One of) the parameters with which this \"\n",
    "                    \"ExponentialMovingAverage \"\n",
    "                    \"was initialized no longer exists (was garbage collected);\"\n",
    "                    \" please either provide `parameters` explicitly or keep \"\n",
    "                    \"the model to which they belong from being garbage \"\n",
    "                    \"collected.\"\n",
    "                )\n",
    "            return parameters\n",
    "        else:\n",
    "            parameters = list(parameters)\n",
    "            if len(parameters) != len(self.shadow_params):\n",
    "                raise ValueError(\n",
    "                    \"Number of parameters passed as argument is different \"\n",
    "                    \"from number of shadow parameters maintained by this \"\n",
    "                    \"ExponentialMovingAverage\"\n",
    "                )\n",
    "            return parameters\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Update currently maintained parameters.\n",
    "        Call this every time the parameters are updated, such as the result of\n",
    "        the `optimizer.step()` call.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; usually the same set of\n",
    "                parameters used to initialize this object. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        decay = self.decay\n",
    "        if self.num_updates is not None:\n",
    "            self.num_updates += 1\n",
    "            decay = min(\n",
    "                decay,\n",
    "                (1 + self.num_updates) / (10 + self.num_updates)\n",
    "            )\n",
    "        one_minus_decay = 1.0 - decay\n",
    "        with torch.no_grad():\n",
    "            for s_param, param in zip(self.shadow_params, parameters):\n",
    "                tmp = (s_param - param)\n",
    "                # tmp will be a new tensor so we can do in-place\n",
    "                tmp.mul_(one_minus_decay)\n",
    "                s_param.sub_(tmp)\n",
    "\n",
    "    def copy_to(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Copy current averaged parameters into given collection of parameters.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored moving averages. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        for s_param, param in zip(self.shadow_params, parameters):\n",
    "            param.data.copy_(s_param.data)\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Save the current parameters for restoring later.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                temporarily stored. If `None`, the parameters of with which this\n",
    "                `ExponentialMovingAverage` was initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        self.collected_params = [\n",
    "            param.clone()\n",
    "            for param in parameters\n",
    "        ]\n",
    "\n",
    "    def restore(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Restore the parameters stored with the `store` method.\n",
    "        Useful to validate the model with EMA parameters without affecting the\n",
    "        original optimization process. Store the parameters before the\n",
    "        `copy_to` method. After validation (or model saving), use this to\n",
    "        restore the former parameters.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored parameters. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        if self.collected_params is None:\n",
    "            raise RuntimeError(\n",
    "                \"This ExponentialMovingAverage has no `store()`ed weights \"\n",
    "                \"to `restore()`\"\n",
    "            )\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        for c_param, param in zip(self.collected_params, parameters):\n",
    "            param.data.copy_(c_param.data)\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def average_parameters(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Context manager for validation/inference with averaged parameters.\n",
    "        Equivalent to:\n",
    "            ema.store()\n",
    "            ema.copy_to()\n",
    "            try:\n",
    "                ...\n",
    "            finally:\n",
    "                ema.restore()\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored parameters. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        self.store(parameters)\n",
    "        self.copy_to(parameters)\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            self.restore(parameters)\n",
    "\n",
    "    def to(self, device=None, dtype=None) -> None:\n",
    "        r\"\"\"Move internal buffers of the ExponentialMovingAverage to `device`.\n",
    "        Args:\n",
    "            device: like `device` argument to `torch.Tensor.to`\n",
    "        \"\"\"\n",
    "        # .to() on the tensors handles None correctly\n",
    "        self.shadow_params = [\n",
    "            p.to(device=device, dtype=dtype)\n",
    "            if p.is_floating_point()\n",
    "            else p.to(device=device)\n",
    "            for p in self.shadow_params\n",
    "        ]\n",
    "        if self.collected_params is not None:\n",
    "            self.collected_params = [\n",
    "                p.to(device=device, dtype=dtype)\n",
    "                if p.is_floating_point()\n",
    "                else p.to(device=device)\n",
    "                for p in self.collected_params\n",
    "            ]\n",
    "        return\n",
    "\n",
    "    def state_dict(self) -> dict:\n",
    "        r\"\"\"Returns the state of the ExponentialMovingAverage as a dict.\"\"\"\n",
    "        # Following PyTorch conventions, references to tensors are returned:\n",
    "        # \"returns a reference to the state and not its copy!\" -\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "        return {\n",
    "            \"decay\": self.decay,\n",
    "            \"num_updates\": self.num_updates,\n",
    "            \"shadow_params\": self.shadow_params,\n",
    "            \"collected_params\": self.collected_params\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict: dict) -> None:\n",
    "        r\"\"\"Loads the ExponentialMovingAverage state.\n",
    "        Args:\n",
    "            state_dict (dict): EMA state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        # deepcopy, to be consistent with module API\n",
    "        state_dict = copy.deepcopy(state_dict)\n",
    "        self.decay = state_dict[\"decay\"]\n",
    "        if self.decay < 0.0 or self.decay > 1.0:\n",
    "            raise ValueError('Decay must be between 0 and 1')\n",
    "        self.num_updates = state_dict[\"num_updates\"]\n",
    "        assert self.num_updates is None or isinstance(self.num_updates, int), \\\n",
    "            \"Invalid num_updates\"\n",
    "\n",
    "        self.shadow_params = state_dict[\"shadow_params\"]\n",
    "        assert isinstance(self.shadow_params, list), \\\n",
    "            \"shadow_params must be a list\"\n",
    "        assert all(\n",
    "            isinstance(p, torch.Tensor) for p in self.shadow_params\n",
    "        ), \"shadow_params must all be Tensors\"\n",
    "\n",
    "        self.collected_params = state_dict[\"collected_params\"]\n",
    "        if self.collected_params is not None:\n",
    "            assert isinstance(self.collected_params, list), \\\n",
    "                \"collected_params must be a list\"\n",
    "            assert all(\n",
    "                isinstance(p, torch.Tensor) for p in self.collected_params\n",
    "            ), \"collected_params must all be Tensors\"\n",
    "            assert len(self.collected_params) == len(self.shadow_params), \\\n",
    "                \"collected_params and shadow_params had different lengths\"\n",
    "\n",
    "        if len(self.shadow_params) == len(self._params_refs):\n",
    "            # Consistant with torch.optim.Optimizer, cast things to consistant\n",
    "            # device and dtype with the parameters\n",
    "            params = [p() for p in self._params_refs]\n",
    "            # If parameters have been garbage collected, just load the state\n",
    "            # we were given without change.\n",
    "            if not any(p is None for p in params):\n",
    "                # ^ parameter references are still good\n",
    "                for i, p in enumerate(params):\n",
    "                    self.shadow_params[i] = self.shadow_params[i].to(\n",
    "                        device=p.device, dtype=p.dtype\n",
    "                    )\n",
    "                    if self.collected_params is not None:\n",
    "                        self.collected_params[i] = self.collected_params[i].to(\n",
    "                            device=p.device, dtype=p.dtype\n",
    "                        )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Tried to `load_state_dict()` with the wrong number of \"\n",
    "                \"parameters in the saved state.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/where-is-the-noise-layer-in-pytorch/2887/3\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=200\n",
    "# batch_size=100\n",
    "\n",
    "# train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "# val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# class NetDDD4(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NetDDD4, self).__init__()\n",
    "        \n",
    "#         self.n = GaussianNoise(0.1)\n",
    "        \n",
    "#         sz = 4096*4\n",
    "        \n",
    "#         self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "#                                    nn.Dropout(0.8),\n",
    "#                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(sz,512),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(512,64),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(64,sz),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "#                                    nn.Dropout(0.8),\n",
    "#                                    nn.Linear(sz,3))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.n(x)\n",
    "#         return self.m(x)\n",
    "\n",
    "# model = NetDDD4().to(device)\n",
    "\n",
    "# ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "\n",
    "\n",
    "# lr = 3e-4\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "# val_f1s = []\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         ema.update()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         with ema.average_parameters():\n",
    "#             for data, target in val_loader:\n",
    "#                 data, target = data.to(device), target.to(device)\n",
    "#                 output = model(data)\n",
    "#                 vl=criterion(output, target).item()\n",
    "#                 val_loss += vl\n",
    "#                 pred = output.argmax(dim=1, keepdim=True)\n",
    "#                 correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#                 val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "#     val_f1s.append(val_f1)\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# # plt.subplot(1,2,1)\n",
    "# # plt.plot(train_losses, label='train loss')\n",
    "# # plt.plot(val_losses, label='val loss')\n",
    "# # plt.legend();\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.plot(train_accs, label='train acc')\n",
    "# # plt.plot(val_accs, label='val acc')\n",
    "# plt.plot(val_accs, label='val f1')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "# from torch.utils import tensorboard\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [I 2022-02-24 01:47:56,827] Trial 35 finished with value: 0.8130246066637513 and parameters: {'smoothing': 2.2731385669022297e-06, 'batch_size': 961, 'noise': 0.005599400703712527, 'neurons': 3022, 'relu': 'Leaky', 'dropout1': 0.004017445332648056, 'dropout2': 0.6251959618185807, 'lr': 0.09806801492571182}. Best is trial 35 with value: 0.8130246066637513.\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "#     smoothing=trial.suggest_float(\"smoothing\", 1e-7, 1e-1, log=True)\n",
    "#     criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "\n",
    "    kwargs = {\"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.999), \"gamma\": trial.suggest_float(\"gamma\", 1,5), \"reduction\": 'mean'}\n",
    "    criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "\n",
    "\n",
    "    class NetDDDOptuna(nn.Module):\n",
    "        def __init__(self,cfg):\n",
    "            super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "            self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "            sz = cfg['neurons']\n",
    "            \n",
    "            if cfg['relu']=='relu':\n",
    "                relu=nn.ReLU\n",
    "            else:\n",
    "                relu=nn.LeakyReLU\n",
    "\n",
    "            self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                       nn.Dropout(cfg['dropout1']),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(sz,512),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(512,64),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(64,sz),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "                                       nn.Dropout(cfg['dropout2']),\n",
    "                                       nn.Linear(sz,3))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.n(x)\n",
    "            return self.m(x)\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 1, 5000)\n",
    "    train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "    val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "        \n",
    "    \n",
    "    noise =trial.suggest_float(\"noise\", 1e-5, 1e-1, log=True)\n",
    "    neurons = trial.suggest_int(\"neurons\", 8, 4096)\n",
    "    relu = trial.suggest_categorical(\"relu\", [\"relu\", \"Leaky\"])\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0,1)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0,1)\n",
    "        \n",
    "    cfg={'noise': noise,\n",
    "         'neurons': neurons,\n",
    "         'relu': relu,\n",
    "         'dropout1': dropout1,\n",
    "         'dropout2': dropout2,\n",
    "    }\n",
    "        \n",
    "    model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "    ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 3e-1, log=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "#     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    train_accs=[]\n",
    "    val_accs=[]\n",
    "    val_f1s = []\n",
    "\n",
    "#     liveloss = PlotLosses()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        correct=0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            ema.update()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            train_loss+=loss.item()\n",
    "        train_loss/=len(train_loader)\n",
    "        acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        val_f1 = 0\n",
    "        with torch.no_grad():\n",
    "            with ema.average_parameters():\n",
    "                for data, target in val_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    vl=criterion(output, target).item()\n",
    "                    val_loss += vl\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                    val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "        val_loss /= float(len(val_loader))\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "        val_f1 /= float(len(val_loader))\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        logs={}\n",
    "        logs['train_loss'] = train_loss\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['train_acc'] = acc\n",
    "    #     logs['val_acc'] = val_acc\n",
    "        logs['val_f1'] = val_f1\n",
    "        \n",
    "        \n",
    "    \n",
    "#         # log scalars to Tensorboard\n",
    "#         writer.add_scalar('val/f1', val_f1, epoch)\n",
    "#         writer.add_scalar('train/loss', train_loss, epoch)\n",
    "#         writer.add_scalar('val/loss', val_loss, epoch)\n",
    "\n",
    "#         liveloss.update(logs)\n",
    "#         if epoch%5==0:\n",
    "#             liveloss.send()\n",
    "            \n",
    "        trial.report(val_f1, epoch)\n",
    "        if trial.should_prune():\n",
    "#             # log metrics and params to TensorBoard HParams\n",
    "#             cfg['epochs']=epochs\n",
    "#             cfg['batch_size']=batch_size\n",
    "#             cfg['lr']=lr\n",
    "#             cfg['smoothing']=smoothing\n",
    "#             cfg['params_count']=sum(p.numel() for p in model.parameters())\n",
    "#             writer.add_hparams(cfg,\n",
    "#                    {'hp/val_loss': cal_loss,\n",
    "#                     'hp/val_f1': val_f1},\n",
    "#                    run_name=unique_name)\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return val_f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='sentiment-focal', storage='sqlite:///example.db', load_if_exists=True)\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[I 2022-02-24 14:30:58,582] Trial 61 finished with value: 0.8191760028934914 and parameters: {'alpha': 0.58952085048941, 'gamma': 3.4880484258622437, 'batch_size': 488, 'noise': 0.06595507038359001, 'neurons': 3775, 'relu': 'Leaky', 'dropout1': 0.13587081895474534, 'dropout2': 0.877662163749141, 'lr': 0.2811878155016364}. Best is trial 61 with value: 0.8191760028934914.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/davda54/ada-hessian/blob/master/ada_hessian.py\n",
    "\n",
    "class AdaHessian(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the AdaHessian algorithm from \"ADAHESSIAN: An Adaptive Second OrderOptimizer for Machine Learning\"\n",
    "    Arguments:\n",
    "        params (iterable) -- iterable of parameters to optimize or dicts defining parameter groups\n",
    "        lr (float, optional) -- learning rate (default: 0.1)\n",
    "        betas ((float, float), optional) -- coefficients used for computing running averages of gradient and the squared hessian trace (default: (0.9, 0.999))\n",
    "        eps (float, optional) -- term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional) -- weight decay (L2 penalty) (default: 0.0)\n",
    "        hessian_power (float, optional) -- exponent of the hessian trace (default: 1.0)\n",
    "        update_each (int, optional) -- compute the hessian trace approximation only after *this* number of steps (to save time) (default: 1)\n",
    "        n_samples (int, optional) -- how many times to sample `z` for the approximation of the hessian trace (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.1, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.0, \n",
    "                 hessian_power=1.0, update_each=1, n_samples=1, average_conv_kernel=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 0: {betas[0]}\")\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 1: {betas[1]}\")\n",
    "        if not 0.0 <= hessian_power <= 1.0:\n",
    "            raise ValueError(f\"Invalid Hessian power value: {hessian_power}\")\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "        self.update_each = update_each\n",
    "        self.average_conv_kernel = average_conv_kernel\n",
    "\n",
    "        # use a separate generator that deterministically generates the same `z`s across all GPUs in case of distributed training\n",
    "        self.generator = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, hessian_power=hessian_power)\n",
    "        super(AdaHessian, self).__init__(params, defaults)\n",
    "\n",
    "        for p in self.get_params():\n",
    "            p.hess = 0.0\n",
    "            self.state[p][\"hessian step\"] = 0\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Gets all parameters in all param_groups with gradients\n",
    "        \"\"\"\n",
    "\n",
    "        return (p for group in self.param_groups for p in group['params'] if p.requires_grad)\n",
    "\n",
    "    def zero_hessian(self):\n",
    "        \"\"\"\n",
    "        Zeros out the accumalated hessian traces.\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.get_params():\n",
    "            if not isinstance(p.hess, float) and self.state[p][\"hessian step\"] % self.update_each == 0:\n",
    "                p.hess.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_hessian(self):\n",
    "        \"\"\"\n",
    "        Computes the Hutchinson approximation of the hessian trace and accumulates it for each trainable parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        params = []\n",
    "        for p in filter(lambda p: p.grad is not None, self.get_params()):\n",
    "            if self.state[p][\"hessian step\"] % self.update_each == 0:  # compute the trace only each `update_each` step\n",
    "                params.append(p)\n",
    "            self.state[p][\"hessian step\"] += 1\n",
    "\n",
    "        if len(params) == 0:\n",
    "            return\n",
    "\n",
    "        if self.generator.device != params[0].device:  # hackish way of casting the generator to the right device\n",
    "            self.generator = torch.Generator(params[0].device).manual_seed(2147483647)\n",
    "\n",
    "        grads = [p.grad for p in params]\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            zs = [torch.randint(0, 2, p.size(), generator=self.generator, device=p.device) * 2.0 - 1.0 for p in params]  # Rademacher distribution {-1.0, 1.0}\n",
    "            h_zs = torch.autograd.grad(grads, params, grad_outputs=zs, only_inputs=True, retain_graph=i < self.n_samples - 1)\n",
    "            for h_z, z, p in zip(h_zs, zs, params):\n",
    "                p.hess += h_z * z / self.n_samples  # approximate the expected values of z*(H@z)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional) -- a closure that reevaluates the model and returns the loss (default: None)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        self.zero_hessian()\n",
    "        self.set_hessian()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None or p.hess is None:\n",
    "                    continue\n",
    "\n",
    "                if self.average_conv_kernel and p.dim() == 4:\n",
    "                    p.hess = torch.abs(p.hess).mean(dim=[2, 3], keepdim=True).expand_as(p.hess).clone()\n",
    "\n",
    "                # Perform correct stepweight decay as in AdamW\n",
    "                p.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 1:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)  # Exponential moving average of gradient values\n",
    "                    state['exp_hessian_diag_sq'] = torch.zeros_like(p.data)  # Exponential moving average of Hessian diagonal square values\n",
    "\n",
    "                exp_avg, exp_hessian_diag_sq = state['exp_avg'], state['exp_hessian_diag_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(p.grad, alpha=1 - beta1)\n",
    "                exp_hessian_diag_sq.mul_(beta2).addcmul_(p.hess, p.hess, value=1 - beta2)\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                k = group['hessian_power']\n",
    "                denom = (exp_hessian_diag_sq / bias_correction2).pow_(k / 2).add_(group['eps'])\n",
    "\n",
    "                # make update\n",
    "                step_size = group['lr'] / bias_correction1\n",
    "                p.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1\n",
      "\tval_f1           \t (min:    0.206, max:    0.783, cur:    0.782)\n",
      "Loss\n",
      "\tvalidation       \t (min:    0.051, max:    0.163, cur:    0.051)\n",
      "train_acc\n",
      "\ttrain_acc        \t (min:    0.326, max:    0.888, cur:    0.888)\n",
      "train_loss\n",
      "\ttraining         \t (min:    0.019, max:    0.191, cur:    0.019)\n"
     ]
    }
   ],
   "source": [
    "# [I 2022-02-24 01:47:56,827] Trial 35 finished with value: 0.8130246066637513 and parameters: {'smoothing': 2.2731385669022297e-06, 'batch_size': 961, 'noise': 0.005599400703712527, 'neurons': 3022, 'relu': 'Leaky', 'dropout1': 0.004017445332648056, 'dropout2': 0.6251959618185807, 'lr': 0.09806801492571182}. Best is trial 35 with value: 0.8130246066637513.\n",
    "\n",
    "cfg ={'alpha': 0.58952085048941,\n",
    "      'gamma': 3.4880484258622437,\n",
    "      'batch_size': 5000,#488,\n",
    "      'noise': 0.06595507038359001/10,\n",
    "      'neurons': 3775,\n",
    "      'relu': 'Leaky',\n",
    "      'dropout1': 0.13587081895474534,\n",
    "      'dropout2': 0.877662163749141,\n",
    "      'lr': 0.01}#0.2811878155016364}\n",
    "\n",
    "# smoothing=cfg[\"smoothing\"]\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "kwargs = {\"alpha\": 0.58952085048941, \"gamma\": 3.4880484258622437, \"reduction\": 'mean'}\n",
    "criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "# def criterion(a,b):\n",
    "#     return kornia.losses.FocalLoss(**kwargs)(a,b) + nn.CrossEntropyLoss(label_smoothing=0.1)(a,b)\n",
    "\n",
    "\n",
    "class NetDDDOptuna(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "        self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "        sz = cfg['neurons']\n",
    "\n",
    "        if cfg['relu']=='relu':\n",
    "            relu=nn.ReLU\n",
    "        else:\n",
    "            relu=nn.LeakyReLU\n",
    "\n",
    "        self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                   nn.Dropout(cfg['dropout1']),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "#                                    nn.Linear(sz,sz),\n",
    "#                                    relu(),\n",
    "#                                    nn.Linear(sz,sz),\n",
    "#                                    relu(),\n",
    "                                   nn.Dropout(cfg['dropout2']),\n",
    "                                   nn.Linear(sz,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.n(x)\n",
    "        return self.m(x)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "noise =cfg[\"noise\"]\n",
    "neurons = [\"neurons\"]\n",
    "relu = cfg[\"relu\"]\n",
    "dropout1 = cfg[\"dropout1\"]\n",
    "dropout2 = cfg[\"dropout2\"]\n",
    "\n",
    "\n",
    "\n",
    "lr = cfg[\"lr\"]\n",
    "\n",
    "\n",
    "\n",
    "unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "#     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "\n",
    "\n",
    "clip_value = 1\n",
    "\n",
    "for xx in range(10):\n",
    "    model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.register_hook(lambda grad: torch.clamp(grad, -clip_value, clip_value))\n",
    "\n",
    "    ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#     optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "    optimizer = AdaHessian(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                    max_lr=lr,\n",
    "                                                    steps_per_epoch=len(train_loader),\n",
    "                                                    epochs=epochs, pct_start=0.1, div_factor=1000, final_div_factor=1000)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5, 2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00001, max_lr=0.3, mode='triangular2',step_size_up=20)\n",
    "\n",
    "#     lr = lr/10\n",
    "\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    train_accs=[]\n",
    "    val_accs=[]\n",
    "    val_f1s = []\n",
    "\n",
    "    liveloss = PlotLosses()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        correct=0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "#             loss.backward()  #normal 1st order opt\n",
    "            loss.backward(create_graph=True) # adahessian\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            ema.update()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            train_loss+=loss.item()\n",
    "    #     scheduler.step()\n",
    "        train_loss/=len(train_loader)\n",
    "        acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        val_f1 = 0\n",
    "        with torch.no_grad():\n",
    "            with ema.average_parameters():\n",
    "                for data, target in val_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    vl=criterion(output, target).item()\n",
    "                    val_loss += vl\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                    val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "        val_loss /= float(len(val_loader))\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "        val_f1 /= float(len(val_loader))\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        logs={}\n",
    "        logs['train_loss'] = train_loss\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['train_acc'] = acc\n",
    "    #     logs['val_acc'] = val_acc\n",
    "        logs['val_f1'] = val_f1\n",
    "        if val_f1>=0.825:\n",
    "            print('val_f1>=0.825')\n",
    "            break\n",
    "\n",
    "\n",
    "    #         # log scalars to Tensorboard\n",
    "    #         writer.add_scalar('val/f1', val_f1, epoch)\n",
    "    #         writer.add_scalar('train/loss', train_loss, epoch)\n",
    "    #         writer.add_scalar('val/loss', val_loss, epoch)\n",
    "\n",
    "        liveloss.update(logs)\n",
    "        if epoch%5==0:\n",
    "            liveloss.send()\n",
    "    \n",
    "    if val_f1>=0.825:\n",
    "        print('val_f1>=0.825')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1643711867290,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "WHNi9e7TP8pz",
    "outputId": "4dc030f1-eb3b-4c34-92f2-87c304e78d5f"
   },
   "outputs": [],
   "source": [
    "submission_embeddings = [literal_eval(embedding)  for embedding in submission['embeddings'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(normalize_X(submission_embeddings))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor((submission_embeddings-np.array(submission_embeddings).mean(axis=0))/np.array(submission_embeddings).std(axis=0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.mean(axis=0),label='test')\n",
    "plt.plot(normalize_X(X_val).mean(axis=0),label='val')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = 100\n",
    "results=[]\n",
    "with torch.no_grad():\n",
    "#     with ema.average_parameters():\n",
    "    for i in range(tta):\n",
    "        results.append(model(x.cuda()).cpu().numpy())\n",
    "results = np.array(results).mean(axis=0)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with ema.average_parameters():\n",
    "        result = model.m(x.cuda()).cpu()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ARGMAX (one hot)  MEAN STD\n",
    "predictions = np.argmax(result,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):\n",
    "    if a==0:\n",
    "        return 'negative'\n",
    "    if a==1:\n",
    "        return 'neutral'\n",
    "    if a==2:\n",
    "        return 'positive'\n",
    "\n",
    "result = list(map(convert, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1643711867292,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "J4vBe0mAQDJv",
    "outputId": "65e20e41-bfcf-4ab6-bb49-90569b52d2b7"
   },
   "outputs": [],
   "source": [
    "submission['label'] = result\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30oDKdd7HV8R"
   },
   "source": [
    "### Saving the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qv7xSbHQHVPg"
   },
   "outputs": [],
   "source": [
    "# Saving the predictions\n",
    "# !rm -rf assets\n",
    "# !mkdir assets\n",
    "submission.to_csv(os.path.join(\"assets\", \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357,
     "referenced_widgets": [
      "4660207a213e42b799859c22675d2476",
      "45f6d3e90b9f46f29b8cdc49f069bcc5"
     ]
    },
    "executionInfo": {
     "elapsed": 38827,
     "status": "ok",
     "timestamp": 1643713380919,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "JyrIU1uXHMjb",
    "outputId": "867e512d-72b1-4b5a-a584-4f0d9c9c6f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using notebook: pytorch-sentiment.ipynb for submission...\n",
      "Removing existing files from submission directory...\n",
      "Scrubbing API keys from the notebook...\n",
      "Collecting notebook...\n",
      "WARNING: Got more than 1 jupyter server, selecting the latest session\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a48d85daba14bc39223b8061acf9692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                                                                                        \n",
       "                                                                                             <span style=\"font-weight: bold\">Successfully submitted!</span>                                                                                             \n",
       "                                                                                                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                                                                                                                        \n",
       "                                                                                             \u001b[1mSuccessfully submitted!\u001b[0m                                                                                             \n",
       "                                                                                                                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                                  Important links                                                                                                  </span>\n",
       "\n",
       "            This submission  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions/175611                                                                              \n",
       "                                                                                                                                                                                                                \n",
       "            All submissions  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions?my_submissions=true                                                                 \n",
       "                                                                                                                                                                                                                \n",
       "                Leaderboard  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/leaderboards                                                                                    \n",
       "                                                                                                                                                                                                                \n",
       "           Discussion forum  https://discourse.aicrowd.com/c/ai-blitz-xiii                                                                                                                                      \n",
       "                                                                                                                                                                                                                \n",
       "             Challenge page  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification                                                                                                 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                                  Important links                                                                                                  \u001b[0m\n",
       "\n",
       "            This submission  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions/175611                                                                              \n",
       "                                                                                                                                                                                                                \n",
       "            All submissions  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions?my_submissions=true                                                                 \n",
       "                                                                                                                                                                                                                \n",
       "                Leaderboard  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/leaderboards                                                                                    \n",
       "                                                                                                                                                                                                                \n",
       "           Discussion forum  https://discourse.aicrowd.com/c/ai-blitz-xiii                                                                                                                                      \n",
       "                                                                                                                                                                                                                \n",
       "             Challenge page  https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification                                                                                                 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%aicrowd notebook submit -c sentiment-classification -a assets --no-verify -n pytorch-sentiment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
