{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ReMrWg8l3mRU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2476,
     "status": "ok",
     "timestamp": 1643711675304,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "9uR1JofUJQKi",
    "outputId": "f071c14b-646e-4bad-8690-d77cbeb62464"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3206779360771179, 0.988215982913971, 1.0441...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.05074610561132431, 1.0742985010147095, 0.60...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.41962647438049316, 0.4505457878112793, 1.39...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4361684024333954, 0.19191382825374603, 0.83...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6382085084915161, 0.8352395296096802, 0.393...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[2.2057647705078125, 1.1072001457214355, 0.435...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[0.6344252228736877, 1.164398193359375, 0.7155...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[0.9160683155059814, 0.39996421337127686, 0.82...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[0.006456990726292133, 0.18667978048324585, 0....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[1.337027668952942, 0.8853631615638733, 0.6706...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.3206779360771179, 0.988215982913971, 1.0441...  positive\n",
       "1     [0.05074610561132431, 1.0742985010147095, 0.60...  negative\n",
       "2     [0.41962647438049316, 0.4505457878112793, 1.39...  negative\n",
       "3     [0.4361684024333954, 0.19191382825374603, 0.83...  positive\n",
       "4     [0.6382085084915161, 0.8352395296096802, 0.393...   neutral\n",
       "...                                                 ...       ...\n",
       "4995  [2.2057647705078125, 1.1072001457214355, 0.435...   neutral\n",
       "4996  [0.6344252228736877, 1.164398193359375, 0.7155...  negative\n",
       "4997  [0.9160683155059814, 0.39996421337127686, 0.82...  negative\n",
       "4998  [0.006456990726292133, 0.18667978048324585, 0....  positive\n",
       "4999  [1.337027668952942, 0.8853631615638733, 0.6706...  negative\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readging the csv \n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "val = pd.read_csv(\"data/val.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZmyPFxjwOe1c"
   },
   "outputs": [],
   "source": [
    "# Getting the feature and labels from each set. \n",
    "\n",
    "\n",
    "X = np.array([literal_eval(embedding)  for embedding in train['embeddings'].values])\n",
    "y = np.array(train['label'].values)\n",
    "\n",
    "X_val = np.array([literal_eval(embedding)  for embedding in val['embeddings'].values])\n",
    "y_val = np.array(val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 512), (5000,), (2000, 512), (5000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_val.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X,axis=0)\n",
    "std = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.errorbar(range(512), mean, std, linestyle='None', marker='^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y=='positive']=2\n",
    "y[y=='negative']=0\n",
    "y[y=='neutral']=1\n",
    "\n",
    "y_val[y_val=='positive']=2\n",
    "y_val[y_val=='negative']=0\n",
    "y_val[y_val=='neutral']=1\n",
    "\n",
    "y=y.astype(np.int32)\n",
    "y_val=y_val.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 2, 1, 0, 0, 0, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([1622, 1694, 1684]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([640, 633, 727]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_X(X):\n",
    "    return (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = torch.Tensor(normalize_X(X))\n",
    "ty = torch.Tensor(y).long()\n",
    "\n",
    "tx_val = torch.Tensor(normalize_X(X_val))\n",
    "ty_val = torch.Tensor(y_val).long()\n",
    "\n",
    "ds_train = TensorDataset(tx,ty)\n",
    "# train_loader = DataLoader(ds_train, batch_size=1000)\n",
    "\n",
    "ds_val = TensorDataset(tx_val,ty_val)\n",
    "# val_loader = DataLoader(ds_val, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(use_cuda,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "batch_size=5000\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#label_smoothing=0.1)\n",
    "\n",
    "class NetDDD3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD3, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Linear(2048,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "    \n",
    "class NetDDD2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD2, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,5000),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(5000,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "\n",
    "class NetDDD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDDD, self).__init__()\n",
    "        self.m = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.m1 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(256,3))\n",
    "        \n",
    "        self.m2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(256,3))\n",
    "        self.m3 = nn.Sequential(nn.Linear(512, 3))\n",
    "\n",
    "        \n",
    "        self.m4 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(256,3))\n",
    "        \n",
    "        self.m5 = nn.Sequential(nn.Linear(512, 2048),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(2048,256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.8),\n",
    "                                   nn.Linear(256,3))\n",
    "\n",
    "        self.fc = nn.Linear(3*5,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.cat((self.m1(x),self.m2(x),self.m3(x),self.m4(x),self.m5(x)),1)\n",
    "        return self.fc(nn.Dropout(0.3)(nn.ReLU()(a)))\n",
    "\n",
    "# model = NetDDD3().to(device)\n",
    "# lr = 3e-2\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# #         scheduler.step()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             vl=criterion(output, target).item()\n",
    "#             val_loss += vl\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(train_losses, label='train loss')\n",
    "# plt.plot(val_losses, label='val loss')\n",
    "# plt.legend();\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(train_accs, label='train acc')\n",
    "# plt.plot(val_accs, label='val acc')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=100\n",
    "# batch_size=5000\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# model = NetDDD3().to(device)\n",
    "# lr = 1e-1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "# val_f1s = []\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             vl=criterion(output, target).item()\n",
    "#             val_loss += vl\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "#     val_f1s.append(val_f1)\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# # plt.subplot(1,2,1)\n",
    "# # plt.plot(train_losses, label='train loss')\n",
    "# # plt.plot(val_losses, label='val loss')\n",
    "# # plt.legend();\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.plot(train_accs, label='train acc')\n",
    "# # plt.plot(val_accs, label='val acc')\n",
    "# plt.plot(val_accs, label='val f1')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable, Optional\n",
    "import weakref\n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# Partially based on:\n",
    "# https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/training/moving_averages.py\n",
    "class ExponentialMovingAverage:\n",
    "    \"\"\"\n",
    "    Maintains (exponential) moving average of a set of parameters.\n",
    "    Args:\n",
    "        parameters: Iterable of `torch.nn.Parameter` (typically from\n",
    "            `model.parameters()`).\n",
    "            Note that EMA is computed on *all* provided parameters,\n",
    "            regardless of whether or not they have `requires_grad = True`;\n",
    "            this allows a single EMA object to be consistantly used even\n",
    "            if which parameters are trainable changes step to step.\n",
    "            If you want to some parameters in the EMA, do not pass them\n",
    "            to the object in the first place. For example:\n",
    "                ExponentialMovingAverage(\n",
    "                    parameters=[p for p in model.parameters() if p.requires_grad],\n",
    "                    decay=0.9\n",
    "                )\n",
    "            will ignore parameters that do not require grad.\n",
    "        decay: The exponential decay.\n",
    "        use_num_updates: Whether to use number of updates when computing\n",
    "            averages.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        parameters: Iterable[torch.nn.Parameter],\n",
    "        decay: float,\n",
    "        use_num_updates: bool = True\n",
    "    ):\n",
    "        if decay < 0.0 or decay > 1.0:\n",
    "            raise ValueError('Decay must be between 0 and 1')\n",
    "        self.decay = decay\n",
    "        self.num_updates = 0 if use_num_updates else None\n",
    "        parameters = list(parameters)\n",
    "        self.shadow_params = [\n",
    "            p.clone().detach()\n",
    "            for p in parameters\n",
    "        ]\n",
    "        self.collected_params = None\n",
    "        # By maintaining only a weakref to each parameter,\n",
    "        # we maintain the old GC behaviour of ExponentialMovingAverage:\n",
    "        # if the model goes out of scope but the ExponentialMovingAverage\n",
    "        # is kept, no references to the model or its parameters will be\n",
    "        # maintained, and the model will be cleaned up.\n",
    "        self._params_refs = [weakref.ref(p) for p in parameters]\n",
    "\n",
    "    def _get_parameters(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]]\n",
    "    ) -> Iterable[torch.nn.Parameter]:\n",
    "        if parameters is None:\n",
    "            parameters = [p() for p in self._params_refs]\n",
    "            if any(p is None for p in parameters):\n",
    "                raise ValueError(\n",
    "                    \"(One of) the parameters with which this \"\n",
    "                    \"ExponentialMovingAverage \"\n",
    "                    \"was initialized no longer exists (was garbage collected);\"\n",
    "                    \" please either provide `parameters` explicitly or keep \"\n",
    "                    \"the model to which they belong from being garbage \"\n",
    "                    \"collected.\"\n",
    "                )\n",
    "            return parameters\n",
    "        else:\n",
    "            parameters = list(parameters)\n",
    "            if len(parameters) != len(self.shadow_params):\n",
    "                raise ValueError(\n",
    "                    \"Number of parameters passed as argument is different \"\n",
    "                    \"from number of shadow parameters maintained by this \"\n",
    "                    \"ExponentialMovingAverage\"\n",
    "                )\n",
    "            return parameters\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Update currently maintained parameters.\n",
    "        Call this every time the parameters are updated, such as the result of\n",
    "        the `optimizer.step()` call.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; usually the same set of\n",
    "                parameters used to initialize this object. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        decay = self.decay\n",
    "        if self.num_updates is not None:\n",
    "            self.num_updates += 1\n",
    "            decay = min(\n",
    "                decay,\n",
    "                (1 + self.num_updates) / (10 + self.num_updates)\n",
    "            )\n",
    "        one_minus_decay = 1.0 - decay\n",
    "        with torch.no_grad():\n",
    "            for s_param, param in zip(self.shadow_params, parameters):\n",
    "                tmp = (s_param - param)\n",
    "                # tmp will be a new tensor so we can do in-place\n",
    "                tmp.mul_(one_minus_decay)\n",
    "                s_param.sub_(tmp)\n",
    "\n",
    "    def copy_to(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Copy current averaged parameters into given collection of parameters.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored moving averages. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        for s_param, param in zip(self.shadow_params, parameters):\n",
    "            param.data.copy_(s_param.data)\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Save the current parameters for restoring later.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                temporarily stored. If `None`, the parameters of with which this\n",
    "                `ExponentialMovingAverage` was initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        self.collected_params = [\n",
    "            param.clone()\n",
    "            for param in parameters\n",
    "        ]\n",
    "\n",
    "    def restore(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Restore the parameters stored with the `store` method.\n",
    "        Useful to validate the model with EMA parameters without affecting the\n",
    "        original optimization process. Store the parameters before the\n",
    "        `copy_to` method. After validation (or model saving), use this to\n",
    "        restore the former parameters.\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored parameters. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        if self.collected_params is None:\n",
    "            raise RuntimeError(\n",
    "                \"This ExponentialMovingAverage has no `store()`ed weights \"\n",
    "                \"to `restore()`\"\n",
    "            )\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        for c_param, param in zip(self.collected_params, parameters):\n",
    "            param.data.copy_(c_param.data)\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def average_parameters(\n",
    "        self,\n",
    "        parameters: Optional[Iterable[torch.nn.Parameter]] = None\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Context manager for validation/inference with averaged parameters.\n",
    "        Equivalent to:\n",
    "            ema.store()\n",
    "            ema.copy_to()\n",
    "            try:\n",
    "                ...\n",
    "            finally:\n",
    "                ema.restore()\n",
    "        Args:\n",
    "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
    "                updated with the stored parameters. If `None`, the\n",
    "                parameters with which this `ExponentialMovingAverage` was\n",
    "                initialized will be used.\n",
    "        \"\"\"\n",
    "        parameters = self._get_parameters(parameters)\n",
    "        self.store(parameters)\n",
    "        self.copy_to(parameters)\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            self.restore(parameters)\n",
    "\n",
    "    def to(self, device=None, dtype=None) -> None:\n",
    "        r\"\"\"Move internal buffers of the ExponentialMovingAverage to `device`.\n",
    "        Args:\n",
    "            device: like `device` argument to `torch.Tensor.to`\n",
    "        \"\"\"\n",
    "        # .to() on the tensors handles None correctly\n",
    "        self.shadow_params = [\n",
    "            p.to(device=device, dtype=dtype)\n",
    "            if p.is_floating_point()\n",
    "            else p.to(device=device)\n",
    "            for p in self.shadow_params\n",
    "        ]\n",
    "        if self.collected_params is not None:\n",
    "            self.collected_params = [\n",
    "                p.to(device=device, dtype=dtype)\n",
    "                if p.is_floating_point()\n",
    "                else p.to(device=device)\n",
    "                for p in self.collected_params\n",
    "            ]\n",
    "        return\n",
    "\n",
    "    def state_dict(self) -> dict:\n",
    "        r\"\"\"Returns the state of the ExponentialMovingAverage as a dict.\"\"\"\n",
    "        # Following PyTorch conventions, references to tensors are returned:\n",
    "        # \"returns a reference to the state and not its copy!\" -\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "        return {\n",
    "            \"decay\": self.decay,\n",
    "            \"num_updates\": self.num_updates,\n",
    "            \"shadow_params\": self.shadow_params,\n",
    "            \"collected_params\": self.collected_params\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict: dict) -> None:\n",
    "        r\"\"\"Loads the ExponentialMovingAverage state.\n",
    "        Args:\n",
    "            state_dict (dict): EMA state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        # deepcopy, to be consistent with module API\n",
    "        state_dict = copy.deepcopy(state_dict)\n",
    "        self.decay = state_dict[\"decay\"]\n",
    "        if self.decay < 0.0 or self.decay > 1.0:\n",
    "            raise ValueError('Decay must be between 0 and 1')\n",
    "        self.num_updates = state_dict[\"num_updates\"]\n",
    "        assert self.num_updates is None or isinstance(self.num_updates, int), \\\n",
    "            \"Invalid num_updates\"\n",
    "\n",
    "        self.shadow_params = state_dict[\"shadow_params\"]\n",
    "        assert isinstance(self.shadow_params, list), \\\n",
    "            \"shadow_params must be a list\"\n",
    "        assert all(\n",
    "            isinstance(p, torch.Tensor) for p in self.shadow_params\n",
    "        ), \"shadow_params must all be Tensors\"\n",
    "\n",
    "        self.collected_params = state_dict[\"collected_params\"]\n",
    "        if self.collected_params is not None:\n",
    "            assert isinstance(self.collected_params, list), \\\n",
    "                \"collected_params must be a list\"\n",
    "            assert all(\n",
    "                isinstance(p, torch.Tensor) for p in self.collected_params\n",
    "            ), \"collected_params must all be Tensors\"\n",
    "            assert len(self.collected_params) == len(self.shadow_params), \\\n",
    "                \"collected_params and shadow_params had different lengths\"\n",
    "\n",
    "        if len(self.shadow_params) == len(self._params_refs):\n",
    "            # Consistant with torch.optim.Optimizer, cast things to consistant\n",
    "            # device and dtype with the parameters\n",
    "            params = [p() for p in self._params_refs]\n",
    "            # If parameters have been garbage collected, just load the state\n",
    "            # we were given without change.\n",
    "            if not any(p is None for p in params):\n",
    "                # ^ parameter references are still good\n",
    "                for i, p in enumerate(params):\n",
    "                    self.shadow_params[i] = self.shadow_params[i].to(\n",
    "                        device=p.device, dtype=p.dtype\n",
    "                    )\n",
    "                    if self.collected_params is not None:\n",
    "                        self.collected_params[i] = self.collected_params[i].to(\n",
    "                            device=p.device, dtype=p.dtype\n",
    "                        )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Tried to `load_state_dict()` with the wrong number of \"\n",
    "                \"parameters in the saved state.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/where-is-the-noise-layer-in-pytorch/2887/3\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=200\n",
    "# batch_size=100\n",
    "\n",
    "# train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "# val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# class NetDDD4(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NetDDD4, self).__init__()\n",
    "        \n",
    "#         self.n = GaussianNoise(0.1)\n",
    "        \n",
    "#         sz = 4096*4\n",
    "        \n",
    "#         self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "#                                    nn.Dropout(0.8),\n",
    "#                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(sz,512),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(512,64),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(64,sz),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "# #                                    nn.Linear(2048,2048),\n",
    "# #                                    nn.LeakyReLU(),\n",
    "#                                    nn.Dropout(0.8),\n",
    "#                                    nn.Linear(sz,3))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.n(x)\n",
    "#         return self.m(x)\n",
    "\n",
    "# model = NetDDD4().to(device)\n",
    "\n",
    "# ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "\n",
    "\n",
    "# lr = 3e-4\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "# train_losses=[]\n",
    "# val_losses=[]\n",
    "# train_accs=[]\n",
    "# val_accs=[]\n",
    "# val_f1s = []\n",
    "\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     model.train()\n",
    "#     train_loss=0\n",
    "#     correct=0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         ema.update()\n",
    "        \n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         train_loss+=loss.item()\n",
    "#     train_loss/=len(train_loader)\n",
    "#     acc = correct / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accs.append(acc)\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_f1 = 0\n",
    "#     with torch.no_grad():\n",
    "#         with ema.average_parameters():\n",
    "#             for data, target in val_loader:\n",
    "#                 data, target = data.to(device), target.to(device)\n",
    "#                 output = model(data)\n",
    "#                 vl=criterion(output, target).item()\n",
    "#                 val_loss += vl\n",
    "#                 pred = output.argmax(dim=1, keepdim=True)\n",
    "#                 correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#                 val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "        \n",
    "\n",
    "#     val_loss /= float(len(val_loader))\n",
    "#     val_acc = correct / len(val_loader.dataset)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accs.append(val_acc)\n",
    "    \n",
    "    \n",
    "#     val_f1 /= float(len(val_loader))\n",
    "#     val_f1s.append(val_f1)\n",
    "    \n",
    "#     logs={}\n",
    "#     logs['train_loss'] = train_loss\n",
    "#     logs['val_loss'] = val_loss\n",
    "#     logs['train_acc'] = acc\n",
    "# #     logs['val_acc'] = val_acc\n",
    "#     logs['val_f1'] = val_f1\n",
    "    \n",
    "#     liveloss.update(logs)\n",
    "#     if epoch%5==0:\n",
    "#         liveloss.send()\n",
    "# #     if epoch%10==0:\n",
    "# #         print(\"Epoch %3d Train loss: %f Acc: %f    Val loss: %f Acc: %f\"%(epoch, train_loss, acc, val_loss, val_acc))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# # plt.subplot(1,2,1)\n",
    "# # plt.plot(train_losses, label='train loss')\n",
    "# # plt.plot(val_losses, label='val loss')\n",
    "# # plt.legend();\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.plot(train_accs, label='train acc')\n",
    "# # plt.plot(val_accs, label='val acc')\n",
    "# plt.plot(val_accs, label='val f1')\n",
    "# plt.legend();\n",
    "# # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "# from torch.utils import tensorboard\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # [I 2022-02-24 01:47:56,827] Trial 35 finished with value: 0.8130246066637513 and parameters: {'smoothing': 2.2731385669022297e-06, 'batch_size': 961, 'noise': 0.005599400703712527, 'neurons': 3022, 'relu': 'Leaky', 'dropout1': 0.004017445332648056, 'dropout2': 0.6251959618185807, 'lr': 0.09806801492571182}. Best is trial 35 with value: 0.8130246066637513.\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "# #     smoothing=trial.suggest_float(\"smoothing\", 1e-7, 1e-1, log=True)\n",
    "# #     criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "\n",
    "#     kwargs = {\"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.999), \"gamma\": trial.suggest_float(\"gamma\", 1,5), \"reduction\": 'mean'}\n",
    "#     criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "\n",
    "\n",
    "#     class NetDDDOptuna(nn.Module):\n",
    "#         def __init__(self,cfg):\n",
    "#             super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "#             self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "#             sz = cfg['neurons']\n",
    "            \n",
    "#             if cfg['relu']=='relu':\n",
    "#                 relu=nn.ReLU\n",
    "#             else:\n",
    "#                 relu=nn.LeakyReLU\n",
    "\n",
    "#             self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "#                                        nn.Dropout(cfg['dropout1']),\n",
    "#                                        relu(),\n",
    "#                                        nn.Linear(sz,sz),\n",
    "#                                        relu(),\n",
    "#     #                                    nn.Linear(2048,2048),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#     #                                    nn.Linear(sz,512),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#     #                                    nn.Linear(512,64),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#     #                                    nn.Linear(64,sz),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#     #                                    nn.Linear(2048,2048),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#     #                                    nn.Linear(2048,2048),\n",
    "#     #                                    nn.LeakyReLU(),\n",
    "#                                        nn.Dropout(cfg['dropout2']),\n",
    "#                                        nn.Linear(sz,3))\n",
    "\n",
    "#         def forward(self, x):\n",
    "#             x = self.n(x)\n",
    "#             return self.m(x)\n",
    "\n",
    "#     epochs = 100\n",
    "#     batch_size = trial.suggest_int(\"batch_size\", 1, 5000)\n",
    "#     train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "#     val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "        \n",
    "    \n",
    "#     noise =trial.suggest_float(\"noise\", 1e-5, 1e-1, log=True)\n",
    "#     neurons = trial.suggest_int(\"neurons\", 8, 4096)\n",
    "#     relu = trial.suggest_categorical(\"relu\", [\"relu\", \"Leaky\"])\n",
    "#     dropout1 = trial.suggest_float(\"dropout1\", 0,1)\n",
    "#     dropout2 = trial.suggest_float(\"dropout2\", 0,1)\n",
    "        \n",
    "#     cfg={'noise': noise,\n",
    "#          'neurons': neurons,\n",
    "#          'relu': relu,\n",
    "#          'dropout1': dropout1,\n",
    "#          'dropout2': dropout2,\n",
    "#     }\n",
    "        \n",
    "#     model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "#     ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "\n",
    "\n",
    "#     lr = trial.suggest_float(\"lr\", 1e-7, 3e-1, log=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "# #     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "    \n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "\n",
    "\n",
    "#     train_losses=[]\n",
    "#     val_losses=[]\n",
    "#     train_accs=[]\n",
    "#     val_accs=[]\n",
    "#     val_f1s = []\n",
    "\n",
    "# #     liveloss = PlotLosses()\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         model.train()\n",
    "#         train_loss=0\n",
    "#         correct=0\n",
    "#         for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "\n",
    "#             ema.update()\n",
    "\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#             train_loss+=loss.item()\n",
    "#         train_loss/=len(train_loader)\n",
    "#         acc = correct / len(train_loader.dataset)\n",
    "#         train_losses.append(train_loss)\n",
    "#         train_accs.append(acc)\n",
    "\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         correct = 0\n",
    "#         val_f1 = 0\n",
    "#         with torch.no_grad():\n",
    "#             with ema.average_parameters():\n",
    "#                 for data, target in val_loader:\n",
    "#                     data, target = data.to(device), target.to(device)\n",
    "#                     output = model(data)\n",
    "#                     vl=criterion(output, target).item()\n",
    "#                     val_loss += vl\n",
    "#                     pred = output.argmax(dim=1, keepdim=True)\n",
    "#                     correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#                     val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "#         val_loss /= float(len(val_loader))\n",
    "#         val_acc = correct / len(val_loader.dataset)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "#         val_f1 /= float(len(val_loader))\n",
    "#         val_f1s.append(val_f1)\n",
    "\n",
    "#         logs={}\n",
    "#         logs['train_loss'] = train_loss\n",
    "#         logs['val_loss'] = val_loss\n",
    "#         logs['train_acc'] = acc\n",
    "#     #     logs['val_acc'] = val_acc\n",
    "#         logs['val_f1'] = val_f1\n",
    "        \n",
    "        \n",
    "    \n",
    "# #         # log scalars to Tensorboard\n",
    "# #         writer.add_scalar('val/f1', val_f1, epoch)\n",
    "# #         writer.add_scalar('train/loss', train_loss, epoch)\n",
    "# #         writer.add_scalar('val/loss', val_loss, epoch)\n",
    "\n",
    "# #         liveloss.update(logs)\n",
    "# #         if epoch%5==0:\n",
    "# #             liveloss.send()\n",
    "            \n",
    "#         trial.report(val_f1, epoch)\n",
    "#         if trial.should_prune():\n",
    "# #             # log metrics and params to TensorBoard HParams\n",
    "# #             cfg['epochs']=epochs\n",
    "# #             cfg['batch_size']=batch_size\n",
    "# #             cfg['lr']=lr\n",
    "# #             cfg['smoothing']=smoothing\n",
    "# #             cfg['params_count']=sum(p.numel() for p in model.parameters())\n",
    "# #             writer.add_hparams(cfg,\n",
    "# #                    {'hp/val_loss': cal_loss,\n",
    "# #                     'hp/val_f1': val_f1},\n",
    "# #                    run_name=unique_name)\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "#     return val_f1\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\", study_name='sentiment-focal', storage='sqlite:///example.db', load_if_exists=True)\n",
    "# study.optimize(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[I 2022-02-24 14:30:58,582] Trial 61 finished with value: 0.8191760028934914 and parameters: {'alpha': 0.58952085048941, 'gamma': 3.4880484258622437, 'batch_size': 488, 'noise': 0.06595507038359001, 'neurons': 3775, 'relu': 'Leaky', 'dropout1': 0.13587081895474534, 'dropout2': 0.877662163749141, 'lr': 0.2811878155016364}. Best is trial 61 with value: 0.8191760028934914.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/davda54/ada-hessian/blob/master/ada_hessian.py\n",
    "\n",
    "class AdaHessian(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the AdaHessian algorithm from \"ADAHESSIAN: An Adaptive Second OrderOptimizer for Machine Learning\"\n",
    "    Arguments:\n",
    "        params (iterable) -- iterable of parameters to optimize or dicts defining parameter groups\n",
    "        lr (float, optional) -- learning rate (default: 0.1)\n",
    "        betas ((float, float), optional) -- coefficients used for computing running averages of gradient and the squared hessian trace (default: (0.9, 0.999))\n",
    "        eps (float, optional) -- term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional) -- weight decay (L2 penalty) (default: 0.0)\n",
    "        hessian_power (float, optional) -- exponent of the hessian trace (default: 1.0)\n",
    "        update_each (int, optional) -- compute the hessian trace approximation only after *this* number of steps (to save time) (default: 1)\n",
    "        n_samples (int, optional) -- how many times to sample `z` for the approximation of the hessian trace (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.1, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.0, \n",
    "                 hessian_power=1.0, update_each=1, n_samples=1, average_conv_kernel=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 0: {betas[0]}\")\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 1: {betas[1]}\")\n",
    "        if not 0.0 <= hessian_power <= 1.0:\n",
    "            raise ValueError(f\"Invalid Hessian power value: {hessian_power}\")\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "        self.update_each = update_each\n",
    "        self.average_conv_kernel = average_conv_kernel\n",
    "\n",
    "        # use a separate generator that deterministically generates the same `z`s across all GPUs in case of distributed training\n",
    "        self.generator = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, hessian_power=hessian_power)\n",
    "        super(AdaHessian, self).__init__(params, defaults)\n",
    "\n",
    "        for p in self.get_params():\n",
    "            p.hess = 0.0\n",
    "            self.state[p][\"hessian step\"] = 0\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Gets all parameters in all param_groups with gradients\n",
    "        \"\"\"\n",
    "\n",
    "        return (p for group in self.param_groups for p in group['params'] if p.requires_grad)\n",
    "\n",
    "    def zero_hessian(self):\n",
    "        \"\"\"\n",
    "        Zeros out the accumalated hessian traces.\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.get_params():\n",
    "            if not isinstance(p.hess, float) and self.state[p][\"hessian step\"] % self.update_each == 0:\n",
    "                p.hess.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_hessian(self):\n",
    "        \"\"\"\n",
    "        Computes the Hutchinson approximation of the hessian trace and accumulates it for each trainable parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        params = []\n",
    "        for p in filter(lambda p: p.grad is not None, self.get_params()):\n",
    "            if self.state[p][\"hessian step\"] % self.update_each == 0:  # compute the trace only each `update_each` step\n",
    "                params.append(p)\n",
    "            self.state[p][\"hessian step\"] += 1\n",
    "\n",
    "        if len(params) == 0:\n",
    "            return\n",
    "\n",
    "        if self.generator.device != params[0].device:  # hackish way of casting the generator to the right device\n",
    "            self.generator = torch.Generator(params[0].device).manual_seed(2147483647)\n",
    "\n",
    "        grads = [p.grad for p in params]\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            zs = [torch.randint(0, 2, p.size(), generator=self.generator, device=p.device) * 2.0 - 1.0 for p in params]  # Rademacher distribution {-1.0, 1.0}\n",
    "            h_zs = torch.autograd.grad(grads, params, grad_outputs=zs, only_inputs=True, retain_graph=i < self.n_samples - 1)\n",
    "            for h_z, z, p in zip(h_zs, zs, params):\n",
    "                p.hess += h_z * z / self.n_samples  # approximate the expected values of z*(H@z)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional) -- a closure that reevaluates the model and returns the loss (default: None)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        self.zero_hessian()\n",
    "        self.set_hessian()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None or p.hess is None:\n",
    "                    continue\n",
    "\n",
    "                if self.average_conv_kernel and p.dim() == 4:\n",
    "                    p.hess = torch.abs(p.hess).mean(dim=[2, 3], keepdim=True).expand_as(p.hess).clone()\n",
    "\n",
    "                # Perform correct stepweight decay as in AdamW\n",
    "                p.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 1:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)  # Exponential moving average of gradient values\n",
    "                    state['exp_hessian_diag_sq'] = torch.zeros_like(p.data)  # Exponential moving average of Hessian diagonal square values\n",
    "\n",
    "                exp_avg, exp_hessian_diag_sq = state['exp_avg'], state['exp_hessian_diag_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(p.grad, alpha=1 - beta1)\n",
    "                exp_hessian_diag_sq.mul_(beta2).addcmul_(p.hess, p.hess, value=1 - beta2)\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                k = group['hessian_power']\n",
    "                denom = (exp_hessian_diag_sq / bias_correction2).pow_(k / 2).add_(group['eps'])\n",
    "\n",
    "                # make update\n",
    "                step_size = group['lr'] / bias_correction1\n",
    "                p.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karol/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:200: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.\n",
      "\u001b[32m[I 2022-02-25 12:24:35,478]\u001b[0m A new study created in RDB with name: sentiment-focal-radam-final-max-500\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:24:42,234]\u001b[0m Trial 0 finished with value: 0.7784214009208312 and parameters: {'alpha': 0.6069801736609624, 'gamma': 4.129758547687664, 'noise': 3.662773014395372e-05, 'neurons': 706, 'relu': 'relu', 'dropout1': 0.5427201530964595, 'dropout2': 0.7712789830153929, 'layers': 1}. Best is trial 0 with value: 0.7784214009208312.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:24:48,444]\u001b[0m Trial 1 finished with value: 0.7534251851101419 and parameters: {'alpha': 0.6114145167164778, 'gamma': 4.700029289893212, 'noise': 0.13900904081766116, 'neurons': 260, 'relu': 'relu', 'dropout1': 0.7316807270612511, 'dropout2': 0.0959349217522123, 'layers': 1}. Best is trial 0 with value: 0.7784214009208312.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:24:55,368]\u001b[0m Trial 2 finished with value: 0.8103802993455476 and parameters: {'alpha': 0.311585004754835, 'gamma': 1.6331470035502957, 'noise': 0.010944117703824944, 'neurons': 601, 'relu': 'Leaky', 'dropout1': 0.1182550826885479, 'dropout2': 0.2615881190616758, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:25:13,382]\u001b[0m Trial 3 finished with value: 0.8059028884699518 and parameters: {'alpha': 0.9264772208544841, 'gamma': 1.527595600640471, 'noise': 2.0850404789549663e-05, 'neurons': 2100, 'relu': 'Leaky', 'dropout1': 0.22254854794099577, 'dropout2': 0.27492546945279595, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:25:59,177]\u001b[0m Trial 4 finished with value: 0.7995873685537573 and parameters: {'alpha': 0.11698258203387525, 'gamma': 1.1751839680590397, 'noise': 0.01465226812890616, 'neurons': 3233, 'relu': 'Leaky', 'dropout1': 0.807505684948393, 'dropout2': 0.5446708706421869, 'layers': 3}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:26:54,585]\u001b[0m Trial 5 finished with value: 0.8042968924772459 and parameters: {'alpha': 0.5900566720469496, 'gamma': 2.340593052890737, 'noise': 0.13689969874568111, 'neurons': 3583, 'relu': 'Leaky', 'dropout1': 0.6422181803306776, 'dropout2': 0.4235647850495463, 'layers': 3}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:27:00,526]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:27:11,062]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:27:34,428]\u001b[0m Trial 8 finished with value: 0.8010483942837292 and parameters: {'alpha': 0.04989183216072559, 'gamma': 3.1475255932246577, 'noise': 2.5502658145169196e-05, 'neurons': 2481, 'relu': 'relu', 'dropout1': 0.15445060975970448, 'dropout2': 0.6687352406473887, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:06,119]\u001b[0m Trial 9 finished with value: 0.8022862287054907 and parameters: {'alpha': 0.7027085754751794, 'gamma': 3.1731354779037186, 'noise': 4.469554821700723e-05, 'neurons': 2441, 'relu': 'Leaky', 'dropout1': 0.4232997130667957, 'dropout2': 0.294663260986165, 'layers': 3}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:15,557]\u001b[0m Trial 10 finished with value: 0.7674004034246257 and parameters: {'alpha': 0.3170418917459874, 'gamma': 2.301362784031487, 'noise': 0.0007214466635676913, 'neurons': 1227, 'relu': 'Leaky', 'dropout1': 0.05512131826515716, 'dropout2': 0.9957577304110634, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:27,470]\u001b[0m Trial 11 finished with value: 0.8087061905692572 and parameters: {'alpha': 0.8808713739224046, 'gamma': 1.8441574636468667, 'noise': 0.019214600897449387, 'neurons': 1540, 'relu': 'Leaky', 'dropout1': 0.31426066408740805, 'dropout2': 0.0223733431787701, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:38,434]\u001b[0m Trial 12 finished with value: 0.8052610308303221 and parameters: {'alpha': 0.3640540587158586, 'gamma': 2.1330558308925482, 'noise': 0.021055660864009836, 'neurons': 1357, 'relu': 'Leaky', 'dropout1': 0.36238307122960733, 'dropout2': 0.04535067441991214, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:44,615]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:28:52,595]\u001b[0m Trial 14 finished with value: 0.8089969906489769 and parameters: {'alpha': 0.3647924157276793, 'gamma': 1.0813341371418115, 'noise': 0.0019358464173201125, 'neurons': 896, 'relu': 'Leaky', 'dropout1': 0.006513682794136874, 'dropout2': 0.15602678595030972, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:29:00,199]\u001b[0m Trial 15 finished with value: 0.8038121380563914 and parameters: {'alpha': 0.26007733005016725, 'gamma': 1.0575104434885114, 'noise': 0.0010382624868392149, 'neurons': 767, 'relu': 'Leaky', 'dropout1': 0.022510991151388424, 'dropout2': 0.16670131387968068, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:29:04,566]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:29:57,619]\u001b[0m Trial 17 finished with value: 0.8076844835911174 and parameters: {'alpha': 0.4660923216421815, 'gamma': 2.7520182603429206, 'noise': 0.00021182063022589257, 'neurons': 4095, 'relu': 'Leaky', 'dropout1': 0.007320154963744421, 'dropout2': 0.186226031840313, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:08,337]\u001b[0m Trial 18 finished with value: 0.8039310774672808 and parameters: {'alpha': 0.19804362616178736, 'gamma': 1.4485339649180138, 'noise': 0.07119810064273241, 'neurons': 1811, 'relu': 'relu', 'dropout1': 0.16875411496242695, 'dropout2': 0.4089094484853999, 'layers': 1}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:16,147]\u001b[0m Trial 19 finished with value: 0.789673565871595 and parameters: {'alpha': 0.5071431105423267, 'gamma': 1.1299878248629465, 'noise': 0.002992256823875134, 'neurons': 88, 'relu': 'Leaky', 'dropout1': 0.49471176963283253, 'dropout2': 0.15592180040040465, 'layers': 3}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:24,617]\u001b[0m Trial 20 finished with value: 0.8097491827506904 and parameters: {'alpha': 0.19363303362176082, 'gamma': 1.7627216209306062, 'noise': 0.0004259843496669337, 'neurons': 1040, 'relu': 'Leaky', 'dropout1': 0.09144885255405043, 'dropout2': 0.3301399785766488, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:32,002]\u001b[0m Trial 21 finished with value: 0.8072518388915586 and parameters: {'alpha': 0.19991608090509488, 'gamma': 1.630732382712641, 'noise': 0.00031086340397239474, 'neurons': 827, 'relu': 'Leaky', 'dropout1': 0.10308284821373953, 'dropout2': 0.2983121780264143, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:40,494]\u001b[0m Trial 22 finished with value: 0.807351424303648 and parameters: {'alpha': 0.2467067531415221, 'gamma': 1.0012238255881005, 'noise': 0.0012050839795278176, 'neurons': 1036, 'relu': 'Leaky', 'dropout1': 0.23045328727080333, 'dropout2': 0.3526849473873669, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:30:47,736]\u001b[0m Trial 23 finished with value: 0.8040272212092788 and parameters: {'alpha': 0.13468602831419357, 'gamma': 1.9024064020379456, 'noise': 0.00651575023028331, 'neurons': 521, 'relu': 'Leaky', 'dropout1': 0.08705552804528721, 'dropout2': 0.21684249406465675, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:03,179]\u001b[0m Trial 24 finished with value: 0.8060568922328024 and parameters: {'alpha': 0.3471212219681593, 'gamma': 1.335938030079951, 'noise': 0.00011844414616014954, 'neurons': 1782, 'relu': 'Leaky', 'dropout1': 0.18363236651922427, 'dropout2': 0.11504130612579111, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:10,511]\u001b[0m Trial 25 finished with value: 0.8081774227070067 and parameters: {'alpha': 0.4602321623937521, 'gamma': 2.8048736062532207, 'noise': 0.0004778834841033024, 'neurons': 514, 'relu': 'Leaky', 'dropout1': 0.36205427942095814, 'dropout2': 0.4808698833224718, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-25 12:31:14,982]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:22,316]\u001b[0m Trial 27 finished with value: 0.8050862663465211 and parameters: {'alpha': 0.2936092610499125, 'gamma': 2.1522674932396395, 'noise': 0.001424193834466861, 'neurons': 382, 'relu': 'Leaky', 'dropout1': 0.0949234713581486, 'dropout2': 0.21849333531346837, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:27,003]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:36,713]\u001b[0m Trial 29 finished with value: 0.8071204869735973 and parameters: {'alpha': 0.3833317996472958, 'gamma': 3.6163308153789684, 'noise': 0.0022179957144673325, 'neurons': 1015, 'relu': 'relu', 'dropout1': 0.4219558341502469, 'dropout2': 0.8957833437758875, 'layers': 3}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:43,809]\u001b[0m Trial 30 finished with value: 0.8074413822001207 and parameters: {'alpha': 0.539274368673208, 'gamma': 2.0519693133751087, 'noise': 0.01040838562984035, 'neurons': 566, 'relu': 'Leaky', 'dropout1': 0.2938425754136455, 'dropout2': 0.6380649101657627, 'layers': 1}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:31:55,698]\u001b[0m Trial 31 finished with value: 0.8098200344272161 and parameters: {'alpha': 0.7979971397104544, 'gamma': 1.88002502867165, 'noise': 0.038383922853968744, 'neurons': 1468, 'relu': 'Leaky', 'dropout1': 0.3221402371432731, 'dropout2': 0.00734445786801608, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:32:08,894]\u001b[0m Trial 32 finished with value: 0.8060510338837922 and parameters: {'alpha': 0.7798290908729709, 'gamma': 1.7034340498610225, 'noise': 0.058251390733738286, 'neurons': 1584, 'relu': 'Leaky', 'dropout1': 0.17109909753166896, 'dropout2': 0.07792427086878811, 'layers': 2}. Best is trial 2 with value: 0.8103802993455476.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:32:15,581]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:32:34,759]\u001b[0m Trial 34 finished with value: 0.8144533992665929 and parameters: {'alpha': 0.41423899852781415, 'gamma': 4.605796260288279, 'noise': 0.03653895338824281, 'neurons': 2117, 'relu': 'Leaky', 'dropout1': 0.09197427109578823, 'dropout2': 0.10944076754797236, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:32:51,893]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:33:02,125]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:33:36,185]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:33:44,089]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:01,576]\u001b[0m Trial 39 finished with value: 0.8056915216783571 and parameters: {'alpha': 0.7894450653889757, 'gamma': 4.550594008219631, 'noise': 0.030860265304696953, 'neurons': 1992, 'relu': 'relu', 'dropout1': 0.7476731424822767, 'dropout2': 0.3557448215058535, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:13,460]\u001b[0m Trial 40 finished with value: 0.8096754211790042 and parameters: {'alpha': 0.07267976819703592, 'gamma': 4.256465541377807, 'noise': 0.08570904361615997, 'neurons': 1460, 'relu': 'Leaky', 'dropout1': 0.416481289479394, 'dropout2': 0.14296696341036763, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:26,561]\u001b[0m Trial 41 finished with value: 0.8063729958091604 and parameters: {'alpha': 0.09644245288907383, 'gamma': 4.434630736928382, 'noise': 0.1146217504691089, 'neurons': 1552, 'relu': 'Leaky', 'dropout1': 0.46365799360773413, 'dropout2': 0.11374413042560796, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:38,402]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:49,528]\u001b[0m Trial 43 finished with value: 0.808134747233012 and parameters: {'alpha': 0.15911126475836357, 'gamma': 4.044714349659401, 'noise': 0.013932911911540663, 'neurons': 1337, 'relu': 'Leaky', 'dropout1': 0.2666091631054961, 'dropout2': 8.260975833715434e-05, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:34:57,610]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:35:09,986]\u001b[0m Trial 45 finished with value: 0.746201083867925 and parameters: {'alpha': 0.22484572107868103, 'gamma': 4.64890834874434, 'noise': 0.08274908168518243, 'neurons': 1228, 'relu': 'Leaky', 'dropout1': 0.8936380897365902, 'dropout2': 0.05908928221167152, 'layers': 3}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:35:33,628]\u001b[0m Trial 46 finished with value: 0.8097847629377726 and parameters: {'alpha': 0.3241176135655977, 'gamma': 3.770376640769915, 'noise': 0.004258278971949467, 'neurons': 2327, 'relu': 'Leaky', 'dropout1': 0.13711248134089737, 'dropout2': 0.19956680013150882, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:35:45,352]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:36:16,996]\u001b[0m Trial 48 finished with value: 0.8090998268052723 and parameters: {'alpha': 0.4076776789402151, 'gamma': 3.345220030587715, 'noise': 0.004594135409940593, 'neurons': 2988, 'relu': 'Leaky', 'dropout1': 0.06617946616153086, 'dropout2': 0.19762365939899482, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:36:34,976]\u001b[0m Trial 49 finished with value: 0.8077725118398592 and parameters: {'alpha': 0.30462785951606247, 'gamma': 2.299522673623219, 'noise': 0.003886194984574863, 'neurons': 2673, 'relu': 'Leaky', 'dropout1': 0.1422105880295666, 'dropout2': 0.46028402879470853, 'layers': 1}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:36:57,718]\u001b[0m Trial 50 finished with value: 0.8071155739970869 and parameters: {'alpha': 0.6240393720850497, 'gamma': 2.9765709462492334, 'noise': 0.0006080457637183028, 'neurons': 2308, 'relu': 'relu', 'dropout1': 0.21515718448255833, 'dropout2': 0.5664808907317577, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:37:15,025]\u001b[0m Trial 51 finished with value: 0.8106529221995554 and parameters: {'alpha': 0.1708147013717529, 'gamma': 4.250872346048634, 'noise': 0.04380200523027888, 'neurons': 1906, 'relu': 'Leaky', 'dropout1': 0.059370870022486255, 'dropout2': 0.16047289545356316, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:37:28,414]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:37:38,349]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:37:56,398]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:38:10,788]\u001b[0m Trial 55 finished with value: 0.8115419029331541 and parameters: {'alpha': 0.8970754022186295, 'gamma': 1.5472961207991547, 'noise': 0.01152944824589598, 'neurons': 1698, 'relu': 'Leaky', 'dropout1': 0.254238947980602, 'dropout2': 0.1939431751007705, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:38:24,094]\u001b[0m Trial 56 finished with value: 0.8065978484995198 and parameters: {'alpha': 0.9231278226495523, 'gamma': 1.509553148128762, 'noise': 0.013081901836825253, 'neurons': 1707, 'relu': 'Leaky', 'dropout1': 0.269513440122115, 'dropout2': 0.18323456903761648, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:38:42,225]\u001b[0m Trial 57 finished with value: 0.8082576475653479 and parameters: {'alpha': 0.9927313113513461, 'gamma': 1.362425412821716, 'noise': 0.020376746423351074, 'neurons': 2266, 'relu': 'Leaky', 'dropout1': 0.24091897011942556, 'dropout2': 0.1277779245059111, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:38:55,677]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:39:02,522]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:39:20,211]\u001b[0m Trial 60 finished with value: 0.8079250423251274 and parameters: {'alpha': 0.7169016834345595, 'gamma': 2.0065539679676707, 'noise': 0.051326002566886055, 'neurons': 2094, 'relu': 'Leaky', 'dropout1': 0.2004942046046274, 'dropout2': 0.016188501429978484, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:39:38,034]\u001b[0m Trial 61 finished with value: 0.809464390171702 and parameters: {'alpha': 0.23477921566777546, 'gamma': 1.8006162775476946, 'noise': 0.00556177237601593, 'neurons': 1934, 'relu': 'Leaky', 'dropout1': 0.08505239662163211, 'dropout2': 0.21718259824049396, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-25 12:39:42,455]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:39:50,464]\u001b[0m Trial 63 finished with value: 0.8052363302166187 and parameters: {'alpha': 0.9030302899613789, 'gamma': 1.2535753454094634, 'noise': 0.003369581327531934, 'neurons': 677, 'relu': 'Leaky', 'dropout1': 0.052478267756533824, 'dropout2': 0.29580316984857835, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:02,964]\u001b[0m Trial 64 finished with value: 0.8056164761161466 and parameters: {'alpha': 0.853778149709454, 'gamma': 1.4808549427611468, 'noise': 0.023565356705681027, 'neurons': 1440, 'relu': 'Leaky', 'dropout1': 0.16770561188494573, 'dropout2': 0.16179944786848877, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:12,251]\u001b[0m Trial 65 finished with value: 0.807345298960796 and parameters: {'alpha': 0.7201831780962658, 'gamma': 1.6438888118794643, 'noise': 0.04308078584026952, 'neurons': 970, 'relu': 'Leaky', 'dropout1': 0.03635320768356633, 'dropout2': 0.7522301908178843, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:26,723]\u001b[0m Trial 66 finished with value: 0.804721426705903 and parameters: {'alpha': 0.3222339083816248, 'gamma': 1.1933391419801682, 'noise': 0.0018505383356042157, 'neurons': 1676, 'relu': 'Leaky', 'dropout1': 0.1385219080074288, 'dropout2': 0.24491829344246827, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:31,913]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:40,303]\u001b[0m Trial 68 finished with value: 0.8128419910167489 and parameters: {'alpha': 0.4150195518676073, 'gamma': 1.912255144785804, 'noise': 0.0008441342908176603, 'neurons': 888, 'relu': 'relu', 'dropout1': 0.22820597577343021, 'dropout2': 0.4371349420322346, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:48,132]\u001b[0m Trial 69 finished with value: 0.8101953013456902 and parameters: {'alpha': 0.41904750653379647, 'gamma': 1.9460012018637305, 'noise': 0.000729932517370856, 'neurons': 649, 'relu': 'relu', 'dropout1': 0.23280350468968058, 'dropout2': 0.44605607004829323, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:53,263]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:40:57,334]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:41:05,584]\u001b[0m Trial 72 finished with value: 0.8089566121249423 and parameters: {'alpha': 0.5213533260272911, 'gamma': 2.628693084417868, 'noise': 0.0014443689075043457, 'neurons': 644, 'relu': 'relu', 'dropout1': 0.20670732782712042, 'dropout2': 0.6587115907380893, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:41:23,819]\u001b[0m Trial 73 finished with value: 0.8097297883968149 and parameters: {'alpha': 0.4819843873115729, 'gamma': 1.8458272081620537, 'noise': 0.015471971580167753, 'neurons': 1894, 'relu': 'relu', 'dropout1': 0.3683298543788112, 'dropout2': 0.5983561719183274, 'layers': 2}. Best is trial 34 with value: 0.8144533992665929.\u001b[0m\n",
      "\u001b[32m[I 2022-02-25 12:41:31,565]\u001b[0m Trial 74 pruned. \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-60-c5aaf5aa3c0c&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">201</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">study.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">409</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimize</span>   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 â”‚   â”‚   â”‚   </span>catch=catch,                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 â”‚   â”‚   â”‚   </span>callbacks=callbacks,                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 â”‚   â”‚   â”‚   </span>gc_after_trial=gc_after_trial,                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 409 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>show_progress_bar=show_progress_bar,                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 â”‚   â”‚   </span>)                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 â”‚   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ask</span>(                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_optimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">76</span> in         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_optimize</span>                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 â”‚   â”‚   â”‚   â”‚   </span>gc_after_trial,                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 â”‚   â”‚   â”‚   â”‚   </span>reseed_sampler_rng=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 â”‚   â”‚   â”‚   â”‚   </span>time_start=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 76 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>progress_bar=progress_bar,                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 â”‚   â”‚   â”‚   </span>)                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> show_progress_bar:                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_optimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">163</span> in        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_optimize_sequential</span>                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 â”‚   â”‚   </span>                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>163 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>trial = _run_trial(study, func, catch)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_optimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">213</span> in        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run_trial</span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 â”‚   â”‚   </span>thread.start()                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 â”‚   </span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>213 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>value_or_values = func(trial)                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> exceptions.TrialPruned <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 â”‚   â”‚   # TODO(mamu): Handle multi-objective cases.</span>                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 â”‚   â”‚   </span>state = TrialState.PRUNED                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-60-c5aaf5aa3c0c&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">142</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">objective</span>                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1102</span> in      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1099 â”‚   â”‚   # this function, and just call forward.</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1100 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1101 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1103 â”‚   â”‚   # Do not call functions when jit is used</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1104 â”‚   â”‚   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1105 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/kornia/losses/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">focal.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.eps: Optional[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span>] = eps                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 â”‚   </span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: torch.Tensor, target: torch.Tensor) -&gt; torch.Tensor:   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>150 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> focal_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.alpha, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gamma, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 </span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 </span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_focal_loss_with_logits</span>(                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/kornia/losses/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">focal.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">91</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">focal_loss</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 â”‚   </span>weight = torch.pow(-input_soft + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>, gamma)                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89 â”‚   </span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 90 â”‚   </span>focal = -alpha * weight * log_input_soft                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 91 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>loss_tmp = torch.einsum(<span style=\"color: #808000; text-decoration-color: #808000\">'bc...,bc...-&gt;b...'</span>, (target_one_hot, focal))           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 â”‚   </span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> reduction == <span style=\"color: #808000; text-decoration-color: #808000\">'none'</span>:                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 â”‚   â”‚   </span>loss = loss_tmp                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/karol/anaconda3/lib/python3.7/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">325</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 322 â”‚   â”‚   </span>_operands = operands[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 323 â”‚   â”‚   # recurse incase operands contains value that has torch function</span>           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 324 â”‚   â”‚   # in the original implementation this line is omitted</span>                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 325 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> einsum(equation, *_operands)                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 326 â”‚   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 327 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _VF.einsum(equation, operands)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[attr-defined]</span>            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 328 </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91mâ•­â”€\u001b[0m\u001b[91mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[91m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[91mâ”€â•®\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[33m<ipython-input-60-c5aaf5aa3c0c>\u001b[0m:\u001b[94m201\u001b[0m in \u001b[92m<module>\u001b[0m                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/\u001b[0m\u001b[1;33mstudy.py\u001b[0m:\u001b[94m409\u001b[0m in \u001b[92moptimize\u001b[0m   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mcatch=catch,                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mcallbacks=callbacks,                                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mgc_after_trial=gc_after_trial,                                         \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 409 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0mshow_progress_bar=show_progress_bar,                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                                          \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                               \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mask\u001b[0m(                                                                       \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/\u001b[0m\u001b[1;33m_optimize.py\u001b[0m:\u001b[94m76\u001b[0m in         \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[92m_optimize\u001b[0m                                                                                 \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mgc_after_trial,                                                     \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mreseed_sampler_rng=\u001b[94mFalse\u001b[0m,                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mtime_start=\u001b[94mNone\u001b[0m,                                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 76 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mprogress_bar=progress_bar,                                          \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m)                                                                       \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                                       \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m show_progress_bar:                                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/\u001b[0m\u001b[1;33m_optimize.py\u001b[0m:\u001b[94m163\u001b[0m in        \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[92m_optimize_sequential\u001b[0m                                                                      \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mbreak\u001b[0m                                                               \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                            \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mtry\u001b[0m:                                                                        \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m163 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0mtrial = _run_trial(study, func, catch)                                  \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m                                                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/optuna/study/\u001b[0m\u001b[1;33m_optimize.py\u001b[0m:\u001b[94m213\u001b[0m in        \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[92m_run_trial\u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mthread.start()                                                              \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mtry\u001b[0m:                                                                            \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m213 \u001b[2mâ”‚   â”‚   \u001b[0mvalue_or_values = func(trial)                                               \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mexcept\u001b[0m exceptions.TrialPruned \u001b[94mas\u001b[0m e:                                             \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# TODO(mamu): Handle multi-objective cases.\u001b[0m                                 \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mstate = TrialState.PRUNED                                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[33m<ipython-input-60-c5aaf5aa3c0c>\u001b[0m:\u001b[94m142\u001b[0m in \u001b[92mobjective\u001b[0m                                          \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1102\u001b[0m in      \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1099 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1100 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1101 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1102 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1103 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1104 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m1105 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/kornia/losses/\u001b[0m\u001b[1;33mfocal.py\u001b[0m:\u001b[94m150\u001b[0m in \u001b[92mforward\u001b[0m   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.eps: Optional[\u001b[96mfloat\u001b[0m] = eps                                             \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: torch.Tensor, target: torch.Tensor) -> torch.Tensor:   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m150 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m focal_loss(\u001b[96minput\u001b[0m, target, \u001b[96mself\u001b[0m.alpha, \u001b[96mself\u001b[0m.gamma, \u001b[96mself\u001b[0m.reduction, \u001b[96mse\u001b[0m \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m151 \u001b[0m                                                                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m152 \u001b[0m                                                                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m153 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_focal_loss_with_logits\u001b[0m(                                                  \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/kornia/losses/\u001b[0m\u001b[1;33mfocal.py\u001b[0m:\u001b[94m91\u001b[0m in \u001b[92mfocal_loss\u001b[0m \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[2mâ”‚   \u001b[0mweight = torch.pow(-input_soft + \u001b[94m1.0\u001b[0m, gamma)                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 90 \u001b[0m\u001b[2mâ”‚   \u001b[0mfocal = -alpha * weight * log_input_soft                                        \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 91 \u001b[2mâ”‚   \u001b[0mloss_tmp = torch.einsum(\u001b[33m'\u001b[0m\u001b[33mbc...,bc...->b...\u001b[0m\u001b[33m'\u001b[0m, (target_one_hot, focal))           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m reduction == \u001b[33m'\u001b[0m\u001b[33mnone\u001b[0m\u001b[33m'\u001b[0m:                                                         \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mloss = loss_tmp                                                             \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[2;33m/home/karol/anaconda3/lib/python3.7/site-packages/torch/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m325\u001b[0m in \u001b[92meinsum\u001b[0m       \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m                                                                                           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 322 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m_operands = operands[\u001b[94m0\u001b[0m]                                                    \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# recurse incase operands contains value that has torch function\u001b[0m           \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# in the original implementation this line is omitted\u001b[0m                      \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 325 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m einsum(equation, *_operands)                                        \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 326 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                               \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 327 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m _VF.einsum(equation, operands)  \u001b[2m# type: ignore[attr-defined]\u001b[0m            \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ”‚\u001b[0m   \u001b[2m 328 \u001b[0m                                                                                   \u001b[91mâ”‚\u001b[0m\n",
       "\u001b[91mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "#     smoothing=trial.suggest_float(\"smoothing\", 1e-7, 1e-1, log=True)\n",
    "#     criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "\n",
    "    kwargs = {\"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.999), \"gamma\": trial.suggest_float(\"gamma\", 1,5), \"reduction\": 'mean'}\n",
    "    criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "\n",
    "\n",
    "    class NetDDDOptuna(nn.Module):\n",
    "        def __init__(self,cfg):\n",
    "            super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "            self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "            sz = cfg['neurons']\n",
    "            \n",
    "            if cfg['relu']=='relu':\n",
    "                relu=nn.ReLU\n",
    "            else:\n",
    "                relu=nn.LeakyReLU\n",
    "\n",
    "                \n",
    "            if cfg['layers']==1:\n",
    "                self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                       nn.Dropout(cfg['dropout1']),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(sz,512),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(512,64),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(64,sz),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "    #                                    nn.Linear(2048,2048),\n",
    "    #                                    nn.LeakyReLU(),\n",
    "                                       nn.Dropout(cfg['dropout2']),\n",
    "                                       nn.Linear(sz,3))\n",
    "\n",
    "            if cfg['layers']==2:\n",
    "                self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                       nn.Dropout(cfg['dropout1']),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "                                       nn.Dropout(cfg['dropout2']),\n",
    "                                       nn.Linear(sz,3))\n",
    "\n",
    "            if cfg['layers']==3:\n",
    "                self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                       nn.Dropout(cfg['dropout1']),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "                                       nn.Linear(sz,sz),\n",
    "                                       relu(),\n",
    "                                       nn.Dropout(cfg['dropout2']),\n",
    "                                       nn.Linear(sz,3))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.n(x)\n",
    "            return self.m(x)\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = 500#trial.suggest_int(\"batch_size\", 1, 5000)\n",
    "    train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "    val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "        \n",
    "    \n",
    "    noise =trial.suggest_float(\"noise\", 1e-5, 1, log=True)\n",
    "    neurons = trial.suggest_int(\"neurons\", 8, 4096)\n",
    "    relu = trial.suggest_categorical(\"relu\", [\"relu\", \"Leaky\"])\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0,1)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0,1)\n",
    "        \n",
    "    cfg={'noise': noise,\n",
    "         'neurons': neurons,\n",
    "         'relu': relu,\n",
    "         'dropout1': dropout1,\n",
    "         'dropout2': dropout2,\n",
    "         'layers': trial.suggest_categorical(\"layers\", [1,2,3])\n",
    "    }\n",
    "    \n",
    "    train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "    val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    lr = 3e-4#trial.suggest_float(\"lr\", 1e-7, 3, log=True)\n",
    "\n",
    "\n",
    "\n",
    "    unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "    #     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "\n",
    "\n",
    "    clip_value = 1\n",
    "\n",
    "    model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.register_hook(lambda grad: torch.clamp(grad, -clip_value, clip_value))\n",
    "\n",
    "    ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "#     optimizer = AdaHessian(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                    max_lr=lr,\n",
    "                                                    steps_per_epoch=len(train_loader),\n",
    "                                                    epochs=epochs, pct_start=0.3, div_factor=1000, final_div_factor=1000)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5, 2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00001, max_lr=0.3, mode='triangular2',step_size_up=20)\n",
    "\n",
    "#     lr = lr/10\n",
    "\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    train_accs=[]\n",
    "    val_accs=[]\n",
    "    val_f1s = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        correct=0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()  #normal 1st order opt\n",
    "#             loss.backward(create_graph=True) # adahessian\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            ema.update()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            train_loss+=loss.item()\n",
    "    #     scheduler.step()\n",
    "        train_loss/=len(train_loader)\n",
    "        acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        val_f1 = 0\n",
    "        with torch.no_grad():\n",
    "            with ema.average_parameters():\n",
    "                for data, target in val_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    vl=criterion(output, target).item()\n",
    "                    val_loss += vl\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                    val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "        val_loss /= float(len(val_loader))\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "        val_f1 /= float(len(val_loader))\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        logs={}\n",
    "        logs['train_loss'] = train_loss\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['train_acc'] = acc\n",
    "    #     logs['val_acc'] = val_acc\n",
    "        logs['val_f1'] = val_f1\n",
    "\n",
    "    \n",
    "        trial.report(val_f1, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return max(val_f1s)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='sentiment-focal-radam-final-max-500', storage='sqlite:///example.db', load_if_exists=True,\n",
    "                           pruner=optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=10))\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAANYCAYAAADZn0yoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADBT0lEQVR4nOzdd3xd9X3/8ddHe2/JS5Yl74WxsbHZmwQycAaEkZAdkhSaJk3TkjalhF/blDargyYlDQkhBEIIBJOYUcIGAx7YxnvIsiV5aO95db+/P+6VIwvZkqwrnTvez8dDD9977rnnfO61pKP3/S5zziEiIiIiIiJjF+d1ASIiIiIiItFCAUtERERERCREFLBERERERERCRAFLREREREQkRBSwREREREREQkQBS0REREREJEQUsEQmkJnNM7PNZtZqZl/xuh4RERERCS0FLJGJ9dfAC865TOAdM3vBzJrNrMLjukREJEaZWYWZXeF1HSLRQgFLZGLNALYHb7cD9wHf8K4cEREREQklBSyRCWJmzwOXAv9lZm1Ak3PuAaDc28pEREROZGbJZvZDMzsc/PqhmSUHHysws9+bWZOZNZjZK2YWF3zsb8ysOtgVfreZXe7tKxGZeApYIhPEOXcZ8Apwm3Muwzm3x+uaRERETuLvgHOApcCZwErgW8HHvg5UAYXAJOBvAWdm84DbgLODXeHfC1RMaNUiYUABS0REREQG+zhwl3OuxjlXC3wbuDn4WC8wBZjhnOt1zr3inHNAH5AMLDSzROdchXNuvyfVi3hIAUtEREREBpsKHBxw/2BwG8C/AfuAZ82s3MxuB3DO7QO+CtwJ1JjZw2Y2FZEYo4AlIiIiIoMdJjAxU7+S4Dacc63Oua8752YC1wB/2T/Wyjn3K+fcBcHnOuDuiS1bxHsKWCIeMbM4M0sBEgN3LcXMkryuS0REYlJi8DqUErw2PQR8y8wKzawAuAP4JYCZfcDMZpuZAc0Eugb6g2s9XhacDKML6AT83rwcEe8oYIl45yICF5+1BD4Z7ASe9bQiERGJVWsJXIf6v1KADcBW4B1gE/CPwX3nAM8BbcA64L+dcy8QGH/1L0AdcBQoAr45cS9BJDxYYEyiiIiIiIiIjJVasEREREREREJEAUtERERERCREFLBERERERERCRAFLREREREQkRBK8OnFBQYErLS316vQiIhJmNm7cWOecK/S6jpPRdUtERAY62XXLs4BVWlrKhg0bvDq9iIiEGTM76HUNp6LrloiIDHSy65a6CIqIiIiIiISIApaIiEQkM7vKzHab2T4zu32Ix5PN7NfBx980s9Lg9iQz+5mZvWNmW8zskgkuXUREopgCloiIRBwziwfuAa4GFgI3mtnCQbt9Dmh0zs0GfgDcHdz+BQDn3BnAlcD3zEzXQxERCQldUEREJBKtBPY558qdcz3Aw8DqQfusBu4P3n4UuNzMjEAgex7AOVcDNAErJqJoERGJfgpYIiISiaYBlQPuVwW3DbmPc84HNAP5wBbgGjNLMLMyYDkwfaiTmNktZrbBzDbU1taG+CWIiEg0UsASEZFYcx+BQLYB+CHwOtA31I7OuXudcyuccysKC8N2BnkREQkjnk3TLiIiMgbVnNjqVBzcNtQ+VWaWAGQD9c45B3ytfyczex3YM77liohIrFALloiIRKL1wBwzKzOzJOAGYM2gfdYAnwrevhZ43jnnzCzNzNIBzOxKwOec2zFRhYuISHRTC5aIiEQc55zPzG4DngHigfucc9vN7C5gg3NuDfBT4AEz2wc0EAhhAEXAM2bmJ9DKdfPEvwIREYlWClgiIhKRnHNrgbWDtt0x4HYXcN0Qz6sA5o13fSIiEpvURVBERERERCREFLBERERERERCRAFLREREREQkRBSwREREREREQkSTXIiMgN/veH1/PS/vraUoM5lZRRnMLsygMDOZ+Dgjzow4AzPzulQRERGRmOWco6XLR31bN40dPTR19NLU0Utz55++Fk3N4roV04c/2GlSwBLPVTZ0cKCunY6ePi6dX0hyQjwQCDU/emk/b5TXU9PSTUFmEnOKMvnQsmksnZ4z7HGbO3u5//UKGjt6mJGXxoyCdIoyk6lu7KSly0dZQRrOwe5jraQlxTO7MJOZhenExxnP76rhnepm2rt9HGroYFt1C3Vt3STEGT6/G/J8ZjA9N405RRnMmZTJtNxU4obJW5kpicwqTCcnLSlwjOBxDAv+G9jYf79/n+TEeDKS9eM73nx9fnx+R0pivNeliIiIxCy/39HQ0cPR5i6ONndR19ZNfXsP9W091Ld309DeQ11bDw3B2719Q/+tBpCZnIDfTVPAkujhnOOtAw28vLeW5s5eNlQ0suto6/HHL5hdwP/cvJzkhDj++tGtPPZ2NYumZjE9L426tm5+vb6Sn79ewdLpOfz9BxawaGo2bx1ooKWrlz6/Y+eRVg7UtdHnh/UVDTR39pKWFE9HT9+Ia0yKj6Onz09CnJGRksDkrBQunFPAZfOLuHLhJDp6+thf28a+mjYa2ntwzuF30OPzc6C+nb3HWnl5b+0pf7hDoTAzmVmF6cwqzCA3GNCGkp2aSFlBOq3dvVTUdeDz+0943Dk42tzFvto2unoD75MFoh1DNciZGUnxRllBOnMmZTKnKIPePsfemlayUxMpLUgnOT7Y+/h4KHz38QxIT05gdlEGfucor22ns/fU/0++PkdlYwdVjZ34TxJ0x6rX7+dQfQf7a9uoqOug1++nND+d/PQkzGBaTiqzizJISjh1D+vE+DhK89OZnJ1CXIhbNnt8fvbXtlHV2IFzkJGSwMzCDHJSE0N6npGKjzMWT8v25NwiIhL5mjt7qWzo4FBDB4ebOgNBqqXr+L/HWrqG/LsqPSme/Ixk8tKTmJaTwhnTssjPSCY/PYn8jCRy05LISUsiJzWR7NREMlMSSIgf/xFS5tzwf6SY2VXAvxNYzPF/nXP/MujxEuB+ICe4z+3B9UlOasWKFW7Dhg2nWbaEM+ccmyubSE6IZ+HULACaOnp4dscxHllfyYaDjcTHGZkpCcwpyuCqxVNYUpzNnmOt3PHEdiZnpdDt81PX1s1fXjmXP79s9vGud61dvTz+djX//cJ+jrZ0kZIYR1fvnwJDYrxRmp9OQnwcJXmpfOXyOSyckkVdWw8H69s51tLNtNxUslMTqahrx+GYOymTzmBo2l/bTmN7D5fNL2LVzHzih2uCOonePj+N7T3D7tfY0cv+2jbaunw4HM5B/09k4PaAbc7hgtvbe3wcqG0/XnNbt++k/xcDc4gZxA/xx35BRjJzJmWQkZxA/68Ex5+e+KdtAf3v15HmrmFf43DijOOva6TMCHloGVhPcW4aswozmFWUTnJCPHuPtR4P8YfqOzgcgtcdTQoyktnwrSvGfBwz2+icWxGCksaFrlsiIqenz++obuykor6dQw0dVDZ0UNkYCFSH6jto6Trx75iUxDgmZ6UwOTsl+G8qk7OSA/9mp1CUGQhVXvcwOdl1a9gWLDOLB+4BrgSqgPVmtsY5t2PAbt8CHnHO/cjMFhJY+LE0JJVLxGjv9vGrNw/xizcqqGzoxAy+cOFM/H7HL944SI/Pz/S8VL59zSKuP3v6u34ozi7NY1JmCvevq2BSVgoXzy3kg2dOPWGfzJREPnluKR89q5ifvnqAhvYeLplXyNScVAwoyU873sVwoMLMZAozk0/YVlaQfsL9OZMyQ/NGEGi9KMpKGXa/oqwU5k0O3XmH0tTRQ3ldO1kpCZTkpQ/b8jIaLV297KtpIyk+jtlFGbR0BT6B8vW5E4IinBjY+m82dfay62grcQbzJmWSmXLqFpj+FqTi3NQJ+QTqZLp6++gbpgWtq7ePA3Xt1LR2h/z8cRZoQZyRn0ZCnNHY0Ut5bRvtPUMH7fGWFK8ulCIiAt2+PsqDHwDvqwl87a9tp7y2jW7fnz4QT4qPozg3lel5aSybnsv0vFRK8tIozk1jWk4qOWmJET2ufSRdBFcC+5xz5QBm9jCwGhgYsByQFbydDRwOZZEycQ7Vd/D8rmM0dPQyJTuF1UunkpZ06m+Tlq5efvF6BT999QCNHb2sKsvjLy6fy6ZDjdz7cjlxBh85q5ibz5nBkuLsU/7AXLFwElcsnDRsnenJCXzl8jmjfn2xKCctibNKTt6FcCyyUhI5qyT3+P2UxHiKMocPlgO974wpoS5r3I3kE7P05ATyM5KH3S8UhvoAQUREZDy1dfvYcbiF7Yeb2X64hW3VzeyraTs+Vt0MinNTmV2YwQWz85lVmEFZQTol+WlMykwh7jR7CUWCkQSsaUDlgPtVwKpB+9wJPGtmfw6kA0P2FTGzW4BbAEpKSkZbq4yDjh4fD6w7SFNnLzUt3TyxufqESRy+s3Ynq2bmMz03jYvnFbKqLI8dR1p4o7yeN8ob2HeslaMtXfgdXDa/iFsvnc3yGYE/uK9dXszqM6eSn5HM7KIMr16iiIiIiIxBb5+fXUda2XiwgY2HmthW3cyBuvbjjxdkJLNoahaXLyhi3uQsZhdmMLMw3fMufF4J1SQXNwI/d859z8zOBR4ws8XOuRNG0zvn7gXuhUBf9hCdW06Dc44Xd9dyx5ptVDZ0khQfhxnctKqEL1w4k6k5qWyubOSBdQfZcaSFV/bWct9rBzD7U5eveZMyOWdmPsW5qbxn0eQhB7mvmpk/wa9MRERERMaiqaOHTYca2Xgw8LWlsvn4RFSTs1I4c3o2H1k2jUXTslg8NXtEwyJiyUgCVjUwcB7D4uC2gT4HXAXgnFtnZilAAVATiiJl9JxzdPb2BddnMuLjAl+dPX089nYVP3+tgr01bZQVpPPIF89lZVkezrkTuu8tn5HH8hl5QGA8yYu7a9lc2cSS4mxWluVRMEHdn0RERERk/DR39vLWgQZe31/Huv31x2d4TogzFk3N4vqzp7N8Ri7LZ+QyNSfV42rD30gC1npgjpmVEQhWNwA3DdrnEHA58HMzWwCkALWhLFRObV9NK796s5Izp2eTEBfH957dTfmAplsITNfd53e0dftYPC2L7113Jh84c8rxSSFONTYqJTGeqxZP5qrFk8f1dYiIiIjI+Ors6eONA/Ws2x/42n64Gb+D5IQ4VpTm8lfvmcvZpXksKc4hNSk2u/mNxbAByznnM7PbgGcITMF+n3Nuu5ndBWxwzq0Bvg78xMy+RmDCi0+7kcz/LiHxu7er+eZj79Dl6zvefW92UQbfeO+84136evv81Lf14PP7+chZxayYkRvRs7OIiIiIyMhVNnTwwu4ant9Vw7r99XT7/CTFx7GsJIevXD6Hc2fms7QkZ8jZmGV0RjQGK7im1dpB2+4YcHsHcH5oS5PhdPX28e0nd/DQW4dYWZbHf9ywjOqmDuraerh8fpGn01iLiIiIiHecc2w/3MJT247w7PZj7K1pA6A0P42bVpVw6bwiVpblxexEFOMpVJNcyARyzvHHnTXc/fQu9ta08eVLZvH1K+eSEB/H5GwNMhQRERGJRc45tlW38Id3jvDUtiMcrO8gPs5YVZbH9WdP57L5Rcws1MzO400BK8JUNnTwzcfe4dV9dZQVpPOzz5zNpfOKvC5LRERERDxyqL6Dx96u4vG3q4+HqvNm5fOli2fxnoWTJmxdRglQwIoAGw82cM8L+6lv72HvsVYM+PY1i7hpVQmJ6gYoIiIiEnOaO3v5w9YjPP52FesrGjGD82bl82eXzOI9CyeTm57kdYkxSwErjDnn+H+/38l9rx1gUlYy8yZn8f4zpvAXV8yhODfN6/JEREREZIJtq27m569XsGbLYXp8fmYXZfDXV83jQ0unaQr1MKGAFcZ+s7GK+147wE2rSvi79y0gPVn/XSIiIiKxprfPz1PbjnL/6xVsPNhIWlI81y0v5oazS1g8LUszQ4cZ/cUeZrZWNfH2oSbmTsrk/z25g1Vlefzj6sXExekHR0RERCSW1LR28dCblTz45kFqWrspzU/j7z+wkGuXF5Odmuh1eXISClge2320lR+9uI/MlER8fj8Pr688vpZVWlI8/3btmQpXIiIiIjFkX00b9768n8ffrqa3z3HJvELuPreUi+cW6u/CCKCA5ZFuXx8/fG4vP3m5nNSkeJyD9h4fnzxnBjefW8ob5fWUFaRTkq+xViIiIiKxYHNlEz96cR/P7jhGckIcN60s4dPnl1FWkO51aTIKClgeOFDXzq0PbmLHkRY+tqKYb169gOzURDp6+8gIjrOaXaQ1CkRERESinXOOV/fV8aMX9/P6/nqyUxP580tn86nzSjW9eoRSwJpgzjm++vDbHG7u5H8/uYIrFk46/liGJrEQERERiQl9fsdT247woxf3s/1wC5OykvnW+xdww8oS/U0Y4fS/N8HW7a9nS1Uz3/nIGSeEKxERERGJfr4+P4+/Xc09L+yjor6DmQXp/OtHl7B62VSSE+K9Lk9CQAFrgv3opf0UZibz4WXTvC5FRERERCaIr8/PE5sP85/P76WivoNFU7P48SfO4sqFk4nXxBVRRQFrAr1T1cwre+v4m6vmk5KoTyhEREREol2f3/HE5mr+8/l9HKhrZ9HULH7yyRVcsaBI61dFKQWsCdLW7eNrj2wmLz2Jj59T4nU5IiIiIjLOXt1bx//7/Q52H2tlwZQs/ufm5bxn4SQFqyingDUBnHP89aNbKK9t45efW0VWihaGExEREYlW5bVt/PPanTy3s4bpeancc9NZXL14stawihEKWBPg4fWVrH3nKN+8ej7nzS7wuhwRERERGQfNnb38xx/3cv/rFaQkxnP71fP5zPmlmrwixihgjbPDTZ380x92cu7MfL5w4UyvyxERERGREHPO8dimav557U4aOnq4fsV0vv6eeRRmah2rWKSANc6+9btt9Pkdd390iZqFRURERKLM/to2/v5323h9fz3LSnK4/7MrWTwt2+uyxEMKWONo77FWnt9Vw19fNY+S/DSvyxERERGREOnq7eNHL+7nRy/uJzkxjn/80GJuWlmiD9RFAWs8rdlymDiD65ZP97oUEREREQmRN8vr+eZj71Be187qpVP5u/cvoCgzxeuyJEwoYI0T5xxPbD7M+bML1P9WREREJAq0d/v416d3cf+6g5TkpfHA51Zy4ZxCr8uSMKOANU62VDVzqKGD2y6b7XUpIiIiIjJGr++r428e20pVYyefOb+Ub7x3HmlJ+lNa3k3fFePkic3VJCXEcdXiyV6XIiIiIiKnqbWrl+88tYtfvXmIsoJ0HvniuZxdmud1WRLGFLDGQZ/f8futR7h0XqEWFRYRERGJUC/vqeX2327laEsXX7iwjL+8ch6pSVrTSk5NAWscvFFeT21rN6uXTvO6FBEREREZpc6ePv5p7Q5++cYhZhWm8+iXz+Osklyvy5IIoYA1DtZsPkxGcgKXzS/yuhQRERERGYWdR1r4ykNvs7emjS9cWMbX3zOPlES1WsnIxXldQLTp9vWxdtsR3rNokn4YRUTGkZldZWa7zWyfmd0+xOPJZvbr4ONvmllpcHuimd1vZu+Y2U4z++aEFy8iYcc5x32vHmD1f71Gc2cvD3xuJX/3/oX6e05GTS1YIfbi7lpau3xcc+ZUr0sREYlaZhYP3ANcCVQB681sjXNux4DdPgc0Oudmm9kNwN3A9cB1QLJz7gwzSwN2mNlDzrmKiX0VIhIualu7+cajW3hxdy1XLCji7o8uIT9Dy+zI6VHACrFntx8jJy2R82cXeF2KiEg0Wwnsc86VA5jZw8BqYGDAWg3cGbz9KPBfZmaAA9LNLAFIBXqAlgmqW0TCzPqKBv7swU20dPby/1Yv4hPnzCDwq0Lk9KiLYAg553ijvJ5zZ+aTGK+3VkRkHE0DKgfcrwpuG3If55wPaAbyCYStduAIcAj4rnOuYaiTmNktZrbBzDbU1taG9hWIiKecc/z01QPceO8bZCQn8MRt53PzuaUKVzJmSgEhVNXYSXVTJ+fOyve6FBERObmVQB8wFSgDvm5mM4fa0Tl3r3NuhXNuRWFh4UTWKCLjqL3bx58/9Db/7/c7uGx+EU/cdj7zJ2d5XZZECXURDKF1++sBOGemApaIyDirBqYPuF8c3DbUPlXB7oDZQD1wE/C0c64XqDGz14AVQPm4Vy0inttX08aXfrmR8to2/uaq+Xzp4plqtZKQUgtWCL1RXk9+ehJzijK8LkVEJNqtB+aYWZmZJQE3AGsG7bMG+FTw9rXA8845R6Bb4GUAZpYOnAPsmpCqRcRTz+86xofueY3G9h5++blVfPmSWQpXEnJqwQoR5xzryus5Z2a+flBFRMaZc85nZrcBzwDxwH3Oue1mdhewwTm3Bvgp8ICZ7QMaCIQwCMw++DMz2w4Y8DPn3NaJfxUiMlH6x1v909qdLJqaxb03r2BqTqrXZUmUUsAKkUMNHRxp7uIcjb8SEZkQzrm1wNpB2+4YcLuLwJTsg5/XNtR2EYlOPT4/dzyxjYfXV3L14sl872NnkpakP4Fl/Oi7K0T6x1+dOzPP40pEREREBKCxvYcv/XIjbx5o4M8vm83XrphLXJx6Gsn4UsAKkXXl9RRkJDOrUOOvRERERLy2v7aNz/58PUeau/j3G5ayeunglRxExocCVgj0r391zsw8jb8SERER8djmyiY+87O3iDPjoS+cw/IZuV6XJDFEASsEDtS1c6ylW+tfiYiIiHjslb21fPGBjeRnJPHAZ1dRWpDudUkSYxSwQuCN8gZA61+JiIiIeOnJLYf5y0c2M6swg198diVFWSlelyQxSAErBNaV11OYmcxMfUIiIiIi4on7X6/gzie3c/aMPH7yqRVkpyZ6XZLEKAWsMeoff3Wu1r8SERERmXDOOX743F7+/Y97uXLhJP7zxmWkJMZ7XZbEMAWsMdpb00Zta7e6B4qIiIhMMOcc//LULv7n5XKuW17Mdz5yBgnxcV6XJTFOAWuMntt5DIBL5xd6XImIiIhI7HDO8e0nd/Dz1yu4+ZwZfPuaRVrjSsKCAtYYPbfjGGdMy2ZKdqrXpYiIiIjEBL/f8Xe/28ZDbx3icxeU8a33L9BQDQkbakMdg9rWbt6ubOKKBZO8LkVEREQkJvT5Hd94dCsPvXWIWy+dpXAlYUctWGPwwq4anIMrFhZ5XYqIiIhI1PP1+fnaI1sC07FfOZevXD7H65JE3kUBawz+b+cxpmansHBKlteliIiIiEQ1v9/x17/dypNbDnP71fP50sWzvC5JZEjqInia+qdnv3hekZqlRURERMZRYEKL7Ty2qZq/vHKuwpWENQWs01Tb1k1rl4/5kzO9LkVEREQkqn332d3cv+4gt1w0kz+/bLbX5YickgLWadpf0w7AzMJ0jysRERERiV7//eI+7nlhPzeuLOGbV89XzyEJeyMKWGZ2lZntNrN9Znb7EI//wMw2B7/2mFlTyCsNM+V1bQDMLMzwuBIRERGR6PTAugr+9endrF46lX/80GKFK4kIw05yYWbxwD3AlUAVsN7M1jjndvTv45z72oD9/xxYNg61hpX9Ne2kJsYzJSvF61JEREREos6aLYf5+ye2c8WCIr573ZnEaxFhiRAjacFaCexzzpU753qAh4HVp9j/RuChUBQXzvbXtlFWkK4Vw0VERERCbOPBRv7qN1tYWZrHf910FonxGtUikWMk363TgMoB96uC297FzGYAZcDzJ3n8FjPbYGYbamtrR1trWCmva2NWkboHioiIiIRSVWMHX3xgA5OzUvjxzctJSYz3uiSRUQn1xwE3AI865/qGetA5d69zboVzbkVhYWGITz1xunr7qGrsZGaBJrgQERERCZW2bh+fv38D3T4/9316BXnpSV6XJDJqIwlY1cD0AfeLg9uGcgMx0D2wor4d5zSDoIiIiEio+P2Orz78Nntr2rjnprOYXaSlcCQyjSRgrQfmmFmZmSURCFFrBu9kZvOBXGBdaEsMP/1TtM/SDIIiIiIiIfFfL+zjuZ013PGBhVw0N3J7OokMG7Cccz7gNuAZYCfwiHNuu5ndZWbXDNj1BuBh55wbn1LDR3lt/xTtasESERERGatX9tbyg+f28KGlU/nkuTO8LkdkTIadph3AObcWWDto2x2D7t8ZurLC296aNqZkp5CWNKK3T0RERERO4nBTJ3/x8GbmFGXwzx85Q2tdScTTnJej5Ovz8+q+OlaU5nldioiIiEhE6/H5ufVXm+ju7eNHn1iuD68lKui7eJTePNBAQ3sP7z9jsteliIiIiES0f316F28fauKem87S2HaJGmrBGqW17xwhNTGei+cWeV2KiIiISMR6ZW8t//vqAW4+ZwbvXzLF63JEQkYBaxT6/I5nth/lsgVFpCZp0TsRERGR09HY3sNf/WYLs4sy+Nv3LfC6HJGQUsAahfUVDdS19fC+xfqURUREROR0OOf45mPv0NDeww+vX6oPrSXqKGCNwrPbj5GUEMcl87Q2g4iIiMjp+M2GKp7efpSvv2cei6dle12OSMgpYI2Qc44/7jrG+bPySU/W3CAiIiIio1XZ0MGdT27nnJl5fOHCmV6XIzIuFLBGqLyunYP1HVy2YJLXpYiIiIhEHOccf/PbrcSZ8b2PLSU+TutdSXRSwBqh53fWAHDZfM0eKCIiIjJav3rrEK/vr+dv37eAaTmpXpcjMm4UsEboj7uOMX9ypn4hiIiIiIxSdVMn31m7i/Nn53PjyulelyMyrhSwRqC5s5cNFY1qvRIREREZJecct/92K37n+JePLMFMXQMluilgjcAfth7B53dcsVDjr0RERERG4zcbqnhlbx23Xz2f6XlpXpcjMu4UsIbhnOP+1ytYNDWLZdNzvC5HREREJGLUtXXzT2t3srI0j0+smuF1OSITQgFrGOvK69l9rJVPn1eqJm0RERGRUfjntTvp6PHxzx9ZTJxmDZQYoYA1jJ+/VkFeehIfPHOq16WIiIiIRIzX99fx2KZqbrloJrOLMr0uR2TCKGCdQl1bN8/tPMYNZ08nJTHe63JEREREIkK3r49v/W4bJXlp/Pllc7wuR2RCJXhdQDh7flcNfgfvO2OK16WIiEiEO1jfzg+f20t+ehKTs1NYVpLD4mnZJCfoAzyJPj95uZzy2nZ+/pmz9SG1xBwFrFP4485jTMlOYdHULK9LERGRCNfQ3sNbBxpoaO+hs7cPgPz0JL5w0Uw+ee4M0pJ0SZbocKi+g/98fh/vP2MKl8zTEjcSe/Tb/CS6fX28sreODy+bpsktRETCkJldBfw7EA/8r3PuXwY9ngz8AlgO1APXO+cqzOzjwDcG7LoEOMs5t3k8611Wkstrt18GQG1rNxsqGvjVW4f4l6d28dimKn72mZVazF6iwl2/30F8nPH3H1jodSkintAYrJN4o7yBjp4+Ll+gT15ERMKNmcUD9wBXAwuBG81s8F9znwManXOzgR8AdwM45x50zi11zi0FbgYOjHe4GqwwM5mrz5jCA59bxf2fXcmRpi4+fM9r7KtpncgyRELuxd01PLfzGH9+2RwmZ6d4XY6IJxSwTuKPO4+RkhjHebMKvC5FRETebSWwzzlX7pzrAR4GVg/aZzVwf/D2o8Dl9u4uCTcGn+uZi+cW8uiXz6PP77j1wbfpCnYfFIk0PT4/d/1+B2UF6Xz2glKvyxHxjALWSby8p5bzZxVoYKaISHiaBlQOuF8V3DbkPs45H9AM5A/a53rgoZOdxMxuMbMNZrahtrZ2zEWfzLzJmXz3Y2ey+1gr31m7c9zOIzKe7n+9gvLadu74wEJN3iIxTQFrCDWtXVTUd7BqZp7XpYiIyDgxs1VAh3Nu28n2cc7d65xb4ZxbUVhYOK71XDqviM9dUMb96w6y8WDDuJ5LJNRqWrr49z/u5bL5RVw6X8MrJLYpYA1hY0UjACtKFbBERMJUNTB9wP3i4LYh9zGzBCCbwGQX/W7gFK1XXvj6e+aSn57ED5/b63UpIqNy99O76fb1aWILERSwhrS+opHkhDgWT832uhQRERnaemCOmZWZWRKBsLRm0D5rgE8Fb18LPO+ccwBmFgd8DI/HXw2WlpTALRfN5JW9dWw82Oh1OSIjsq26mcferuKz55dRVpDudTkinlPAGsKGgw0snZ5DUoLeHhGRcBQcU3Ub8AywE3jEObfdzO4ys2uCu/0UyDezfcBfArcPOMRFQKVzrnwi6x6Jm8+dQV56Ev/+R7ViSWS4++ldZKcm8meXzva6FJGwoHWwBuno8bH9cAtfunim16WIiMgpOOfWAmsHbbtjwO0u4LqTPPdF4JzxrO90pSUl8JnzSvne/+3hUH0HJflpXpckclIv76nllb11/P0HFpKdmuh1OSJhQU00g2w+1ESf32n8lYiIeOYjy4sBeGLz4GFlIuGjz+/4zlO7mJ6XyifOKfG6HJGwoYA1yPqKRszgrJJcr0sREZEYNS0nlVVleTy+uZrgsDGRsPO7t6vZeaSFb7x3vqZlFxlAAWuQPTWtlOSlqZlbREQ89eFl0yivbWdrVbPXpYi8S1dvH997djdLirP5wBlTvC5HJKwoYA1S1dBBSZ76u4uIiLeuPmMKSfFxPP62uglK+Hlg3UEON3dx+9XziYszr8sRCSsKWINUNnZSnKuAJSIi3spOTeSiuYU8t/OYuglKWOno8fHjl/Zz4ZwCzptV4HU5ImFHAWuA9m4fDe09TM9L9boUERERLppbQFVjJ4caOrwuReS4X6w7SH17D1+9Yq7XpYiEJQWsASobAxew6WrBEhGRMHDB7EDrwCt76zyuRCSgrdvH/7y0n4vnFrJ8hiYEExmKAtYAlQ2dAEzXGCwREQkDZQXpTMtJ5VUFLAkT979eQWNHL1+7Uq1XIiejgDVAZUN/C5a6CIqIiPfMjAtmF/D6/jr6/BqHJd5q6erl3pfLuXx+EUun53hdjkjYUsAaoLKxg7SkePLSk7wuRUREBIAL5hTQ0uVja1WT16VIjPvZqxU0d6r1SmQ4ClgDVDZ0Mj03DTNNNyoiIuHh/NkFmMFr+9RNULzT0tXL/75azpULJ7F4WrbX5YiENQWsAaoaOzSDoIiIhJW89CRmFqSzuVILDot3fvnGQVq7fHzlsjlelyIS9hSwgpxzVDZ0aA0sEREJO2cW56iLoHims6ePn75ygIvmFnJGsVqvRIajgBXU2NFLe0+fZhAUEZGws6Q4m5rWbo42d3ldisSgRzZUUt/ew62XzPK6FJGIoIAVpBkERUQkXC0Jzti2Ra1YMsF6+/zc+3I5K2bksrIsz+tyRCKCAlbQ8UWG1YIlIiJhZuGULBLiTN0EZcI9sfkw1U2d3HrpbE0CJjJCClhB/YsMF6sFS0REwkxKYjzzJmeytUoTXcjE6fM7/vvFfSyYksUl8wq9LkckYihgBVU2dpCTlkhmSqLXpYiIiLzLkuIctlY145wWHJaJ8ez2o5TXtnPrpbPUeiUyCgpYQZUNHUzXDIIiIhKmlhRn09zZy8H6Dq9LkRjxv68eYEZ+GlcvnuJ1KSIRRQErqKqxU2tgiYhI2DojuLjr9sMtHlcisWBzZRMbDzbymfNKiY9T65XIaChgAX6/o7qxUy1YIiIStmYXZWAGe2tavS5FYsDPXjtAZnIC166Y7nUpIhFHAQs41tpFT5+fYs0gKCIiYSolMZ7puWnsq2nzuhSJckebu/jD1iNcf/Z0MpITvC5HJOIoYPGnGQS1BpaIiISzOUUZClgy7n6xrgK/c3zqvFKvSxGJSApYDFhkWC1YIiISxmYXZVBe246vz+91KRKlOnv6+NVbh3jPwsn6u0jkNI0oYJnZVWa228z2mdntJ9nnY2a2w8y2m9mvQlvm+OpfZHhajlqwREQkfM0uyqCnz09lY6fXpUiUevztapo6evnsBWVelyISsYbtWGtm8cA9wJVAFbDezNY453YM2GcO8E3gfOdco5kVjVfB46GyoZNJWcmkJMZ7XYqIiMhJzZmUCcDeY62UFaR7XI1EG+ccP3vtAIunZXF2aa7X5YhErJG0YK0E9jnnyp1zPcDDwOpB+3wBuMc51wjgnKsJbZnjq7JRa2CJiEj4m1UYCFX7ajUOS0JvXXk9e2va+PR5ZVpYWGQMRhKwpgGVA+5XBbcNNBeYa2avmdkbZnbVUAcys1vMbIOZbaitrT29isdBVUOH+hmLiEjYy0xJZEp2CvuOKWBJ6D34xiGyUxP5wBItLCwyFqGa5CIBmANcAtwI/MTMcgbv5Jy71zm3wjm3orCwMESnHpsen58jLV2aQVBERCLC7KIM9momQQmxmtYuntl+lOuWF2vIhMgYjSRgVQMDV5krDm4bqApY45zrdc4dAPYQCFxh73BTJ86hNbBERCQizC7KYH9tG36/87oUiSK/2VCFz++4cVWJ16WIRLyRBKz1wBwzKzOzJOAGYM2gfX5HoPUKMysg0GWwPHRljp/+GQQ1BktERCLBrMIMOnr6ONrS5XUpEiX6/I5fvXmI82blM6sww+tyRCLesAHLOecDbgOeAXYCjzjntpvZXWZ2TXC3Z4B6M9sBvAB8wzlXP15Fh9LxRYbz1EVQRETC34z8wAeC/Ws4iozVS3tqqG7q5BPnzPC6FJGoMOw07QDOubXA2kHb7hhw2wF/GfyKKJWNHSTEGVOyFbBERCT89fe4ONTQwaqZ+R5XI9HgwTcOUZiZzJULJ3ldikhUCNUkFxGrsqGDqTmpxMdpOlIREQl/U3NSiTO1YEloVDV28PzuGq5fMZ3E+Jj/s1AkJGL+J6mysVPdA0VEJGIkJcQxJTuVysZOr0uRKPDwW4GVeG5YOX2YPUVkpGI+YFU1aJFhERGJLCV5aRxSC5aMUZ/f8ejGKi6eW0ix/hYSCZmYDljt3T7q23u0yLCIiESU6XmpClgyZq/sreVoSxcfW6HWK5FQiumAVd0U6F5RrEWGRUQkgpTkpVHb2k1nT5/XpUgE+83GKnLSErl8QZHXpYhElZgOWP0DhNWCJSIikaT/ulXVqFYsOT1NHT383/ZjfGjpNJIT4r0uRySqKGChRYZFRCSylOT9aap2kdPxxObD9PT5uW5FsdeliESd2A5YjZ2kJsZTkJHkdSkiIiIjpoAlY/WbjZUsnJLFoqnZXpciEnViO2A1dFCcm4qZ1sASEZHIkZeeRFpSvAKWnJYdh1vYVt3Cx9R6JTIuYjtgNXZq/JWIiEQcM6MkL43KBq2FJaP3m42VJMXHsXrpNK9LEYlKMR2wqhs7NIOgiEiEMrOrzGy3me0zs9uHeDzZzH4dfPxNMysd8NgSM1tnZtvN7B0zS5nQ4kNgel7a8bHEIiPV4/Pzu7eruXLhJHLTNURCZDzEbMDq9vXR0uWjMCPZ61JERGSUzCweuAe4GlgI3GhmCwft9jmg0Tk3G/gBcHfwuQnAL4EvOecWAZcAvRNUeshMy0nlcLNasGR0XthdQ2NHL9cuV/dAkfESswGrob0HgHwFLBGRSLQS2OecK3fO9QAPA6sH7bMauD94+1HgcgsMun0PsNU5twXAOVfvnIu4BaUmZ6fQ2uWjrdvndSkSQdZsPkx+ehIXzinwuhSRqBWzAau+LRCwNIOgiEhEmgZUDrhfFdw25D7OOR/QDOQDcwFnZs+Y2SYz++uTncTMbjGzDWa2oba2NqQvYKwmZwV6NR5t7vK4EokUrV29PLfzGB9YMoWE+Jj9E1Bk3MXsT1ddWzegFiwRkRiUAFwAfDz474fN7PKhdnTO3eucW+GcW1FYWDiRNQ5rcnYgYB1rUcCSkXlm+zG6fX6u0eQWIuMqZgOWWrBERCJaNTB9wP3i4LYh9wmOu8oG6gm0dr3snKtzznUAa4Gzxr3iEJsSDFhH1IIlI/TE5mqm56VyVkmO16WIRLXYDVjtasESEYlg64E5ZlZmZknADcCaQfusAT4VvH0t8LxzzgHPAGeYWVoweF0M7JigukNm0vEugproQoZX09rFa/vqWH3mNK3/KTLOErwuwCv1bT0kJ8SRnhTvdSkiIjJKzjmfmd1GICzFA/c557ab2V3ABufcGuCnwANmtg9oIBDCcM41mtn3CYQ0B6x1zv3BkxcyBimJ8eSmJaoFS0bkD1uP4HfwoWVTvS5FJOrFbMCqa+uhICNZn+KIiEQo59xaAt37Bm67Y8DtLuC6kzz3lwSmao9ok7NTNQZLRuR3mw+zaGoWs4syvS5FJOrFbBfBurZu8jX+SkREItiU7BS1YMmwKura2VLZxOqlar0SmQgxG7Dq27sp0PgrERGJYJOzUzRNuwzric2HMYMPnqmAJTIRYjdgtfWQn64WLBERiVyTs1Kob++h2xdx6yTLBHpy62FWluYxJTvV61JEYkJMBiznXCBgqQVLREQiWP9aWDUt3R5XIuFqX00r+2raeP+SKV6XIhIzYjJgtXb76Onzaw0sERGJaFoLS4bz1DtHAXjvoskeVyISO2IyYPUvMqxJLkREJJL9KWBpLSwZ2tPbj7J8Ru7xddNEZPzFaMAKLjKcri6CIiISuf602LBasOTdDtV3sP1wC1ep9UpkQsVkwKpTC5aIiESBzJREMpIT1EVQhvT09iMAXLVYAUtkIsXkQsP17YEWLE3TLiITrbe3l6qqKrq6YvcP4pSUFIqLi0lMTPS6lKgwKSuZmtbY/X6Sk3tq21EWT8tiel6a16WIxJTYDFjBFqw8TdMuIhOsqqqKzMxMSktLMTOvy5lwzjnq6+upqqqirKzM63KiQkFGMnWtPV6XIWHmSHMnbx9q4hvvned1KTLB9EFe6I32g8EYDVjd5KQlkhgfkz0kRcRDXV1dMRuuAMyM/Px8amtrvS4lahRmJrP9cIvXZUiYeWZbYPZAdQ+MPbH+QV6onc4HgzGZMOq0yLCIeCjWL3ix/vpDLdCCpXWw5ERPbTvK3EkZzCrM8LoUmWBdXV3k5+frd22I9H8wOJoWwZgMWA3tPeoeKCIiUaEwM5nWbh9dvX1elyJhoq6tm/UVDVy1WIsLxyqFq9Aa7fsZkwGrubOX7FQNrhYRkchXGJywqVatWBL0x53H8Ds0PbuIR2I2YGUpYImIDCsj49Tdi77xjW+waNEivvGNb/Dyyy9z1llnkZCQwKOPPjpBFUpBZqBHRl2bApYE/N+OGqblpLJgSqbXpYiMSP+15vDhw1x77bVD7nPJJZewYcOGUx7nhz/8IR0dHcfvv+9976OpqSlkdY5UTE5y0aIWLBGRkLj33ntpaGggPj6eiooKfv7zn/Pd737X67JiSmFGYLFhtWAJQGdPH6/uq+WGs0vUTUwiztSpU8f0Ad0Pf/hDPvGJT5CWFliaYO3ataEqbVRiLmD1+R2t3T4FLBHx3Lef3M6OEM/+tnBqFv/wwUUnffz2229n+vTp3HrrrQDceeedJCQk8MILL9DY2Ehvby//+I//yOrVq4c91zXXXENbWxvLly/nm9/8Jtdffz0AcXEx2TnCM39qwdJU7QKv7aujq9fPFQsmeV2KhAEvrjNw+teaiooKPvCBD7Bt2zY6Ozv5zGc+w5YtW5g/fz6dnZ3H9/vyl7/M+vXr6ezs5Nprr+Xb3/42//Ef/8Hhw4e59NJLKSgo4IUXXqC0tJQNGzZQUFDA97//fe677z4APv/5z/PVr36ViooKrr76ai644AJef/11pk2bxhNPPEFqauqY3qOYuwq2dPYCkJWigCUisef666/nkUceOX7/kUce4VOf+hSPP/44mzZt4oUXXuDrX/86zrlhj7VmzRpSU1PZvHnz8XAlEy8/XWOw5E+e23mMzOQEVpbleV2KxLBQXGt+9KMfkZaWxs6dO/n2t7/Nxo0bjz/2T//0T2zYsIGtW7fy0ksvsXXrVr7yla8wdepUXnjhBV544YUTjrVx40Z+9rOf8eabb/LGG2/wk5/8hLfffhuAvXv3cuutt7J9+3ZycnL47W9/O+bXH3MtWM3BgKUWLBHx2nCfAI6HZcuWUVNTw+HDh6mtrSU3N5fJkyfzta99jZdffpm4uDiqq6s5duwYkydrgHwkSEqIIyctUWOwBL/f8cddNVw0r5CkhJj7DF2G4MV1BkJzrXn55Zf5yle+AsCSJUtYsmTJ8cceeeQR7r33Xnw+H0eOHGHHjh0nPD7Yq6++yoc//GHS09MB+MhHPsIrr7zCNddcQ1lZGUuXLgVg+fLlVFRUjPn1K2CJiMSY6667jkcffZSjR49y/fXX8+CDD1JbW8vGjRtJTEyktLR0VOt9iPcKM5IVsISt1c3UtnZzpboHShgYr2vNgQMH+O53v8v69evJzc3l05/+9JiuWcnJycdvx8fHn9AV8XTF3McbxwNWmgKWiMSm66+/nocffphHH32U6667jubmZoqKikhMTOSFF17g4MGDXpcoo1SQkawugsJzO44RH2dcMq/Q61JExnytueiii/jVr34FwLZt29i6dSsALS0tpKenk52dzbFjx3jqqaeOPyczM5PW1tZ3HevCCy/kd7/7HR0dHbS3t/P4449z4YUXhvDVnih2A5ZasEQkRi1atIjW1lamTZvGlClT+PjHP86GDRs444wz+MUvfsH8+fNP67jr16+nuLiY3/zmN3zxi19k0SJvuqbEooJMtWBJYPzV2aW55KQleV2KyJivNV/+8pdpa2tjwYIF3HHHHSxfvhyAM888k2XLljF//nxuuukmzj///OPPueWWW7jqqqu49NJLTzjWWWedxac//WlWrlzJqlWr+PznP8+yZctC/6KDbCQDmcfDihUr3HBz2Y+HX75xkG/9bhtv/u3lTMpKmfDzi0hs27lzJwsWLPC6DM8N9T6Y2Ubn3AqPShqWV9etkbjryR38ev0htt91ldeliEcqGzq48F9f4FvvX8DnL5zpdTniIV1nxsdorltqwRIREYlwBZlJtPf00dnT53Up4pE/7jwGwOUafyXiuZib5KKls5ekhDhSEuO9LkVEJCK888473HzzzSdsS05O5s033/SoIhmsMCMwSLuurZvpeWkeVyNeeG5nDbOLMigrSPe6FJGYF3sBq6tXrVci4innHGbmdRkjdsYZZ7B58+aQHc+rrunRrCAzELBqWhWwYlF7t483D9TzmfPLvC5FwkSkXWfC3WivWzHZRVABS0S8kpKSQn19fcyGDOcc9fX1pKRoDGwoDWzBktizbn89vX2OS+Zq9kDRdSbUTue6FXMtWApYIuKl4uJiqqqqqK2t9boUz6SkpFBcXOx1GVGlMNiCpanaY9PLe2tJS4pneWmu16VIGNB1JvRGe92KyYBVlKlPTkXEG4mJiZSVqRuPhFZucFruxvYejysRL7y0p5bzZuWTnKDx5aLrTDhQF0EREZEIl5QQR2ZKAvUKWDGnoq6dg/UdXKTugSJhI/YCVocCloiIRJ+89CQaFLBizkt7At3ALlbAEgkbIwpYZnaVme02s31mdvsQj3/azGrNbHPw6/OhL3Xs/H5Ha7ePrJSY6xkpIiJRLi89icYOBaxY8/KeWkrz05iRr+nZRcLFsEnDzOKBe4ArgSpgvZmtcc7tGLTrr51zt41DjSHT2uXDOchSC5aIiESZ/PQkDjd1eV2GTKBuXx+v76/nuhWaNEYknIykBWslsM85V+6c6wEeBlaPb1njo7mzF0BdBEVEJOrkpqkFK9ZsqGiks7dP3QNFwsxIAtY0oHLA/argtsE+amZbzexRM5sekupCTAFLRESiVV5GEvXtPVr7Joa8tKeWpPg4zpmZ73UpIjJAqCa5eBIodc4tAf4PuH+onczsFjPbYGYbvJibXwFLRESiVV5aEj0+P+09fV6XIhPk5T21nF2WS3qyxpaLhJORBKxqYGCLVHFw23HOuXrnXP/qhv8LLB/qQM65e51zK5xzKwoLJ745+3jASlPAEhGR6JKXrrWwYsnR5i52HW3lojnqHigSbkYSsNYDc8yszMySgBuANQN3MLMpA+5eA+wMXYmhoxYsERGJVv0BS2thxYaX+6dnn6eAJRJuhm1Tds75zOw24BkgHrjPObfdzO4CNjjn1gBfMbNrAB/QAHx6HGs+bQpYIiISrdSCFVte2lvLpKxk5k3K9LoUERlkRJ12nXNrgbWDtt0x4PY3gW+GtrTQa+vuJc4gNTHe61JERERCKj89GVALVizw9fl5dW8d71k4CTPzuhwRGSRUk1xEhI6ePtKTEvTLSEREok5ueqB3RkN79zB7SqTbUtVMc2evugeKhKnYCljdfaQmqfVKRESiT0ZyAknxcTS093pdioyzl/bUEmdwwewCr0sRkSHEVsDq7SNNAUtERKKQmZGbnqgWrBjw8p5alk7PISctyetSRGQIMRWwOnt8pCVprQgRkWhgZleZ2W4z22dmtw/xeLKZ/Tr4+JtmVhrcXmpmnWa2Ofj14wkvfpzkpSerBSvKNbb3sKWqiYvmqnugSLiKqbTR3q0WLBGRaGBm8cA9wJVAFbDezNY453YM2O1zQKNzbraZ3QDcDVwffGy/c27pRNY8EfLTk9SCFeVe2VeHc3CxApZI2IqpFqyOXo3BEhGJEiuBfc65cudcD/AwsHrQPquB+4O3HwUutyif5Sg3PYkGzSIY1V7aXUtOWiJLinO8LkVETiKmAlZnj490dREUEYkG04DKAfergtuG3Mc55wOagfzgY2Vm9raZvWRmF57sJGZ2i5ltMLMNtbW1oat+nOQrYEU15xwv763lgtkFxMdF9WcFIhEtpgKWugiKiAhwBChxzi0D/hL4lZllDbWjc+5e59wK59yKwsLw75KVm5ZES5eP3j6/16XIONh5pJXa1m51DxQJczEVsDrVRVBEJFpUA9MH3C8ObhtyHzNLALKBeudct3OuHsA5txHYD8wd94onQF5GYFa5xg61YkWjl/YEWlEVsETCW0wFrI4eH+nJ6iIoIhIF1gNzzKzMzJKAG4A1g/ZZA3wqePta4HnnnDOzwuAkGZjZTGAOUD5BdY+rvOC03eomGJ1e3lPLgilZFGWleF2KiJxCzASsPr+jq9dPaqJasEREIl1wTNVtwDPATuAR59x2M7vLzK4J7vZTIN/M9hHoCtg/lftFwFYz20xg8osvOecaJvQFjJO89GDAalPAijZt3T42HGzgorlaXFgk3MVMc05nbx+AxmCJiEQJ59xaYO2gbXcMuN0FXDfE834L/HbcC/RAfrCLYIO6CEaddfvr6e1z6h4oEgFipgWro8cHQJq6CIqISJTKVRfBqPXSnhrSkuJZMSPP61JEZBixE7C6gy1Y6iIoIiJRKjctEVDAGg8dPT7ufnoXe4+1Tvi5nXO8tKeW82blk5QQM3+6iUSsmPkp7ehRF0EREYluCfFxZKcmKmCFWFu3j0//bD0/enE/f/v4OzjnJvT8FfUdVDZ0qnugSISImYDV2asugiIiEv202HBoOef48i83svFgI1cvnsz6ikZe3ls3oTW8tLsGgIvnFk3oeUXk9MRMwGrvVguWiIhEv1wFrJB6aU8tr+yt41vvX8C/37CMaTmpfO/Z3RPaivXSnlrKCtIpyU+bsHOKyOmLmYDV30VQ07SLiEg0y1PAChnnHN97dg/Fual8fNUMkhLi+Isr5rC1qpknNh+ekBq6evt4o7yBi+ZoenaRSBEzAau/i6AWGhYRkWimLoKh88z2Y7xT3cxfXD7n+OQSHz2rmGUlOXz7ye3Ut3WPew0bKhrp7O3j4nkafyUSKWImYKmLoIiIxILc9CQaO3omfCKGaHTfqweYkZ/Gh5dNO74tPs64+6NLaOv2ceeTO8b9fX5pTw1J8XGcMzN/XM8jIqETMwGrs7+LoAKWiIhEsfz0JHr7HK3dPq9LiWiH6jt4q6KBj62YTkL8iX8uzZ2UyVcum8OTWw7zPy+Xj2sdL++p4+yyXNKS1ANHJFLETMA6Pk27xmCJiEgUO77YcJu6CY7FbzdVYcYJrVcD3XrpbD545lT+5ald/Py1A/T5Q9+SdaS5k93HWjU9u0iEiaGA5SMpIe5dn0KJiIhEk7yMQMCq1zis0+b3Ox57u4rzZxUwNSd1yH3i4ozvXreEC+cUcOeTO7j8ey+yoaIhpHW8vKcW0PTsIpEmZtJGR0+fxl+JiEjUywu2YDUqYJ22DQcbqWzo5KPLh2696pecEM/9n1nJjz9xFj0+P9/63baQjsl6aU8tk7NSmDspI2THFJHxF1MBK139l0VEJMrlpQe7CCpgnbb/23GUpPg43rto8rD7xsUZVy2ewteunMuuo628ui80ixD7+vy8ureOi+YWYGYhOaaITIwYClg+TXAhIiJRLz/YRbChQwHrdL2yd/QTS1yzdCpFmcncG6JJL7ZUNdHS5VP3QJEIFEMBS10ERUQk+qUmxpOcEKcWrNN0rKWLXUdbuXDO6CaWSE6I59Pnl/LK3jp2HmkZcx0v7a4lzuCC2VpgWCTSxEzA6lTAEhGRGGBm5KcnUa9ZBE/LK3sDXfwunDP6YHPD2SUA/HHnsTHX8dKeWpZOzyE7LXHMxxKRiRUzAau9x6c1JEREJCb0LzYso/fK3loKMpJYMDlr1M/NS09i3qRM3qpoHFMNDe09bK1uVvdAkQgVMwGrs6dPY7BERCQm5KUnaZr20+D3O17dW8eFcwqJizu9iSXOLstl08HGMa2L9creWpyDi+aqe6BIJIqZgBWYRVABS0REol9+epKmaT8Nu462Ut/eM6ZxT2eX5tHW7RvTOKw/7qwhPz2JM4tzTvsYIuKdGApY6iIoIiKxITc9SZNcnIaNhwJd+1aW5Z32Mc4uDTx3/WkuOuzr8/Pi7hounV902q1oIuKtGApY6iIoIiKxIT89ibZuH92+Pq9LiSibDjZSmJlMcW7qaR9jak4q03JS2XCa47A2HmykpcvH5fM1/kokUsVEwOrx+fH5nboIiohITMgNLjbc2N7rcSWRZePBRpaX5I55Yd+zS3N5q6IB50Y/Duv5XTUkxhsXnMYshiISHmIiYHX2BD7BS1UXQRERiQH5wYBV397tcSWRo6a1i0MNHSyfkTvmY60ozaO2tZtDDR2jfu4fd9WwqiyfzBRNzy4SqWIiYLX3+AC0DpaIiMSE3DS1YI3WpoNNAJwVgoDVP4brrQOjG4d1sL6dfTVtXKbugSIRLSYCVkewBUsBS0REYkF+hlqwRmvToUaS4uNYPG30618NNrswg+zUxFFPdPH8rhoALl+ggCUSyWIiYHUeD1jqIigiItEvLz0ZQDMJjsKmg42cUZxNcsLYP4yNizPOLs0d9UQXz++qYVZhOjPy08dcg4h4JyYClroIiohILMlOTcQMrYU1Qj0+P1urmzmrJCdkx1xRmkd5XTu1rSNrRWzr9vFGeT2XL5gUshpExBsxEbA6e/snuVDAEhGR6BcfZ+SmJVGvgDUiu4+20uPzc+b0nJAds389rI0HR9ZN8NW9tfT2OY2/EokCMRGwujQGS0REYkxuWiKNHQpYI7GlqgmAM4tzQnbMM6Zlk5wQx1sHRtZN8I87a8hKSQjJLIYi4q2YCFj9LVgpIehXLSIiEgny05Opb1PAGomtVU3kpiWOaYHhwZIS4lg6PWdEE134+vy8sLuGi+cVkRgfE3+aiUS1mPgpVhdBERGJNbnpasEaqa1VzSwpzhnzAsODrZqZz7bDzcNONvLWgQbq2nq4evHkkJ5fRLwRGwEr2EUwJVEBS0REYkNeerJmERyBjh4fe461cmZxdsiPfem8QpyDV/bWnnK/379zhLSkeC6dp/FXItEgJgJWV38LlgKWiIjEiPz0JBo7evH7ndelhLXth1vwO0I6wUW/JcU55KUn8eLukwcsX5+fp7cd5fIFk9TTRiRKxETA6uztIz7OSIwPbdO/iIhIuMpNT6LP72jp6vW6lLC2pbIJCIShUIuPMy6eW8hLe2rpO0nQXVdeT0N7D+8/Y0rIzy8i3oiJgNXV6yc1MT7kfatFRETCVX56EoCmah/G1qpmpmanUJiZPC7Hv2ReIQ3tPWwNzlQ42JNbDpOeFM8l8wrH5fwiMvFiImB19vZp/JWIiMSU3GDA0mLDp7bxYCPLSsZvavSL5xYSZ/DCEN0EW7t6+f3WI7zvjCn6O0UkisREwOrq6SM1KSZeqoiICBC9LVidPX08urHq+PjqsTjc1El1Uydnl45fwMpJS2JFaR6/33IY507sJvi7zYfp6Onj4+fMGLfzi8jEi4nU0dnbpzWwREQkpvS3YEXbTII/eaWcv/rNFj7zs/W0dfvGdKz+NarOLssLRWkndf2K6ZTXtbOuvP74NuccD75xkEVTs8ZlBkMR8U7MBCzNzCMiIrEkPwoDVm+fnwffPMiM/DTeqmjg8/evH9Px3jrQQGZyAvMnZ4WowqG9f8kUslMT+dWbh45v23SokV1HW/n4qhkaIy4SZUYUsMzsKjPbbWb7zOz2U+z3UTNzZrYidCWOXWePxmCJiEhsSUmMJy0pPqoC1jPbj3KspZt/+OBCbr1kFm+UN4ypFWt9RQNnzcglPm58A05KYjwfPauYZ7Yfpba1mx6fnzvX7CA3LZFrlk4d13OLyMQbNmCZWTxwD3A1sBC40cwWDrFfJvAXwJuhLnKsunr7tAaWiIjEnNy0pKia5OL+1ysoyUvj4rlFzJ2cCcCh+o7TOlZjew97jrWxcpy7B/a7aVUJvX2OW3+1ib//3TbeqW7mOx9ZQkZywoScX0QmzkhasFYC+5xz5c65HuBhYPUQ+/0/4G6gK4T1hUT/NO0iIiKxJD8jKWomudh5pIX1FY188twZxMcZM/LSATjU0H5ax9twsBGAs0snJmDNLsrgXz+6hF1HWvj1hkpuXDmdqxZPnpBzi8jEGknAmgZUDrhfFdx2nJmdBUx3zv3hVAcys1vMbIOZbaitPfmq5qGmMVgiItFnuO7rZpZsZr8OPv6mmZUOerzEzNrM7K8mrOgJlp+eRF1bt9dlhMRDbx0iKSGOj55VDEBJfhoAB0+zBWt9RQNJ8XEsmcAJJj529nRe+KtL+KcPL+aODyyasPOKyMQa8yQXZhYHfB/4+nD7Oufudc6tcM6tKCycuAX1tA6WiEh0GWH39c8Bjc652cAPCPSyGOj7wFPjXauXCjOToyJgdfb08fimat63ePLx2RGzUxPJSUvkYMPpBay3DjRw5vTsCf/7ID8jmY+vmqEPfkWi2EgCVjUwfcD94uC2fpnAYuBFM6sAzgHWhNNEF109GoMlIhJlRtJ9fTVwf/D2o8DlFpyuzcw+BBwAtk9Mud4IBKwe/H43/M5h7PdbD9Pa7ePGlSUnbJ+Rl0blaQSsjh4f26qbJ6x7oIjElpEErPXAHDMrM7Mk4AZgTf+Dzrlm51yBc67UOVcKvAFc45zbMC4Vn4ZAC1ZMzEgvIhIrhu2+PnAf55wPaAbyzSwD+Bvg28OdxKuu7aFSmJFMn9/R2BHZ47AeeusQMwvT3zUhxfS8tNPqIrj5UBM+vxv39a9EJDYNmzqCF6XbgGeAncAjzrntZnaXmV0z3gWOVW+fH5/fqQVLRET63Qn8wDnXNtyOXnVtD5XCzBQAaiO4m+Cuoy1sOtTETStL3rVe1Iz8NKqbOunt84/qmG9VNGAGy2fkhrJUEREARjQ3qHNuLbB20LY7TrLvJWMvK3Q6e/sA1NdZRCS6DNd9feA+VWaWAGQD9cAq4Foz+1cgB/CbWZdz7r/GveoJVpiZDEBtazfzI3TCuofePERS/J8mtxhoRl46fX7H4aZOZuSnj/iY6ysaWDA5i6yUxFCWKiIChGCSi3DXFQxYmuRCRCSqnLL7etAa4FPB29cCz7uACwd0a/8h8M/RGK7gxIAViTp7+njs7WquPuNPk1sM1D+T4KFRjMPq7fOz6WDThK1/JSKxJ/oDVk+g24C6CIqIRI8Rdl//KYExV/uAvwTeNZV7tIv0gPWHd47Q2vXuyS36zTiNqdq3H26hs7dPE1yIyLiJ+uXD1UVQRCQ6Ddd93TnXBVw3zDHuHJfiwkR6UjypifERG7Ae2VBJWUE6q07S2jQpM4WkhLhRtWCtP9AAwNllGn8lIuMj6luwjgcstWCJiEiMMTMKM5MjcpKLw02dvHWggQ8vm/auyS36xcUZ03NTOVjfPuLjvlXRQGl+GkXBCUBEREIt+gNWj8ZgiYhI7CrMTI7IFqwntxwG4Jozp55yvxn56Rxq6BzRMf1+x4aKBnUPFJFxFfUB60+TXET9SxUREXmXoggNWE9sPsyZ03MoLTj17IAleWkcqm/HueEXU95f20ZjR68CloiMq6hPHRqDJSIisSwSuwjuPdbKjiMtfGjpqVuvIDDRRXtPH/Xtwy+m/FZF//grBSwRGT9RH7C6NAZLRERiWGFGMk0dvXT7+rwuZcSe2X4UgPcvmTLsvqOZSXD9gQYKMpIpDT5HRGQ8RH3A0iQXIiISy/qnaq9rG76FJ1ysr2hk7qSMEU1EUZIXCEuVI5hJcH1FIyvLck86aYaISChEf8Dqn+RCXQRFRCQGRdpaWH1+x6ZDjSyfMbJufMW5aZgN34JVUddOdVMnKzX+SkTGWdQHLHURFBGRWBZpAWvPsVZau3ycXTqydapSEuOZnJXCwYZTT9Xe3+3wioWTxlyjiMipRH3A6uztIyHOSIyP+pcqIiLyLpEWsDYcbARgxQhbsKB/JsFTt2A9vf0oZ0zLpjhX469EZHxFfero7PGr9UpERGJWfnogYNW0dnlcychsqGigKDOZ6XmpI37OjPw0Dp1iDNbR5i7ePtTEexep9UpExl/0B6zePo2/EhGRmJWUEEdeehI1kdKCVdHI2aV5o5qIoiQvjZrW7uPjrgd7dkege+BViyeHpEYRkVOJ+oDV3dunRYZFRCSmTc5K4Vhz+LdgHW7qpLqpk+UzRjb+ql9JfmAx4pO1Yj31zlFmFaYzuyhzzDWKiAwn6pNHZ2+fugiKiEhMm5ydwpEICFj946/OHuVMfzPy+tfCevdEFzUtXbx5oJ73nTH8mloiIqGggCUiIhLlJmencKwl/APWxooG0pLiWTBldC1N/YsND9WC9futR/A7WL10akhqFBEZTvQHrJ4+UhSwREQkhk3OSqG+vYdu39BjlMLF+opGlpXkkDDKmX9z0pIoykxmc2XTux57YsthFk7JUvdAEZkwUR+wunr7SNUkFyIiEsMmZ6cAUNMSvhNdtHb1sutoy6imZx/oormFvLK3jj6/O76toq6dLZVNar0SkQkV9QFLXQRFRCTWTc4KBKxwHof19qEm/A5WjHCB4cEunltIc2cvW6qajm/73eZqzOAaBSwRmUAKWCIiIlFuSrAF62gYj8PacLCROINlJacXsC6YXYAZvLS7FoD6tm5++uoBLplbyJTska+pJSIyVlEfsLp6/VoHS0REYtqk/oDV3OlxJSe3oaKBBVOyyEhOOK3n56YncWZxDi/tCQSs7z67m86ePv7u/QtCWaaIyLCiP2D19JGSoIAlIiKxKzM5gfSk+LDtItjb52dzZRMrRrn+1WAXzy1kS1UT//r0Lh5eX8knzy3V5BYiMuGiPmB19vaRmhT1L1NEROSkzIxJYTxV+9aqJjp6+jhnZv6YjnPFgkk4Bz96aT/LpufwF1fMCVGFIiIjd3rt8BGit8+Pz+80BktERGLe5KzwXWx43f56gDEHrDOKs3nxry6hIDP5tLsaioiMVVQ37XT0BNb70DpYIiIS6yZnp3AsTAPW6/vrWTAli9z0pDEfq7QgXeFKRDwV1QGrpbMXgKzURI8rERER8dbkrBSOtXafsE5UOOjq7WPjwUbOmzW21isRkXAR1QGrtcsHQFaKApaIiMS2Kdkp9Pkd9W3htdjw24ea6Pb5FbBEJGpEdcBq6epvwVJXARERiW2TwnSx4XX764gzOLssz+tSRERCIroDVn8XQbVgiYhIjOtfbDfcAtYb5Q2cMS1b12oRiRrRHbDURVBERASAabmBgHW4KXwWG+7x+dlS1cTZpWq9EpHoEdUBq1VdBEVERADITUskNTGeqsbwCVg7j7TQ7fOzrGRsCwyLiISTqA5YLZ2BFixN1yoiIrHOzJiWm0p1U4fXpRz39qFGAM6akeNtISIiIRTdAaurl/SkeBLio/plioiIjEhxbmpYtWBtOtTElOyU4+PDRESiQVQnj5bOXq2BJSIiEjQtJ5XqMBqDtelQI8tKcrwuQ0QkpKI6YLV2+TTBhYiISFBxbhpNHb20dfu8LoWa1i6qGjs5S+OvRCTKRHXAaunqJTNF469ERETgTzMJVodBN8G3DzUBaIILEYk6UR+w1EVQREQkoLg/YIXBRBebDjaSGG8smprldSkiIiEV3QGr00eWWrBEREQAKM4JBKxwmOjijfJ6lk7PISUx3utSRERCKqoDVqtasERERI4ryEgmKSHO8y6CLV29vFPdzLkz8z2tQ0RkPERtwHLO0dLl0xgsERGRoLg4Y1pOKlUezyS4/kADfgfnzFLAEpHoE7UBq6Onjz6/0yyCIiIiA4TDWljr9teTlBCnGQRFJCpFbcBq6eoFUBdBERGRAablpHreRXBdeT3LS3I1/kpEolLUBqzWrsAaH+oiKCIi8ifFuanUtXXT1dvnyfmbOnrYcaSFc9U9UESiVNQGrJbOYAuWugiKiIgcNz0vDYDKBm+man+jvAHnUMASkagVvQFLXQRFRETepTQ/HYADde2enP+N8npSE+M5szjHk/OLiIy36A1YnYEugloHS0QkOpnZVWa228z2mdntQzyebGa/Dj7+ppmVBrevNLPNwa8tZvbhCS/eQ6UF3gasdfvrWVGaS1JC1P4JIiIxLmp/u7UGW7Ay1UVQRCTqmFk8cA9wNbAQuNHMFg7a7XNAo3NuNvAD4O7g9m3ACufcUuAq4H/MLGY+jctOTSQ/PYmK+okPWPVt3ew+1so5Wv9KRKJY1AasFk1yISISzVYC+5xz5c65HuBhYPWgfVYD9wdvPwpcbmbmnOtwzvmC21MANyEVh5GygnTKayc+YL1R3gBo/JWIRLfoDVidvSQnxGkKWBGR6DQNqBxwvyq4bch9goGqGcgHMLNVZrYdeAf40oDAdQIzu8XMNpjZhtra2hC/BO+UFqR70oL1+v46MpITWDIte8LPLSIyUaI3YHX1aoILEREZknPuTefcIuBs4JtmlnKS/e51zq1wzq0oLCyc2CLHUVlBOsdaumnvHjJXjpt15fWcXZpLQnzU/vkhIjKygDWCgcRfMrN3ggOGXx2iH/yEa+nyqXugiEj0qgamD7hfHNw25D7BMVbZQP3AHZxzO4E2YPG4VRqGyoITXUxkK9axli7Ka9vVPVBEot6wAWuEA4l/5Zw7Izhg+F+B74e60NFq6ezVGlgiItFrPTDHzMrMLAm4AVgzaJ81wKeCt68FnnfOueBzEgDMbAYwH6iYmLLDw/GAVTdxa2G9UR7ItufOLJiwc4qIeGEkTTzHBxIDmFn/QOId/Ts451oG7J9OGAwYbunyka0ugiIiUck55zOz24BngHjgPufcdjO7C9jgnFsD/BR4wMz2AQ0EQhjABcDtZtYL+IE/c87VTfyr8M6f1sJqm7BzrttfT1ZKAgunZk3YOUVEvDCSgDXUQOJVg3cys1uBvwSSgMuGOpCZ3QLcAlBSUjLaWkeluaOH6bmp43oOERHxjnNuLbB20LY7BtzuAq4b4nkPAA+Me4FhLDUpninZKRyYwBas1/fXs7Isn/g4m7Bzioh4IWSjTJ1z9zjnZgF/A3zrJPtM2GDhurYeCjOTx/UcIiIikao0P33CWrCqmzo51NCh8VciEhNGErBGMpB4oIeBD42hpjHr6PHR1u2jKHPISaFERERi3szCdPbVtOHc+PfqX7c/MP7qPAUsEYkBIwlYww4kNrM5A+6+H9gbuhJHr7a1G0AtWCIiIiexcGoWLV0+qho7x/1c6/bXk5uWyLxJmeN+LhERrw07BmuEA4lvM7MrgF6gkT/N2uQJBSwREZFTWzglMNnEjiMtTM9LG7fzOOd4fX8d58zMJ07jr0QkBoxooagRDCT+ixDXNSbHA1aGApaIiMhQ5k/OIs5g++EW3rto8ridZ/vhFo40d/G1K4rG7RwiIuEkKpdSr1ELloiIyCmlJsUzszCDHYdbht95DJ7dcYw4g8sXKGCJSGyIyoBV29pNfJyRl57kdSkiIiJha9HULHYcbh7Xczy7/SgrSvPIV68SEYkRURuw8tOTtNaGiIjIKSycksXh5i4a23vG5fiH6jvYdbSV9yycNC7HFxEJR9EZsNq61T1QRERkGIumZgOBiS7Gw7M7jgKM6xgvEZFwE50Bq1UBS0REZDgLpwZmEtw+Tt0En9p2lAVTssZ1lkIRkXATlQGrprWLIgUsERGRU8pLT2JKdgrvVIe+BauqsYONBxv5wJIpIT+2iEg4i7qA5fc76tp61IIlIiIyAitK83izvB7nXEiP++SWIwBcc+bUkB5XRCTcRV3Aauzooc/vtAaWiIjICJw/K5+a1m7217aF9LhPbK7mrJIcdQ8UkZgTdQGrtq1/DawUjysREREJf+fNKgDg9f31ITvm3mOt7DraqtYrEYlJURewalq0yLCIiMhITc9LZVpOKq/vC13A+t3mauIM3qfxVyISg6IuYNW2BgKWJrkQEREZnplx3qx81pXX4/ePfRyW3+94fFM1F80tpEi9SUQkBkVfwGpTC5aIiMhonD+7gObO3pCsh7WuvJ7DzV189KziEFQmIhJ5oi9gtXaTlhRPenKC16WIiIhEhHNn5QPw0p7aMR/r0Y1VZKYkcOXCSWM+lohIJIq6gLX7aCslmrFIRERkxCZlpXBWSQ5Pbjk8puO0dft4ettRPnjmVFIS40NUnYhIZImqgNXV28dbFQ2cP7vA61JEREQiyuql09h1tJVdR0+/m+Bjm6ro7O3juuXqHigisSuqAtb6igZ6fH4umKOAJSIiMhrvO2MK8XHGms2n14rV53fc9+oBlpXksKwkN8TViYhEjqgKWK/srSMpPo5VZXlelyIiIhJRCjOTOX92AU9sPoxzo59N8Lmdx6io7+DzF8wch+pERCJH1AWss2bkkJakCS5ERERGa/WZU6lu6mTdaSw6/NNXDjAtJ5X3LtLkFiIS26ImYNW2drPzSAsXzin0uhQREZGI9P4lUyjMTOaeF/eN6nnP7zrGWxUNfP7CMhLio+ZPCxGR0xI1vwWf33UMgAs1/kpEROS0pCTG88WLZvLavno2Hmwc0XO6evu4c80OZhWm8/FVM8a5QhGR8BcVAau3z889L+xnwZQsFk/N9rocERGRiHXTqhLy0pP4z+f3jmj//3mpnEMNHdy1ejFJCVHxZ4WIyJhExW/CX6+v5FBDB99471zi4szrckRERCJWWlICt1w0kxd31/LE5upT7vv6vjr+4/m9fGDJFC2RIiISFPEBq6PHx38+v5cVM3K5dF6R1+WIiIhEvM9fUMaKGbn87WPvcKCufch9Kura+fKDm5hZkM53PnLGBFcoIhK+IjpgOef45mPvUNvazTffNx8ztV6JiIiMVUJ8HP9x4zISE+L4zM/eYs+x1hMef6eqmev+Zx1m8NNPnU1mSqJHlYqIhJ+Ins/8/tcreGLzYb7x3nksn6G1r0REREJlak4qP/3UCr74wCY+dM9r3LSyhNlFGWytbubxTdXkpSfx4OdXUZKf5nWpIiJhJWIDVlNHD999dg9XLpzEly+e5XU5IiIiUWf5jDx+/+cX8De/3cov3jhIj89PRnICl80v4h+uWUhRZorXJYqIhJ2IDVg5aUn8+ovnMD0vTRNbiIiIjJPJ2Snc/9mV9Pb5qWrspDg3lUStdSUiclIRG7AAFmlKdhERkQmRGB9HWUG612WIiIQ9fQQlIiIiIiISIgpYIiIiIiIiIaKAJSIiIiIiEiIKWCIiIiIiIiGigCUiIiIiIhIiClgiIiIiIiIhooAlIiIiIiISIgpYIiIiIiIiIaKAJSIiIiIiEiIKWCIiIiIiIiGigCUiIhHJzK4ys91mts/Mbh/i8WQz+3Xw8TfNrDS4/Uoz22hm7wT/vWzCixcRkailgCUiIhHHzOKBe4CrgYXAjWa2cNBunwManXOzgR8Adwe31wEfdM6dAXwKeGBiqhYRkViggCUiIpFoJbDPOVfunOsBHgZWD9pnNXB/8PajwOVmZs65t51zh4PbtwOpZpY8IVWLiEjUU8ASEZFINA2oHHC/KrhtyH2ccz6gGcgftM9HgU3Oue6hTmJmt5jZBjPbUFtbG5LCRUQkuiV4deKNGzfWmdnBEByqgEB3j0gRafVC5NUcafVC5NUcafVC5NUcafXC2GueEapCRsLMFhHoNviek+3jnLsXuDe4f62uWxEj0mqOtHoh8mqOtHoh8mqOtHphnK5bngUs51xhKI5jZhuccytCcayJEGn1QuTVHGn1QuTVHGn1QuTVHGn1woTXXA1MH3C/OLhtqH2qzCwByAbqAcysGHgc+KRzbv9ITqjrVuSItJojrV6IvJojrV6IvJojrV4Yv5rVRVBERCLRemCOmZWZWRJwA7Bm0D5rCExiAXAt8LxzzplZDvAH4Hbn3GsTVbCIiMQGBSwREYk4wTFVtwHPADuBR5xz283sLjO7JrjbT4F8M9sH/CXQP5X7bcBs4A4z2xz8KprglyAiIlHKsy6CIXSv1wWMUqTVC5FXc6TVC5FXc6TVC5FXc6TVCxNcs3NuLbB20LY7BtzuAq4b4nn/CPzjuBd4cpH2fxtp9ULk1Rxp9ULk1Rxp9ULk1Rxp9cI41WzOufE4roiIiIiISMxRF0EREREREZEQUcASEREREREJkYgNWGZ2lZntNrN9Znb78M+YeGY23cxeMLMdZrbdzP4iuP1OM6seMLj6fV7X2s/MKszsnWBdG4Lb8szs/8xsb/DfXK/r7Gdm8wa8j5vNrMXMvhpu77GZ3WdmNWa2bcC2Id9XC/iP4Pf2VjM7K0zq/Tcz2xWs6fHgTGyYWamZdQ54r3880fWeouaTfh+Y2TeD7/FuM3tvmNT76wG1VpjZ5uB2z9/jU/w+C9vv43AT7tetSLxmga5b41RjRF2zTlFz2F63Iu2adYqadd0ainMu4r6AeGA/MBNIArYAC72ua4g6pwBnBW9nAnuAhcCdwF95Xd9Jaq4ACgZt+1cC0xlDYBauu72u8xTfF0cJLPoWVu8xcBFwFrBtuPcVeB/wFGDAOcCbYVLve4CE4O27B9RbOnC/MHuPh/w+CP4cbgGSgbLg75N4r+sd9Pj3gDvC5T0+xe+zsP0+DqevSLhuReI1K1irrluhryuirlmnqDlsr1uRds06Wc2DHtd1K/gVqS1YK4F9zrly51wP8DCw2uOa3sU5d8Q5tyl4u5XAVMLTvK3qtKwG7g/evh/4kHelnNLlwH7n3EGvCxnMOfcy0DBo88ne19XAL1zAG0COmU2ZkEKDhqrXOfesC0yNDfAGgYVdw8ZJ3uOTWQ087Jzrds4dAPYR+L0yYU5Vr5kZ8DHgoYms6VRO8fssbL+Pw0zYX7ei6JoFum6NSaRdsyDyrluRds0CXbdGI1ID1jSgcsD9KsL8ImBmpcAy4M3gptuCzY/3hVPXBcABz5rZRjO7JbhtknPuSPD2UWCSN6UN6wZO/MEO1/e438ne10j4/v4sgU95+pWZ2dtm9pKZXehVUScx1PdBuL/HFwLHnHN7B2wLm/d40O+zSP4+nkgR9X5E0DULdN2aKJH+sx4p161IvGaBrlsniNSAFVHMLAP4LfBV51wL8CNgFrAUOEKgSTVcXOCcOwu4GrjVzC4a+KALtKGG3dz+ZpYEXAP8JrgpnN/jdwnX93UoZvZ3gA94MLjpCFDinFtGYDHXX5lZllf1DRJR3wcD3MiJf3SFzXs8xO+z4yLp+1hOLsKuWaDr1oQL1/f0ZCLouhUx3wND0HVrgEgNWNXA9AH3i4Pbwo6ZJRL4T33QOfcYgHPumHOuzznnB36CB828J+Ocqw7+WwM8TqC2Y/1NpMF/a7yr8KSuBjY5545BeL/HA5zsfQ3b728z+zTwAeDjwV9KBLss1AdvbyTQN3yuZ0UOcIrvg3B+jxOAjwC/7t8WLu/xUL/PiMDvY49ExPsRadcs0HVrAkXkz3okXbci8ZoFum4NJVID1npgjpmVBT8BugFY43FN7xLsj/pTYKdz7vsDtg/sz/lhYNvg53rBzNLNLLP/NoHBodsIvLefCu72KeAJbyo8pRM+OQnX93iQk72va4BPBmezOQdoHtCU7Rkzuwr4a+Aa51zHgO2FZhYfvD0TmAOUe1PliU7xfbAGuMHMks2sjEDNb010fSdxBbDLOVfVvyEc3uOT/T4jwr6PPRT2161Iu2aBrlsTLOJ+1iPtuhWh1yzQdevdnIeze4zli8BMH3sIJOK/87qek9R4AYFmx63A5uDX+4AHgHeC29cAU7yuNVjvTAKz1GwBtve/r0A+8EdgL/AckOd1rYPqTgfqgewB28LqPSZwET0C9BLo0/u5k72vBGavuSf4vf0OsCJM6t1HoG9y//fyj4P7fjT4/bIZ2AR8MIze45N+HwB/F3yPdwNXh0O9we0/B740aF/P3+NT/D4L2+/jcPsizK9bp/g/Dqvfp4Nq1nVrfOqLqGvWKWoO2+vWSeoN22vWyWoObv85um6d8GXBA4qIiIiIiMgYRWoXQRERERERkbCjgCUiIiIiIhIiClgiIiIiIiIhooAlIiIiIiISIgpYIiIiIiIiIaKAJRLmzOwSM/u913WIiIiMhK5bEusUsEREREREREJEAUskRMzsE2b2lpltNrP/MbN4M2szsx+Y2XYz+6OZFQb3XWpmb5jZVjN73Mxyg9tnm9lzZrbFzDaZ2azg4TPM7FEz22VmDwZXJxcRETltum6JjA8FLJEQMLMFwPXA+c65pUAf8HEgHdjgnFsEvAT8Q/ApvwD+xjm3hMBq4f3bHwTucc6dCZxHYMV0gGXAV4GFwEzg/HF+SSIiEsV03RIZPwleFyASJS4HlgPrgx/SpQI1gB/4dXCfXwKPmVk2kOOceym4/X7gN2aWCUxzzj0O4JzrAgge7y3nXFXw/magFHh13F+ViIhEK123RMaJApZIaBhwv3PumydsNPv7Qfu50zx+94DbfehnV0RExkbXLZFxoi6CIqHxR+BaMysCMLM8M5tB4Gfs2uA+NwGvOueagUYzuzC4/WbgJedcK1BlZh8KHiPZzNIm8kWIiEjM0HVLZJzo0wSREHDO7TCzbwHPmlkc0AvcCrQDK4OP1RDo7w7wKeDHwQtROfCZ4Pabgf8xs7uCx7huAl+GiIjECF23RMaPOXe6Lb8iMhwza3POZXhdh4iIyEjouiUyduoiKCIiIiIiEiJqwRIREREREQkRtWCJiIiIiIiEiAKWiIiIiIhIiChgiYiIiIiIhIgCloiIiIiISIgoYImIiIiIiISIApaIiIiIiEiIKGCJiIiIiIiEiAKWiIiIiIhIiChgiYiIiIiIhIgCloiIiIiISIgoYImIiIiIiISIApbIODGzH5vZ33tdh4iIyKmE4nplZj83s38MVU0ikSzB6wJEwpWZVQCfd849dzrPd859KbQViYiIvJuuVyLhRS1YIqfBzPThhIiIhD1dr0QmngKWyBDM7AGgBHjSzNrM7K/NzJnZ58zsEPB8cL/fmNlRM2s2s5fNbNGAYxzvLmFml5hZlZl93cxqzOyImX1mBHW838zeNrMWM6s0szsHPX6Bmb1uZk3Bxz8d3J5qZt8zs4PB2l41s9SQvUEiIhIWwuV6NURdXzCzfWbWYGZrzGxqcLuZ2Q+Cx24xs3fMbHHwsfeZ2Q4zazWzajP7qxC8RSITTgFLZAjOuZuBQ8AHnXMZwCPBhy4GFgDvDd5/CpgDFAGbgAdPcdjJQDYwDfgccI+Z5Q5TSjvwSSAHeD/wZTP7EICZzQie/z+BQmApsDn4vO8Cy4HzgDzgrwH/MOcSEZEIE0bXq+PM7DLgO8DHgCnAQeDh4MPvAS4C5gbP8TGgPvjYT4EvOucygcUEw6FIpFGzscjo3Omca++/45y7r/92sHWp0cyynXPNQzy3F7jLOecD1ppZGzAPeONkJ3POvTjg7lYze4jARfN3wE3Ac865h4KP1wP1ZhYHfBY4xzlXHXzs9VG9ShERiXQTer0a5OPAfc65TcHzfTN4vtLgsTOB+cBbzrmdg8670My2OOcagcYRnk8krKgFS2R0KvtvmFm8mf2Lme03sxagIvhQwUmeWx+8WPXrADJOdTIzW2VmL5hZrZk1A18acPzpwP4hnlYApJzkMRERiQ0Ter0aZCqBVisAnHNtBD4EnOacex74L+AeoMbM7jWzrOCuHwXeBxw0s5fM7NxRnFMkbChgiZycG2bbTcBq4AoC3RxKg9sthDX8ClgDTHfOZQM/HnD8SmDWEM+pA7pO8piIiESfcLheDXQYmNF/x8zSgXygGsA59x/OueXAQgJdBb8R3L7eObeaQDfG3/Gn7o4iEUUBS+TkjgEzT/F4JtBN4FO5NOCfx6GGTKDBOddlZisJXCT7PQhcYWYfM7MEM8s3s6XOOT9wH/B9M5sa/OTyXDNLHof6RETEe+FwvRroIeAzZrY0eO35Z+BN51yFmZ0d7J2RSGCccRfgN7MkM/t4sNtiL9CCxg5LhFLAEjm57wDfMrMm4NohHv8FgS4Q1cAORt43fTT+DLjLzFqBOxjwaZ5z7hCBrhRfBxoITHBxZvDhvwLeAdYHH7sb/byLiESrcLheHRdcj+vvgd8CRwj0qLgh+HAW8BMC46sOEgh9/xZ87GagItiN8UsExnKJRBxzbqhWZRERERERERktfaItIiIiIiISIgpYIh4zs+3BxSEHf6lrhIiIhA1dr0RGRl0ERUREREREQsSzhYYLCgpcaWmpV6cXEZEws3HjxjrnXKHXdZyMrlsiIjLQya5bngWs0tJSNmzY4NXpRUQkzJjZweH38o6uWyIiMtDJrlsagyUiIiIiIhIiClgiIiIiIiIhooAlIiIiIiISIgpYIiIiIiIiIaKAJSIiIiIiEiIKWCIiIiIiIiGigCUiIiIiIhIiClgiIiIiIiIhooAlIiIiIiISIgpYIiIiIiIiIaKAJSIiIiIiEiIKWCIiIiIiIiEybMAys/vMrMbMtp3kcTOz/zCzfWa21czOCn2ZIiIiIiIi4W8kLVg/B646xeNXA3OCX7cAPxp7WSIiItGnuaPX6xJERGScJQy3g3PuZTMrPcUuq4FfOOcc8IaZ5ZjZFOfckVAVKTISLV29PLH5MM9uP8qeY63UtnZ7XZJITCjISOatv7vC6zLC3vbDzXz4nte5+ozJXL14Mm3dfUzNSeG8WQVelyYiIiE0bMAagWlA5YD7VcFt7wpYZnYLgVYuSkpKQnBqkYAnNlfzt4+9Q3tPH7OLMjh/dgFTs1Mx87oykeiXlhSKS0n0y0lL4qZVJfx2YxVPbD58fPvl84u460OLmZaT6mF1IiISKhN6VXTO3QvcC7BixQo3keeW6HX307v40Yv7Obs0l2+9fyFLirMxJSsRCTPTclK585pF/PVV89h9tJWctCT+b8dR/v25vdz80zdZc9sFZCQrrIqIRLpQzCJYDUwfcL84uE2i1B93HuMbv9lCVWMHbd0+fruxio0HG3HO0dXbR0vXxI0xqG7q5Ecv7ucjy6bxqy+cw5nTcxSuRGKEmV1lZruDkyzdPsTjyWb26+Djb/Z3dzezj5vZ5gFffjNbOlF1pyUlsKwkl7KCdG65aBb/+6mzqahr5/bfbiXQ215ERCJZKD4qWwPcZmYPA6uAZo2/8obf74iLG/9w8YPn9rCtuoXfbz1CQrzR2uUDYGp2CrVt3RjGf9y4jKsWTx73Wp7ZdhSA2y6bTWK8Vh0QiRVmFg/cA1xJoGv6ejNb45zbMWC3zwGNzrnZZnYDcDdwvXPuQeDB4HHOAH7nnNs8oS9ggHNn5fP198zj357ZzfmzC7hxpbrQi4hEsmEDlpk9BFwCFJhZFfAPQCKAc+7HwFrgfcA+oAP4zHgVKyf3wu4avviLjVyxsIjL5k9ix+EW5k/O5GNnTx/+yaNwoK6dbdUtfOHCMurbeuhzjk+cM4P9NW28sLuGmYUZvFFez62/2sT3P3Ymq5dOo63bx3+/sI9PnDODqSEeY/D09qPMm5TJzMKMkB5XRMLeSmCfc64cIPgh32pgYMBaDdwZvP0o8F9mZu7EZqIbgYfHv9xT+/LFs3h1bx3/9IedXDy3MOS/K0VEZOKMZBbBG4d53AG3hqwiGbWu3j7+4Ynt5KYn8ureOta+c5SEOMPnd9S2dXPrpbNDdq7fbwkMzP7M+WUn/AFwdmkeNwQ/dW3v9vG5+9fz1V9vpqXLx9qtR1hXXk9bt4+7Vi8OWS21rd2sr2jgzy+bE7JjikjEGGqCpVUn28c55zOzZiAfqBuwz/UEgpin4uKMuz+6hPf+8GX+9vF3+Nmnz1Z3ZxGRCKU+VVHgf18p51BDB9//2FLWffNynv7qhWy/6718eNk0/u2Z3Ty2qSpk5/r91iOsmJF7yk9X05MT+PlnVnLRnEL+/nfbeONAPTML0nlyy2F6fP4hn9Pc0cvPXztAV2/fiGv5vx3HcA6unoCuiCISfcxsFdDhnNt2in1uMbMNZrahtrZ2XOspyU/jG++dx4u7a3l1X93wTxARkbCkgBXhXtlby3+9sI+rF0/m/NkFpCcnMH9yFskJ8Xz3ujMpK0jnD1tDMyRux+EWdh9r5QNLpgy7b0piPPd+cjmfPq+U7157Jt/6wAIaO3p5ac+f/kBp7/ZR3dTJ7qOtfPhHr3Hnkzt4MthC9tBbh/inP+w42eEBeHbHUWbkpzF/cubYXpiIRKKRTLB0fB8zSwCygfoBj98APHSqkzjn7nXOrXDOrSgsLBxz0cP5+DklFGQk8fPXKsb9XCIiMj40H2wEcs5RUd/BH3ce4+6ndzGrMGPIrnfxccbyGbm8sKsG59yYupvsPtrKZ3++nsyUBN6/ZOqInpOcEM+d1ywCoLfPT356Eo+/XUVeehIPv3WI3289QmewxSonLZH0pHg2HWriuhXTuf/1Cspr2/nGe+eTlPDuzwH6/I4NFY2sXjpV3WhEYtN6YI6ZlREIUjcANw3aZw3wKWAdcC3wfP/4KzOLAz4GXDhhFY9AckI8N62awX8+v5eKunZKC9K9LklEREZJASsC/dszu/nvF/cDcO7MfH5883KyUxOH3HdZSQ6PbqyisqGTkvy00zpffVs3H/ufdSQnxPHIF8+lMDN51MdIjI/jg2dO5eevV7D2naOkJ8XzoWVTObM4h87ePq5YMIm/+9023j7USFNHD7uPteJcINidUZz9ruPtOtpCW7ePs0vzTus1iUhkC46pug14BogH7nPObTezu4ANzrk1wE+BB8xsH9BAIIT1uwio7J8kI5x8YlUJ//3CPn6x7iB3fHCh1+WIiMgoKWBFmK7ePh544yCXzCvkb9+3gNmFGaecmn3p9BwA3q5sPO2A9cz2YzR39vLkbRewYErWaR0D4DPnl3K4qZPL5hfxgTOnvmtBzWXTc/jP5/fy0p5a+uf42lzVNGTA2niwEYAVpbmnXY+IRDbn3FoCM9kO3HbHgNtdwHUnee6LwDnjWd/pKspK4X1nTOE3Gyr5m6vnkZwQ73VJIiIyChqDFWGe31VDa5ePz11QxtxJmcOuezVvUiapifFsrmwCGNUkEv2e2X6Ukrw0Fk87/XAFMCM/nXs/uYIbVpa8K1wBnDUjF7+De18uJyk+jpy0RLYG6x5sfUUjk7NSmKapjEUkCn142TRau328pskuREQijgJWhHlsUzVFmcmcN6tgRPsnxMdxxrRs3j7UxE9eLmfpXc/yRnn98E8Maunq5fX9dbx30aRxH+vU39q2/XALS6fnsHR6Dlurmofcd0NFAytKczX+SkSi0nmz88lMTuCpd456XYqIiIySAlYEaWjv4cXdNaxeOpX4YVquBlpWksO26mbufnoXPT4/tz64ieqmzhE994VdNfT2Od67aPynQs9OTWR2UWDB4JVleZxZnMPemlbau30n7Ffd1MmR5i6NvxKRqJWcEM/lC4r4v53H8PUNvbyFiIiEJwWsCPL7rYfx+R0fXlY8quctnZ6Dz+8oyEjmN186jx6fny89sJFu3/DdBZ/dfoyCjGTOKpmYsU5nleQAwYA1PRu/g23VJ7ZibahoADT+SkSi21WLJ9PU0cubBxq8LkVEREZBAStCOOd46K1KFk3NYuHU0Y2FOndWPmdOz+Hfb1jK8hm5fO9jZ/JOdTPfWbvrlM/z9fl5aU8tVy4sGnasV6hctXgyswrTWT4jlyXFOQDv6ia4bn89mcH1vkREotXFc4tITYznqW2hWctQREQmhgJWhHinupmdR1q4YWXJqJ+bk5bEE7eez6qZ+QC8Z9FkPnN+KT9/vYL/23HspM/bfjgwFfpIx3uFwmXzJ/HHr19CenICBRnJlBWk84s3Kqhp6QICQfPF3bVcMKdgVN0kRUQiTWpSPOfPzue1fSMfNysiIt5TwIoQD71VSUpiHKuXjmyR3+HcfvV85k/O5J/X7sTvd0Pu8+aBwEV91Uzvxjp9/2NnUt/Ww80/fYvmjl52H2vlaEsXl8wr9KwmEZGJsnxGHgfq2qlv6/a6FBERGSEFrAjQ3u1jzeZq3n/GVLJShl5QeLSSE+L5s0tnc6Cuned31Qy5z5vlDcwsSKcoMyUk5zwdy0py+cknV7C/to1/eXonL+6uBQJdZ0REol3/WNP+tf9ERCT8KWBFgOd31dDe08d1K0Y3ucVwrl48manZKfz01QPveqzP73irosHT1qt+588u4OZzZ/Dr9ZX8en0l8ydnMjnbu9AnIjJRzpiWTVJ8nAKWiEgEUcCKAE9vP0pBRnLIpyVPjI/jU+eVsq68nu2HT5xIYueRFlq7fKwqyw/pOU/XVy6bQ3pyAgfq2rl0vlqvRCQ2pCTGs3haFhsUsEREIoYCVpjr6u3jhV01vGfRpHGZ1OH6s6cD8NKe2hO2908LHA4tWAC56UncdulsAC5XwBKRGLJ8Ri7vVDWPaGkNERHxngJWmHt1bx0dPX1cNU4L/eakJZGSGEdzR+8J2zcdbKQ4N5Up2anjct7T8YULZ/LYn53HCi0wLCIxZPmMPHr6/O9aE1BERMKTAlaYe2rbUbJSEjhn5vh11ctOTaRpUMCqbeumODd8whVAXJxN2ILHIiLhQhNdiIhEFgWsMNbb5+e5nce4YsEkkhLG778qJzWJ5s4TA1ZLZy+ZIZqxUERETl9BRjJTslPYeaTV61JERGQEFLDC2JvlDTR39vLexePTPbBfdmoiTZ09J2xr7fKFbEp4EREZm7mTMtl9VAFLRCQSKGCFsae3HyE1MZ6L5ozvorrZaYk0d/pO2NbS2UtWasK4nldEREZm3uRM9tW24evze12KiIgMQwErTPn9jme2H+OSeYWkJsWP67myUxNp7vhTC5bf72jrUQuWiEi4mDspkx6fn4MNHV6XIiIiw1DAClNvVzZS29rNVePcPRAgJzXxhDFYrd0+nIPMFLVgiYiEg3mTMgHYo26CIiJhTwErTD297ShJ8XFcNgFrPmWnJtLe00dvsOtJSzBsZaWqBUtEJBzMLsrADHYfU8ASEQl3ClhhyDnHU9uOcv7s/AmZyS87LXCO/laslq5gwFIXQRGRsJCaFM+MvDT2KGCJiIQ9BawwtP1wC1WNnRPSPRACLVjA8bWwWrsCE15okgsRkfAxb7JmEhQRiQQKWGHome1HiTO4YsGkCTlff8A63oLVqRYsEZFwM29SJhX1HXT19nldioiInIICVhh6ettRVpblkZ+RPCHny0lLAqA5uBZWS38LlgKWiEjYmDs5kz6/o7y23etSRETkFBSwwsy+mjb21rRx1aKJ6R4Ip2jBUhdBEZGwMbsoA4B9tW0eVyIiIqeigBVmntl+FID3TGDAyjnJGKyMZAUsEZFwMSMvHYBD9WrBEhEJZwpYYeaZ7Uc5c3oOU3NSJ+ycWYNbsLp6SU+KJyFe3x4iIuEiNSmeSVnJVNRrsWERkXCmv6DDSFVjB1urmrl6gmYP7BcfZ2SmJBxvwWrp7NUaWCIiYWhGXjqHFLBERMKaAlYYeWb7MQDeO4HdA/tlpyae0IKlCS5ERMLPjPw0KtRFUEQkrClghZFnth1l/uRMygrSJ/zcOWkDAlanTxNciIiEodKCdGpau+no8XldioiInIQCVpiobe1m/cEGT1qvINCC1dQRmKa9tbuXTLVgiYiEnZK8NAAONaiboIhIuFLAChOv7avDObhy4cQsLjxYTmrSiS1YKWrBEhEJN6X5gR4OBzUOS0QkbClghYnth5tJSohj3uRMT86fNXgMlia5EBEJOyX5gRasgxqHJSISthSwwsSOIy3Mm5RJokdTo/ePwXLO0drl0yQXIiJhKDs1kdy0RE3VLiISxhSwwoBzjh2HW1g0NcuzGrJTE+ntc9S2ddPnd2Sqi6CISFgqyddU7SIi4UwBKwwcbemisaOXhR4GrJxgl8DKhk4AdREUEQlTpZqqXUQkrClghYHt1S0ALJzibQsWQGVwZip1ERQRCU8z8tI43NRJj8/vdSkiIjKEEQUsM7vKzHab2T4zu32Ix2eY2R/NbKuZvWhmxaEvNXrtONKCGcz3MGBNy00F4PX9dQBaB0tEJEwV56Xhd3C0ucvrUkREZAjDBiwziwfuAa4GFgI3mtnCQbt9F/iFc24JcBfwnVAXGs12HG6hND+djGTvQs0Z07KZU5TB429XA2gdLBGRMDU1O/CB2JHmTo8rERGRoYykBWslsM85V+6c6wEeBlYP2mch8Hzw9gtDPC6nsONIi6fdAwHMjE+cM4PePgegdbBEJOyNoHdFspn9Ovj4m2ZWOuCxJWa2zsy2m9k7ZpYyocWPweTsQKlHW9SCJSISjkYSsKYBlQPuVwW3DbQF+Ejw9oeBTDPLH3wgM7vFzDaY2Yba2trTqTfqtHT1cqihw9MJLvp9+KxppCXFA5rkQkTC2wh7V3wOaHTOzQZ+ANwdfG4C8EvgS865RcAlQO8ElT5m/QHrcJMClohIOArVJBd/BVxsZm8DFwPVQN/gnZxz9zrnVjjnVhQWFobo1JFtS2UTAEuKs70thMDEFh9aNo3EeNM07SIS7kbSu2I1cH/w9qPA5WZmwHuArc65LQDOuXrn3LuuWeEqIznh/7d35+FxnvW9/99f7YttSZb3LbaJSeLswWQhYSmhJUnbhLKdQJfQw2kOlLT0UGjDgQZK2+tXejjQLUATwiGkQCBAwLRpAymFsiQhzm5ndZzF8pJ4k7xIsrb798eMHFmRbdma0TOjeb+uS5dnnnk089VY1u2P7vv+PkxvqGGrSwQlqSSN53/Rm4DFI+4vyh87IKW0mfwMVkRMA96SUuosUI1T2n3PdhIBZyxuzboUAD5yyUm85axF1NdUZ12KJB3OWKsrzjnUOSmlgYjoAtqBlwMpIm4HZgM3p5T+pvglF86Clka22ORCkkrSeGaw7gFWRMSyiKgDLgdWjzwhImZFxPBzfRj4YmHLnLru37iLl8+ZXjJNJZrra3jFcW1ZlyFJxVQDXAD8Zv7P34iIC8c6sVSXts9raTBgSVKJOmLASikNAFcBtwOPAt9IKa2LiE9ExKX5014HPB4RTwBzgb8qUr1TytBQ4v7nOjlzSWvWpUhSuTni6oqR5+T3XbUAO8jNdv1XSml7SqkbuA04a6wXKdWl7fMNWJJUssa10SaldBu5AWjksWtG3P4mufXtOgobtu+jq6efs5Y4YyRJR+nA6gpyQepy4J2jzlkNXAHcCbwV+GFKaXhp4J9ERBPQR27v8GcmrfICmN/SyPa9++kbGKKuplDbqSVJheBP5Qzd99wuAM46rjXbQiSpzIxzdcUNQHtErAc+AFyd/9xdwKfJhbQHgPtSSv86yV/ChMzPdxJ83lbtklRybBWXofuf62RGQw3LZ03LuhRJKjvjWF3RC7ztEJ/7z+RatZel4VbtW7p6WTyzKeNqJEkjOYOVofuf28UZS9qoqoqsS5EklZEFrcMBy1btklRqDFgZ6eru5/Hn97DKjn2SpKM0r6URwEYXklSCDFgZWfPsTlKCs5fNzLoUSVKZmVZfw/T6GrYasCSp5BiwMvKLp3dSV11VMhcYliSVl/mtDS4RlKQSZMDKyN1P7+T0xS001FZnXYokqQzNa2l0iaAklSADVga6+wZYu6mLVy51eaAk6djMnV5vm3ZJKkEGrAzc/1wnA0PJ/VeSpGM2a3o9O/b2MTSUsi5FkjSCASsDdz+9k6qAV9hBUJJ0jGZPq2dgKNHV0591KZKkEQxYGbjn6Z2sXDCD6Q21WZciSSpTs6bXA7B97/6MK5EkjWTAmmR9A0Pc99wuzl7annUpkqQyNmtaHQDbDFiSVFIMWJPs4U2d7B8Ycv+VJGlCZk8bnsHqy7gSSdJIBqxJ9oundwHwyqXuv5IkHbtZwwFrjzNYklRKDFiT7BdP7+D4OdNozw+MkiQdi5bGWmqqwj1YklRiDFiTaHAoseaZXS4PlCRNWFVV0D6tzoAlSSXGgDWJHtu6mz37BzjHgCVJKoBZ0+rdgyVJJcaANYl+tn47AK9casCSJE1cLmA5gyVJpcSANYluvX8zpy9qYUFrY9alSJKmgFnT6m1yIUklxoA1SR7ZvJtHt+zmzWctyroUSdIUMWt6Hdv39pFSyroUSVKeAWuSfPu+Dmqrg0tPX5B1KZKkKWL2tHr6BofY3TuQdSmSpDwD1iQYGBziOw9s5vUnzqGtuS7rciRJU8SBa2G5D0uSSoYBaxL85+Pb2L53v8sDJUkF5cWGJan0GLAmwZfvfIb5LQ1ceOKcrEuRJE0hs6cPz2DZql2SSoUBq8jWv7CXnzy5nd88Zwk11b7dkqTCmTUtt+x8257ejCuRJA3zf/xF9s93PUtddRWXn70k61IkSVNMW1Md1VXhDJYklRADVhH1Dw7xrXs7uOTUeQfWyUuSVChVVcHM5jqbXEhSCTFgFdGGbfvYs3+A153g3itJUnG0N9exc58zWJJUKgxYRfTIli4AVi6YkXElkqSpqrWpls7u/qzLkCTlGbCK6JHNu6mrqWL5rOasS5EkTVFtTXXs7HYGS5JKhQGriNZt3s2J86bbPVCSVDRtzXV0GrAkqWT4P/8iSSnxyJbdnOzyQElSEbU11bKru5+UUtalSJIwYBXNlq5eOrv7WTnfgCVJKp62pjoGhxK7eweyLkWShAGraB7ZvBuwwYUkqbjamnIXG3aZoCSVBgNWkazbvJsIOHGeAUuSVDxtzbUA7LKToCSVBANWkTyypYtl7c0019dkXYokaQprzc9g7fJaWJJUEgxYRbB/YJCfP7WDM5e0ZV2KJGmKmzkcsFwiKEklwYBVBD9+fBt7egf4tdPnZ12KJGmKazsQsFwiKEmlwIBVBN97aAttTbVccPysrEuRJE1x0xtqqAqXCEpSqTBgFVh33wB3PPI8l5w6n1ovMCxJKrKqqqCtqc4lgpJUIkwABfaDR56np3+QS09fkHUpkjSlRcRFEfF4RKyPiKvHeLw+Ir6ef/zuiFiaP740Inoi4oH8x+cnvfgCa22qpdMlgpJUEsYVsMYxiC2JiP+MiPsj4qGIuKTwpZaHHz++jVnT6njl0plZlyJJU1ZEVAPXAhcDK4F3RMTKUae9G9iVUjoe+AzwyRGPPZVSOiP/8Z5JKbqI2prq2OkSQUkqCUcMWOMcxD4KfCOldCZwOfDZQhdaLh7s6OSMxa1UVUXWpUjSVHY2sD6ltCGl1AfcDFw26pzLgBvzt78JXBgRU/KHc6tLBCWpZIxnBms8g1gChq+o2wJsLlyJ5WNPbz8btu/j1IWtWZciSVPdQmDjiPsd+WNjnpNSGgC6gPb8Y8vyqy5+HBGvLnaxxTaz2SWCklQqxnMV3LEGsXNGnfNx4PsR8QdAM/CGsZ4oIq4ErgRYsmTJ0dZa8tZu2k1KcNrilqxLkSQd2hZgSUppR0S8AvhORJycUto9+sRyGbfamurY2d1HSokpOkknSWWjUE0u3gF8KaW0CLgEuCkiXvLcKaXrUkqrUkqrZs+eXaCXLh0PdXQCcPqi1kzrkKQKsAlYPOL+ovyxMc+JiBpyKyx2pJT2p5R2AKSU7gWeAl4+1ouUy7jV2lRH38AQPf2DWZciSRVvPAFrPIPYu4FvAKSU7gQagIq7CNRDHV0samtkZnNd1qVI0lR3D7AiIpZFRB25/b+rR52zGrgif/utwA9TSikiZuf3FxMRy4EVwIZJqrsoZjbXAl5sWJJKwXgC1ngGseeACwEi4iRyAWtbIQstBw92dDp7JUmTIL+n6irgduBRco2W1kXEJyLi0vxpNwDtEbEe+AAw3AX3NcBDEfEAueYX70kp7ZzUL6DAWptyv9jzYsOSlL0j7sFKKQ1ExPAgVg18cXgQA9aklFYDfwxcHxH/i1zDi3ellFIxCy81O/f10bGrh98697isS5GkipBSug24bdSxa0bc7gXeNsbnfQv4VtELnERtwwHLToKSlLnxNLkYzyD2CHB+YUsrL8P7r05bZIMLSdLkcomgJJWOQjW5qHh3bdhJbXW4RFCSNOlcIihJpcOAVSA/W7+dM5e00Vw/rklBSZIKpqUxN4PV1eMMliRlzYBVAJ3dfazd3MX5L6u4xomSpBJQW13FtPoaLzYsSSXAgFUAdz61g5TgghXtWZciSapQLY21dPa4RFCSsmbAKoCfrt/OtPoaTnP/lSQpIy2Ntex2iaAkZc6AVQA/f2oH5y6fSW21b6ckKRutTbUuEZSkEmAimKAtXT08vX0fr3L/lSQpQ61NtXQ6gyVJmTNgTdCDGzsBOOu4tmwLkSRVtJbGOmewJKkEGLAm6MGOLmqrg5PmT8+6FElSBWtprKWrp4+UUtalSFJFM2BN0EMdnZw4bwb1NdVZlyJJqmCtTbX0DyZ6+gezLkWSKpoBawKGhhIPdXRx6qKWrEuRJFW41vzFhl0mKEnZMmBNwLM7u9nTO8DpBixJUsZamwxYklQKDFgT8FBHJ4DXv5IkZa6lsQ7Aiw1LUsYMWBPw4MYuGmqrWDFnWtalSJIqXEt+iWCXM1iSlCkD1gQ81NHJyQtaqPECw5KkjA0vEezyWliSlCmTwTFKKfH41j2cvGBG1qVIkvTiHiwDliRlyoB1jHb3DLBn/wBLZjZlXYokSTTWVlNXXWWTC0nKmAHrGG3c1Q3AorbGjCuRJAkighn5iw1LkrJjwDpGHbt6AFjU5gyWJKk0tDbVugdLkjJmwDpGHc5gSZJKTGtjrUsEJSljBqxj1LGrh+n1NQfa4kqSlLXWJgOWJGXNgHWMOnZ1s7CtkYjIuhRJkoDcxYZdIihJ2TJgHaOOXT3uv5IklZSWxlo6u21yIUlZMmAdg5RSPmC5/0qSVDpam2rZ1zdI/+BQ1qVIUsUyYB2Drp5+9u4fMGBJkkrK8MWGXSYoSdkxYB0DW7RLkkrRcOMlG11IUnYMWMdg405btEuSSk9rUx2AFxuWpAwZsI7B8AzWYmewJEklxBksScqeAesYdOzqZnpDDS1NXgNLklQ6WhvdgyVJWTNgHYNndnS7/0qSVHKGm1w4gyVJ2TFgHYPHt+7hxHnTsy5DkqSDTG+oJQI6ncGSpMwYsI7Srn19bN3da8CSJJWc6qpgRkMtXV5sWJIyY8A6So9u3Q3ASfNnZFyJJEkv1dJY6x4sScqQAesoPbZlDwAnzncGS5JUelqbal0iKEkZMmAdpce27qa9uY7Z0+qzLkWSpJdoaay1yYUkZciAdZQe27qHk+bPICKyLkWSpJdobapziaAkZciAdRQGBofsIChJKmktjTV02uRCkjJjwDoKz+zoZv/AECfa4EKSVKJaG3MzWENDKetSJKkiGbCOwmP5DoLOYElS9iLiooh4PCLWR8TVYzxeHxFfzz9+d0QsHfX4kojYGxEfnLSiJ0FrUy1DCfb2DWRdiiRVJAPWUXh0y26qq4IVc6dlXYokVbSIqAauBS4GVgLviIiVo057N7ArpXQ88Bngk6Me/zTwb8WudbK1NNYC0GWjC0nKhAHrKDy2ZQ8vm91MfU111qVIUqU7G1ifUtqQUuoDbgYuG3XOZcCN+dvfBC6MfIeiiHgT8DSwbnLKnTytTXUAdhKUpIyMK2CNYxnGZyLigfzHExHRWfBKS8BjW/dw4jz3X0lSCVgIbBxxvyN/bMxzUkoDQBfQHhHTgD8F/vxILxIRV0bEmohYs23btoIUXmzDM1idPTa6kKQsHDFgjWcZRkrpf6WUzkgpnQH8A/DtItSaqa7ufjZ19nCSDS4kqdx9HPhMSmnvkU5MKV2XUlqVUlo1e/bs4ldWAK1N+SWCtmqXpEzUjOOcA8swACJieBnGI4c4/x3AxwpTXuk40OBivg0uJKkEbAIWj7i/KH9srHM6IqIGaAF2AOcAb42IvwFagaGI6E0p/WPRq54ErcMzWC4RlKRMjCdgjbUM45yxToyI44BlwA8nXlppeWzrHgBOcomgJJWCe4AVEbGMXJC6HHjnqHNWA1cAdwJvBX6YUkrAq4dPiIiPA3unSrgCmNHoDJYkZWk8AetoXA58M6U0ONaDEXElcCXAkiVLCvzSxfXY1t20NdUyd0Z91qVIUsVLKQ1ExFXA7UA18MWU0rqI+ASwJqW0GrgBuCki1gM7yY1RU15DbTWNtdVebFiSMjKegDWeZRjDLgfed6gnSildB1wHsGrVqrK6AuIjW3INLvINqCRJGUsp3QbcNurYNSNu9wJvO8JzfLwoxWWspbHWGSxJysh4uggeWIYREXXkQtTq0SdFxIlAG7mlGFPK4FDiia173H8lSSoLrU217sGSpIwcMWDlW9sOL8N4FPjG8DKMiLh0xKmXAzfn17dPKc/t7Kanf9D9V5KkstDSWEunM1iSlIlx7cE60jKM/P2PF66s0nL/c7sAOHmhAUuSVPpam2p5Znt31mVIUkUa14WGK91dG3bQ0ljrDJYkqSzkZrBsciFJWTBgjcPdT+/k7GUzqaqywYUkqfS1NtW5B0uSMlLoNu1TzubOHp7d0c3vnLc061IklYD+/n46Ojro7e3NupSy1dDQwKJFi6itrc26lCmrramO/QND9PQN0lhXnXU5kkqUY9r4HO24ZcA6gruf3gHAuctnZlyJpFLQ0dHB9OnTWbp0qZdtOAYpJXbs2EFHRwfLli3Lupwpa2Zz7j8BO/btZ1FdU8bVSCpVjmlHdizjlksEj+Cup3a6/0rSAb29vbS3tzsQHaOIoL293d+WFllbUx0Au/a5TFDSoTmmHdmxjFsGrCO46+kd7r+SdBAHoonx/Su+9mm5gLWz20YXkg7Pn8lHdrTvkQHrMJ7atpdnd3Tzqpe1Z12KJEnj9uIMlgFLkiabAeswVj+wmQi45NT5WZciSdK4zWzOBawdBixJJayzs5PPfvazR/15l1xyCZ2dnYc955prruGOO+44xsomxoB1CCklvvfgZs5ZNpO5MxqyLkeSDijmgKSpYUZDLdVV4QyWpJJ2qPFsYGDgsJ9322230draethzPvGJT/CGN7xhIuUdM7sIHsK6zbvZsH0f/+PVy7MuRVKJ+vPvreORzbsL+pwrF8zgY79+8mHPGR6Qfv/3f/+g4wMDA9TUHPrH+m233VaQGlX6qqqCtqZa92BJKmlXX301Tz31FGeccQa1tbU0NDTQ1tbGY489xhNPPMGb3vQmNm7cSG9vL+9///u58sorAVi6dClr1qxh7969XHzxxVxwwQX8/Oc/Z+HChXz3u9+lsbGRd73rXfzar/0ab33rW1m6dClXXHEF3/ve9+jv7+eWW27hxBNPZNu2bbzzne9k8+bNnHfeefzgBz/g3nvvZdasWRP6ugxYh7D6wc3UVAUXnzIv61Ik6SDFHJDGcv3113PdddfR19fH8ccfz0033URTUxPPP/8873nPe9iwYQMAn/vc53jVq17Fl7/8ZT71qU8REZx22mncdNNNk/be6EVtTXXOYEkatyx+afjXf/3XrF27lgceeIAf/ehH/Oqv/ipr16490A79i1/8IjNnzqSnp4dXvvKVvOUtb6G9/eDeCE8++SRf+9rXuP7663n729/Ot771LX7rt37rJa81a9Ys7rvvPj772c/yqU99ii984Qv8+Z//Oa9//ev58Ic/zL//+79zww03FOTrNmAdwh2PPs/5x8+iLb+OXZJGO9JMU7FM5oAE8OY3v5nf+73fA+CjH/0oN9xwA3/wB3/AH/7hH/La176WW2+9lcHBQfbu3cu6dev4y7/8S37+858za9Ysdu7cWdw3Q4fU1lznHixJZeXss88+6FpTf//3f8+tt94KwMaNG3nyySdfMp4tW7aMM844A4BXvOIVPPPMM2M+95vf/OYD53z7298G4Kc//emB57/oootoa2sryNdhwBpDV08/G7bt481nLsy6FEk6omIOSABr167lox/9KJ2dnezdu5c3vvGNAPzwhz/ky1/+MgDV1dW0tLTw5S9/mbe97W0HllfMnOlF2rMys6mOp7btzboMSWUiq18ajtTc3Hzg9o9+9CPuuOMO7rzzTpqamnjd61435rWo6uvrD9yurq6mp6dnzOcePq+6uvqIe7wmyiYXY3i4owuA0xa1ZluIJI3DoQakBx98kDPPPHNcA9LhBpt3vetd/OM//iMPP/wwH/vYx7xIcJmYOa2OXe7BklTCpk+fzp49e8Z8rKuri7a2Npqamnjssce46667Cv76559/Pt/4xjcA+P73v8+uXbsK8rwGrDE82NEJwGmLWrItRJLGMNkD0p49e5g/fz79/f185StfOXD8wgsv5HOf+xwAg4ODdHV18frXv55bbrmFHTt2ALhEMEMzm+rY1d3P0FDKuhRJGlN7ezvnn38+p5xyCh/60IcOeuyiiy5iYGCAk046iauvvppzzz234K//sY99jO9///uccsop3HLLLcybN4/p06dP+HldIjiGhzo6Oa69idYm919JKj0jB6TGxkbmzp174LGLLrqIz3/+85x00kmccMIJBRmQ/uIv/oJzzjmH2bNnc8455xwId3/3d3/HlVdeyQ033EB1dTWf+9znOO+88/jIRz7Ca1/7WqqrqznzzDP50pe+NOEadPTamusYHErs7u13PJNUsr761a+Oeby+vp5/+7d/G/Ox4WXts2bNYu3atQeOf/CDHzxwe+TYM3IZ/KpVq/jRj34EQEtLC7fffjs1NTXceeed3HPPPQet8DhWBqwxPNTRxaql7huQVLqKNSCN5b3vfS/vfe97X3J87ty5fPe7333J8SuuuIIrrrjisM+p4pvZXAvAzn19BixJGsNzzz3H29/+doaGhqirq+P6668vyPMasEZ5YU8vW7p6Od3lgZKkMjazOfdbWPdhSdLYVqxYwf3331/w5zVgjfLQRhtcSKpM73vf+/jZz3520LH3v//9/O7v/m5GFWkiZuZnrXbsNWBJOrSUEhGRdRklLaWj28tqwBrloY5OqgJOWTgj61IklaipOhhde+21k/I6RztQ6di05ZcIOoMl6VAaGhrYsWMH7e3tU3JcK4SUEjt27KChoWHcn2PAGuXBji5WzJlOU51vjaSXcjCamGMZqHRs2vNLBHfu68+4EkmlatGiRXR0dLBt27asSylpDQ0NLFq0aNznmyJGSCnxUEcnbzhp7pFPllSRHIwm7mgHKh2bxrpqGmqrnMGSdEi1tbUHXahehWHAGqFjVw+7uvs5bXFr1qVIKlEORionM5vq3IMlSZPMCw2PMHyBYTsISpKmgrbmOmewJGmSGbBGeKiji7rqKk6cZ4MLSVL5m9lcx469+7MuQ5IqigFrhAc3dnLSghnU1fi2SJLK36xp9ezY5wyWJE0mk0Te4FBi7aYulwdKkqaMWdPq2L53v63xJWkSGbDyNmzby76+QS8wLEmaMtqn1dPbP0R332DWpUhSxTBg5T3U0QXAac5gSZKmiPbmOgA7CUrSJDJg5T2yZTcNtVW8bPa0rEuRJKkgZk3PXWx4m40uJGnSGLDyHtm8mxPmzaC6KrIuRZKkgpjVnAtYdhKUpMljwAJSSjyyZTcr59ueXZI0dbRPyy8RtJOgJE0aAxawpauXrp5+Vs6fnnUpkiQVzHDA2r7HGSxJmiwGLHLLAwFWLnAGS5I0ddTXVDO9ocYZLEmaRAYscg0uIuCEeQYsSdLUMmtaPdvdgyVJk8aABTy6ZTfHzWxiWn1N1qVIksYpIi6KiMcjYn1EXD3G4/UR8fX843dHxNL88bMj4oH8x4MR8RuTXvwkam+uM2BJ0iQyYJGbwXJ5oCSVj4ioBq4FLgZWAu+IiJWjTns3sCuldDzwGeCT+eNrgVUppTOAi4B/iogp+xu2WdPqvQ6WJE2iig9Ye3r7eXZHtx0EJam8nA2sTyltSCn1ATcDl4065zLgxvztbwIXRkSklLpTSgP54w1AmpSKM9I+rc49WJI0iSo+YD27oxuA4+fYQVCSyshCYOOI+x35Y2Oekw9UXUA7QEScExHrgIeB94wIXAeJiCsjYk1ErNm2bVuBv4TJ0T6tnl3dfQwMDmVdiiRVhIoPWJs7ewBY0NqQcSWSpMmSUro7pXQy8ErgwxEx5iCQUroupbQqpbRq9uzZk1tkgcyeVkdKsLPbWSxJmgwVH7C27u4FYF6LAUuSysgmYPGI+4vyx8Y8J7/HqgXYMfKElNKjwF7glKJVmrH2afUA7sOSpElS8QFrS1cvtdXBrOb6rEuRJI3fPcCKiFgWEXXA5cDqUeesBq7I334r8MOUUsp/Tg1ARBwHnAg8MzllT7725vzFhu0kKEmTYlwB60itcPPnvD0iHomIdRHx1cKWWTxbOnuYO6OBqqrIuhRJ0jjl90xdBdwOPAp8I6W0LiI+ERGX5k+7AWiPiPXAB4Dh8esC4MGIeAC4Ffj9lNL2Sf0CJtGs6c5gSdJkOmJb2hGtcH+Z3CbieyJidUrpkRHnrAA+DJyfUtoVEXOKVXChbenqZb7LAyWp7KSUbgNuG3XsmhG3e4G3jfF5NwE3Fb3AEjG8QsMZLEmaHOOZwRpPK9zfA65NKe0CSCm9UNgyi2fr7l7mtzRmXYYkSUUxo7GG2upgmwFLkibFeALWeFrhvhx4eUT8LCLuioiLxnqiUmt3m1JyBkuSNKVFBHOmN7BtjwFLkiZDoZpc1AArgNcB7wCuj4jW0SeVWrvbnfv66BsYMmBJkqa0OTPqeT7fNVeSVFzjCVjjaYXbAaxOKfWnlJ4GniAXuEralq7hFu0uEZQkTV1zpzfw/G5nsCRpMownYI2nFe53yM1eERGzyC0Z3FC4MotjOGA5gyVJmsrmOoMlSZPmiAFrnK1wbwd2RMQjwH8CH0op7Rj7GUvH1q4eAOa3GrAkSVPXnBkN7OkdoLtvIOtSJGnKO2KbdhhXK9xE7hojHyhodUW2pauXmiovMixJmtrmzsj9IvGF3ftZOmtcQ78k6RgVqslFWdrS1etFhiVJU97cGblfJLpMUJKKr8IDVg8LXB4oSZrihmewnrdVuyQVXUUHrK1dvXYQlCRNeXOnDy8RdAZLkoqtogPWC3v2M2e6+68kSVPbjMYaGmqrXCIoSZOgYgPW/oFBuvsGaWuqzboUSZKKKiKYO8NrYUnSZKjYgNXV0w9AS1NdxpVIklR8uYsNO4MlScVWsQFrdz5gtTY6gyVJmvrmzKjnBZtcSFLRVWzA6uzOByyXCEqSKkBuiWAvuUtXSpKKxYDV6BJBSdLUN3dGPd19g+zdP5B1KZI0pVVuwOpxBkuSVDkOXAvLfViSVFSVG7C6+wCY4R4sSVIFmDN9OGC5D0uSiqliA1ZXTz9VAdPra7IuRZKkopvfkgtYW7qcwZKkYqrYgNXZ3U9LYy1VVZF1KZIkFd284YDV2ZNxJZI0tVVswOrq6afVa2BJkipEQ201s6bVs7nLgCVJxVSxAauzJzeDJUlSpVjY2sCmTpcISlIxVWzA6urus4OgJKmiLGhtZLNLBCWpqCo2YHX29NPqDJYkqYIMBywvNixJxVO5AavbPViSpMqyoLWR7r5BuvLXgpQkFV5FBqzBocTu3n6vgSVJqigLW3OdBDe5TFCSiqYiA9ae3n5SwiWCkqSKsqC1EYDNNrqQpKKpyIA1vDTCJheSpEryYsByBkuSiqUiA1ZntwFLklR52pvrqKupMmBJUhFVZsDKz2C1NNrkQpJUOSKCha2N7sGSpCKqzIDV3Qc4gyVJqjwLWhucwZKkIqrIgHVgD5ZNLiRJFWZBS6NNLiSpiCoyYA3vwWoxYEmSKsyC1kae39NL/+BQ1qVI0pRUsQFrWn0NNdUV+eVLkirYwrZGUoJNu1wmKEnFUJEJo6un39krSVJFWj6rGYCnt+/LuBJJmpoqMmB1dvcZsCRJFWn57GkAbDBgSVJRVGTA2tndR/s0W7RLkirPzOY6Wptq2bBtb9alSNKUVJkBa18fM5sNWJKkyrRsVjMbtjmDJUnFUJkBa68BS5LKXURcFBGPR8T6iLh6jMfrI+Lr+cfvjoil+eO/HBH3RsTD+T9fP+nFZ2z5rGnuwZKkIqm4gLV/YJA9+wdoN2BJUtmKiGrgWuBiYCXwjohYOeq0dwO7UkrHA58BPpk/vh349ZTSqcAVwE2TU3XpWD67ma27e9m3fyDrUiRpyqm4gLVzXx8AM5vrM65EkjQBZwPrU0obUkp9wM3AZaPOuQy4MX/7m8CFEREppftTSpvzx9cBjRFRUYOCnQQlqXgqLmDt2DscsJzBkqQythDYOOJ+R/7YmOeklAaALqB91DlvAe5LKe0f60Ui4sqIWBMRa7Zt21aQwkuBnQQlqXgqLmANz2DZRVCSKltEnExu2eD/PNQ5KaXrUkqrUkqrZs+ePXnFFdlx7U1EYCdBSSqCig1YzmBJUlnbBCwecX9R/tiY50REDdAC7MjfXwTcCvxOSumpoldbYhpqq1nY2mgnQUkqgooLWDuGZ7AMWJJUzu4BVkTEsoioAy4HVo86ZzW5JhYAbwV+mFJKEdEK/CtwdUrpZ5NVcKlZPttOgpJUDBUXsHbu2091VTCjoTbrUiRJxyi/p+oq4HbgUeAbKaV1EfGJiLg0f9oNQHtErAc+AAy3cr8KOB64JiIeyH/MmeQvIXPLZzWzYdteUkpZlyJJU0pN1gVMtp37+mhrqqOqKrIuRZI0ASml24DbRh27ZsTtXuBtY3zeXwJ/WfQCS9zy2c3s6xvkhT37mTujIetyJGnKqLgZrB17+1weKEmqeMtn5TsJug9LkgpqXAErIi6KiMcjYn1EXD3G4++KiG0jllr8j8KXWhg79/XZQVCSVPGWzc5dC2vDdjsJSlIhHXGJYERUA9cCv0zuOiP3RMTqlNIjo079ekrpqiLUWFA79vVx8oIZWZchSVKm5s9ooKG2yhksSSqw8cxgnQ2sTyltSCn1ATcDlxW3rOLZsXe/SwQlSRWvqipYNstOgpJUaOMJWAuBjSPud+SPjfaWiHgoIr4ZEYvHeJyIuDIi1kTEmm3bth1DuRPTPzjE7t4BZjbXT/prS5JUaoY7CUqSCqdQTS6+ByxNKZ0G/AC4cayTUkrXpZRWpZRWzZ49u0AvPX67hi8y7B4sSZJYPruZjbt66BsYyroUSZoyxhOwNgEjZ6QW5Y8dkFLakVLan7/7BeAVhSmvsLzIsCRJL1o+u5nBocRzO7uzLkWSpozxBKx7gBURsSwi6oDLgdUjT4iI+SPuXkruoo8lZ+fwDJYBS5Iklh1o1e4yQUkqlCN2EUwpDUTEVcDtQDXwxZTSuoj4BLAmpbQa+MOIuBQYAHYC7ypizcfMGSxJkl60bFauVbuNLiSpcI4YsABSSrcBt406ds2I2x8GPlzY0gpv597cKkZnsCRJgpbGWmZNq+MpZ7AkqWAK1eSiLOzs7icCWpsMWJIkAZwwbzqPbd2TdRmSNGVUVMDq6u5jRkMt1VWRdSmSJJWEUxa08NiWPfQP2klQkgqhogJWZ08/rU21WZchSVLJOHlhC32DQzzxvLNYklQIlRWwuvtpbTRgSZI07NSFLQCs27Q740okaWqorIDV00+L+68kSTrguJlNTKuvYe3mrqxLkaQpoaICVld3Hy3OYEmSdEBVVbBywQwe3mTAkqRCqKyA1eMSQUmSRjt1YQuPbtnNgI0uJGnCKiZgDQ2lXMCyyYUkSQc5ZeEMevuH2OAFhyVpwiomYO3ZP8BQwiWCkiSNcsqCXKOLhztcJihJE1UxAaurux/wIsOSJI22fPY0GmurbXQhSQVQMQGrs6cPwD1YkiSNUp1vdGGrdkmauMoJWAdmsAxYkiSNdsqCGazb3MXQUMq6FEkqa5UTsHpyAcs9WJIkvdTJC1vY1zfI0ztsdCFJE1ExAatrOGA5gyVJ0kucujDX6GKt18OSpAmpnIDVnduD5QyWJEkvdfycadTVVBmwJGmCKiZgdXb301RXTX1NddalSJJUcmqrqzhp3nTW2uhCkiakcgJWT78dBCVJOoxTFrawdnMXKdnoQpKOVeUErO5+WrwGliRJh3TKwhb29A7w3M7urEuRpLJVMQGrq6fPGSxJkg7jjMWtAKx5Zle2hUhSGauYgNXZ3e81sCRJOowT5k6ntamWuzbsyLoUSSpblROwevrtIChJ0mFUVQVnL53J3U/vzLoUSSpbFRGwUkp09fR7DSxJko7g3OXtPLezm02dPVmXIkllqSICVm//EH0DQ7Q22uRCkqTDOXd5OwB3u0xQko5JRQSszp7cRYbdgyVJ0uGdOG86LY3uw5KkY1UZAau7H8AugpIkHUFVVXDOspnctaG092Ft27Ofe58t7RolVaaKClg2uZAk6ciG92FtLuF9WF/82dP81hd+4UWRJZWcCglYw0sE3YMlSdKRnLN8JgB3P126ywS7evrp6R+ku28w61Ik6SAVEbB25Wew2pqdwZIk6UhOmjcjtw/rqdJdgteTD1adPf0ZVyJJB6uQgJWbwWpzBkuSpoyIuCgiHo+I9RFx9RiP10fE1/OP3x0RS/PH2yPiPyNib0T846QXXgaqqoKzl83krhKeweruGwBeXKUiSaWiIgJWZ3cfDbVVNNRWZ12KJKkAIqIauBa4GFgJvCMiVo467d3ArpTS8cBngE/mj/cCfwZ8cJLKLUvnLm/n2R3dbOkqzX1Yw0sDu7qdwZJUWioiYO3q7nf2SpKmlrOB9SmlDSmlPuBm4LJR51wG3Ji//U3gwoiIlNK+lNJPyQUtHcK5w/uwSrSboEsEJZWqighYnd19NriQpKllIbBxxP2O/LExz0kpDQBdQPvRvEhEXBkRayJizbZt2yZQbvk5sA+rRK+HNTyD1ekMlqQSUxEBKzeDZYMLSdLRSSldl1JalVJaNXv27KzLmVTD+7B+9tT2kmyF3ts/PIPlHixJpaVCAlYfbc3OYEnSFLIJWDzi/qL8sTHPiYgaoAUozemYEvWaFbPYuLOHZ3Z0Z13KSziDJalUVUbA2tfnDJYkTS33ACsiYllE1AGXA6tHnbMauCJ/+63AD1MpTsWUsNe8PDdr9+PHX8i4kpeyi6CkUjXlA9bQUKKrxyYXkjSV5PdUXQXcDjwKfCOltC4iPhERl+ZPuwFoj4j1wAeAA63cI+IZ4NPAuyKiY4wOhAKOa2/muPYm/uvJ7VmX8hI9/c5gSSpNNVkXUGy7e/sZStjkQpKmmJTSbcBto45dM+J2L/C2Q3zu0qIWN4W89uWzuWVNB/sHBqmvKY3LnfQPDtE/mJuMtIugpFIz5WewduV/s+USQUmSjt5rVsymp3+Qe5/ZlXUpBwzvvwKvgyWp9FRAwMqtzXaJoCRJR++8l7VTWx38+InSaVM/fA2sCLsISio9Uz5gDW9+bXUGS5Kko9ZcX8M5y9q549Hnsy7lgOEGF7On1bsHS1LJmfIBa9e+4SWCzmBJknQsLjxpDk9t28fT2/dlXQrw4hLB+a2N7B8YOnBNLEkqBeMKWBFxUUQ8HhHrI+Lqw5z3lohIEbGqcCVOjEsEJUmamDecNBeA/yiRWazhQLWwtQGwk6Ck0nLEgBUR1cC1wMXASuAdY7WzjYjpwPuBuwtd5ER0dvdTFTC9Yco3TJQkqSgWz2zihLnTS2aZ4IEZrJZG4MVfpkpSKRjPDNbZwPqU0oaUUh9wM3DZGOf9BfBJoLeA9U3Yru4+WpvqqKqKrEuRJKlsXXjSHO55ZldJdO17MWA5gyWp9IwnYC0ENo6435E/dkBEnAUsTin96+GeKCKujIg1EbFm27bJ6UbU2d1vgwtJkiboDSvnMjiU+I/Hsp/F6unPNblY0Jqbweqyk6CkEjLhJhcRUQV8GvjjI52bUroupbQqpbRq9uzZE33pcdnV3cdM919JkjQhZyxqZUFLA//y0JasSzkwgzXPGSxJJWg8AWsTsHjE/UX5Y8OmA6cAP4qIZ4BzgdWl0uhi577cEkFJknTsqqqCXzt9Af/1xLYDl0DJyvB1sBbk92B19hiwJJWO8QSse4AVEbEsIuqAy4HVww+mlLpSSrNSSktTSkuBu4BLU0prilLxUers7qfNJYKSJE3Yr5+2gIGhxL+t3ZppHcMzWO3T6qirrnIGS1JJOWLASikNAFcBtwOPAt9IKa2LiE9ExKXFLnCidnX30dbsDJYkSRN1ysIZLJvVzPce3JxpHd19g9RWB7XVVbQ01boHS1JJGVfv8pTSbcBto45dc4hzXzfxsgqjp2+Q/QNDNrmQJKkAIoJfP20+//Cf63lhdy9zZjRkUkdP3wCNtdUAtDXVOoMlqaRMuMlFKdvU2QO8uEZbkiRNzK+fvoCU4F8fzq7ZRU//IE11ud8RtzbVsWOvM1iSSseUDljP7dwH5C6QKEmSJm7F3OmcOG96pssEu/sGaarLzWAtbG088AtVSSoFUztg7egGYIkBS5Kkgvn10xdw33OdbNzZncnr9/QN0pgPWIvaGtm6u5eBwaFMapGk0aZ2wNrZQ1NdNbOm2eRCkqRCufT0BQCZXRNr5AzW4rYmBocSW7p6M6lFkkab4gFrH0tmNhERWZciSdKUsXhmE2csbuU7928ipTTpr9/dP0hjfg/WorbcPuuOXS4TlFQapnjA6nZ5oCRJRfDOs5fw+PN7uOPRFyb9tXNdBHP/hVnUlhvnO3Zls1xRkkabsgErpWTAkiSpSH7jrIUc197Ep3/wBENDkzuLlVsimJvBmtfSQFXARmewJJWIKRuwtu3ZT2//EEvaDViSJBVabXUVf/SGFTy6ZTf/vm7rpL72yCYXdTVVzJvR4AyWpJIxZQPWczvtIChJUjFdevpCjp8zjU/d/jj9k9jFr7tvkKb8hYYht0zQPViSSoUBS5IkHZPqquDqi05kw/Z9fO0Xz03Ka6aU8hcaHhmwGtlkwJJUIqZswHp2RzcRsDDfXUiSJBXehSfN4dzlM/nbO55kd29/0V+vtz83UzbcRRByAWtLV8+kzqJJ0qFM2YC1cWc3C1oaqa+pPvLJkiTpmEQEH/3Vlezq7uNvf/Bk0V+vu28AYNQMVhNDCbZ6LSxJJWDKBqzndnazeKazV5IkFdspC1t459lL+NLPn+bhjq6ivlZ33yDAgSYXAIvy4/1GG11IKgFTMmCllHjyhb0smzUt61IkSaoIf3LRibRPq+fDtz7EQBGX6vX05wLWyBmsxQeuheU+LEnZm5IBa0tXL109/axcMCPrUiRJqggtjbX8+aUns3bTbj75748V7XWGZ7BGBqx5LQ1UVwVPbN1TtNeVpPGakgHrkc27AVg5f3rGlUiSVDkuOXU+V5x3HNf/5GluWbOxKK8xvAerYUSb9trqKl5/4hy+ff8mevMzXFnq7hvgO/dv4s6ndtDVU/zGH5JKS82RTyk/j27JBawT5jmDJUnSZPqzX1vJ+m17+cita1k+u5lXHDezoM+/u2e4ycXB/4X57+cv4wePPM937t/E5WcvKehrHo2UEn/6rYf53oObAWhrquXmK8/jhHn+0leqFFNyBuvRrbs5rr2JafVTMj9KklSyaqqruPadZ7GgtYH/edO9bOo8+n1RKSW6ul868/OLp3fyv299mBkNNSxtP/g6l+cun8lJ82fwxZ89TUrpmOufqFvu7eB7D27mfb/0Mv7fu15JXU0Vv3XD3TyzfV9mNUmaXFMzYG3Zw8r5zl5JkpSF1qY6vnDFKvb3D/E7xxAubvz5M5zxF9/nj7/xIBt35joD/stDm/nNL9xFS2Mtt77vfFqb6g76nIjg3Rcs44nn9/Kjx7cV7Gs5Gs/v7uVj313Hecvb+cAvn8AvnTiHf373OQwMDvGn33ook5okTb4pF7D27R/gmR37OMmAJUlSZo6fM50vXLGKHfv6uOzan/EvD21maGh8M0s337OR9uZ6vvfQZl77f/6Ty6+7kz/42v2csbiV7/z++bxs9thdgi89fQHHtTfxyX9/jMFxvtZE/e9bH+Z/3HgPKSW+ctez9A4M8v+9+VSqqwKAFXOn857Xvoy7n97Jk8/bhEOqBFMuYD22dQ8pYcCSJClj5yxvZ/X7LmB+SwNXffV+3vi3/8VPnjz87NKjW3bz2NY9vP/C4/nxh17He1/3Mta/sI9fPmkuN737HFqaag/5uXU1VfzJG0/ksa17+Na9HYX+cl7i2R37uPkXz3HHoy/w72u38tVfbOSXTpjD0lnNB5331lcsoq66iq/c/VzRa5KUvSkXsIYbXJxkB0FJkjK3pL2Jf/3DV/P37ziTwaHEb9/wCz50y4Nj7rEC+M79m6ipCn71tAXMb2nkQ288kXs+ciH/9NuvOKhz4KFccuo8zlzSyqe+//gx7f8aade+PtZu6nrJnq7h63x94SdPU10VLJ7ZyAe+8SDb9+7nt8877iXP0z6tnotOmce37uugpy/7LoeSimtKdIG455mdnLm4lZrqKu57bhczGmpY2NqYdVmSJAmorgouPX0Bv7JyLv/wwyf5/I838KMntvGhN57Aa18+m7kzGgDY09vPdx/YzOtOmM3M5hf3WEXEuF8rIviLy07hHdffxZuu/Rn/712v5JSFLUdd8+BQ4ne/dA8PbOxkxZxpHNfezKbOHjp2ddPdN8hvnLmQf3loM79x5kJef+Jc3vPP93JcexOvXTF7zOf7zXOWsPrBzdx6/ybeeU52XQ4lFV/ZB6yfr9/OO79wNx/8lZdz+dlL+JeHtvCWsxYe1Q9jSZJUfA211XzojSdyyanz+ZNvPsSffDPX+KGxtpr62io687NaH7905YRe55SFLXzrva/id//fPbz9n+7k2neexS+dOOewnzM0lPjaPc/xhZ88zbsvWMbA4BAPbOzkd847jke37Gbjzm4WtTVy9tI2+gYT37q3g77BIX7v1cs5fs40fue843jVy2ZRVTX2/z/OXjaT0xe38rd3PMFlZyyg2U7H0pQVWbUyXbVqVVqzZs2En+cPvnY/33twM8111bzpzIV85e7n+I8/fu0hN8BKkkpTRNybUlqVdR2HUqhxSzmDQ4mHN3Vx77O72NrVQ0//IPNbGjl9USsXrJhVkNd4YXcv//3Ge3hk825e8/LZVEWwYu40Tl/Uyp7efvb0DjCtvoaOXT3c8ejzPLZ1D3Om1/PCnv1UVwXnHz+LG3/3lWP+0nZTZw8dO7s5Z3n7uOu577ldvPmzP+d9v/QyPvTGEwvyNUrKzqHGrbL+9Ulndx+3r9vKL50wm588uZ2v3P0cbzhpruFKkipARFwE/B1QDXwhpfTXox6vB74MvALYAfy3lNIz+cc+DLwbGAT+MKV0+ySWLnLLBs9Y3MoZi1uL9hpzZjTw9SvP45rvruOxrbsZSvCTJ7fRP3jwL5erq4LTF7Xw6befzmVnLORv73iC7zywib960ymHXBGzsLXxqLcjnLWkjTefuZDrf/I0py5s4Y0nz3PFjTQFlXXA+u4Dm+kbGOKDbzyBJTObuPHOZ7nyNcuzLkuSVGQRUQ1cC/wy0AHcExGrU0qPjDjt3cCulNLxEXE58Engv0XESuBy4GRgAXBHRLw8pWT3gSmoub6G//v20w/c7+kb5Klte2ltqmV6fS17+waY0VDD9IYXuxP+8a+cwB//yglFqefqi09k3ebdvOef7+OVS9u49IyFnLe8nUVtjeNq4iGp9JV1wPr6PRs5ZeEMTl7QwtUXT+NXTp7H2ctmZl2WJKn4zgbWp5Q2AETEzcBlwMiAdRnw8fztbwL/GLnpgsuAm1NK+4GnI2J9/vnunKTalaHGuuqDml4cru17McyZ0cC//uEFfOXu5/jiz57mz76zFoAIaKippqY6qK2uoqYq/2d1UFMVB66rFQTDk14RQeQ/d/g5hh+P/IHh+bHhYyM/Jxg+8cAfhzUZk20xrkoK8DqTNHE4aa8zxd63Yrvg+Fn8z9e+rGjPX7YBa9/+Adqn1fErJ88Dcj8wzz++MGu2JUklbyGwccT9DuCcQ52TUhqIiC6gPX/8rlGfu3CsF4mIK4ErAZYssfObCqOmuoorXrWU3znvONa/sJeHN3Xx3M5u9u0foH8wMTA0xMBgOuj2UEqkBInhPyG3jT633PHFY+nAY8MLIYf32x/0+fnbHHiew3vx9YpoxNdT3JeZnP4Dk9XmYLK6KUxG34bJ+lp6+ou7YKFsA1ZzfQ03vfucSfnLliRVppTSdcB1kGtykXE5mmIighVzp7NirtfulKaSsr/QsJtDJakibQIWj7i/KH9szHMiogZoIdfsYjyfK0nSMSn7gCVJqkj3ACsiYllE1JFrWrF61DmrgSvyt98K/DDllj2sBi6PiPqIWAasAH4xSXVLkqa4sl0iKEmqXPk9VVcBt5Nr0/7FlNK6iPgEsCaltBq4Abgp38RiJ7kQRv68b5BriDEAvM8OgpKkQjFgSZLKUkrpNuC2UceuGXG7F3jbIT73r4C/KmqBkqSK5BJBSZIkSSoQA5YkSZIkFYgBS5IkSZIKxIAlSZIkSQViwJIkSZKkAjFgSZIkSVKBGLAkSZIkqUDGFbAi4qKIeDwi1kfE1WM8/p6IeDgiHoiIn0bEysKXKkmSJEml7YgBKyKqgWuBi4GVwDvGCFBfTSmdmlI6A/gb4NOFLlSSJEmSSt14ZrDOBtanlDaklPqAm4HLRp6QUto94m4zkApXoiRJkiSVh5pxnLMQ2DjifgdwzuiTIuJ9wAeAOuD1BalOkiRJksrIeALWuKSUrgWujYh3Ah8Frhh9TkRcCVyZv7s3Ih4vwEvPArYX4HkmS7nVC+VXc7nVC+VXc7nVC+VXc7nVCxOv+bhCFVIM99577/aIeLYAT1Vuf7flVi+UX83lVi+UX83lVi+UX83lVi8UadwaT8DaBCwecX9R/tih3Ax8bqwHUkrXAdeN4zXHLSLWpJRWFfI5i6nc6oXyq7nc6oXyq7nc6oXyq7nc6oXyrPlopJRmF+J5yu19Krd6ofxqLrd6ofxqLrd6ofxqLrd6oXg1j2cP1j3AiohYFhF1wOXA6lHFrRhx91eBJwtXoiRJkiSVhyPOYKWUBiLiKuB2oBr4YkppXUR8AliTUloNXBURbwD6gV2MsTxQkiRJkqa6ce3BSindBtw26tg1I26/v8B1HY2CLjmcBOVWL5RfzeVWL5RfzeVWL5RfzeVWL5RnzVkot/ep3OqF8qu53OqF8qu53OqF8qu53OqFItUcKdlRXZIkSZIKYTx7sCRJkiRJ42DAkiRJkqQCKduAFREXRcTjEbE+Iq7Oup6xRMTiiPjPiHgkItZFxPvzxz8eEZsi4oH8xyVZ1zosIp6JiIfzda3JH5sZET+IiCfzf7ZlXeewiDhhxPv4QETsjog/KrX3OCK+GBEvRMTaEcfGfF8j5+/z39sPRcRZJVLv/4mIx/I13RoRrfnjSyOiZ8R7/fnJrvcwNR/y+yAiPpx/jx+PiDeWSL1fH1HrMxHxQP545u/xYX6elez3cakp9XGrHMcscNwqUo1lNWYdpuaSHbfKbcw6TM2OW2NJKZXdB7luhk8By4E64EFgZdZ1jVHnfOCs/O3pwBPASuDjwAezru8QNT8DzBp17G+Aq/O3rwY+mXWdh/m+2Eruom8l9R4DrwHOAtYe6X0FLgH+DQjgXODuEqn3V4Ca/O1Pjqh36cjzSuw9HvP7IP/v8EGgHliW/3lSnXW9ox7/v8A1pfIeH+bnWcl+H5fSRzmMW+U4ZuVrddwqfF1lNWYdpuaSHbfKbcw6VM2jHnfcyn+U6wzW2cD6lNKGlFIfuYsbX5ZxTS+RUtqSUrovf3sP8CiwMNuqjsllwI352zcCb8qulMO6EHgqpfRs1oWMllL6L2DnqMOHel8vA76ccu4CWiNi/qQUmjdWvSml76eUBvJ37yJ30fGScYj3+FAuA25OKe1PKT0NrCf3c2XSHK7eiAjg7cDXJrOmwznMz7OS/T4uMSU/bk2hMQsctyak3MYsKL9xq9zGLHDcOhrlGrAWAhtH3O+gxAeBiFgKnAncnT90VX768YultHQBSMD3I+LeiLgyf2xuSmlL/vZWYG42pR3R5Rz8D7tU3+Nhh3pfy+H7+7+T+y3PsGURcX9E/DgiXp1VUYcw1vdBqb/HrwaeTymNvGh7ybzHo36elfP38WQqq/ejjMYscNyaLOX+b71cxq1yHLPAcesg5RqwykpETAO+BfxRSmk38DngZcAZwBZyU6ql4oKU0lnAxcD7IuI1Ix9MuTnUkuvtHxF1wKXALflDpfwev0Spvq9jiYiPAAPAV/KHtgBLUkpnAh8AvhoRM7Kqb5Sy+j4Y4R0c/J+uknmPx/h5dkA5fR/r0MpszALHrUlXqu/poZTRuFU23wNjcNwaoVwD1iZg8Yj7i/LHSk5E1JL7S/1KSunbACml51NKgymlIeB6MpjmPZSU0qb8ny8At5Kr7fnhKdL8ny9kV+EhXQzcl1J6Hkr7PR7hUO9ryX5/R8S7gF8DfjP/Q4n8koUd+dv3klsb/vLMihzhMN8Hpfwe1wBvBr4+fKxU3uOxfp5Rht/HGSmL96Pcxixw3JpEZflvvZzGrXIcs8BxayzlGrDuAVZExLL8b4AuB1ZnXNNL5Nej3gA8mlL69IjjI9dz/gawdvTnZiEimiNi+vBtcptD15J7b6/In3YF8N1sKjysg35zUqrv8SiHel9XA7+T72ZzLtA1Yio7MxFxEfAnwKUppe4Rx2dHRHX+9nJgBbAhmyoPdpjvg9XA5RFRHxHLyNX8i8mu7xDeADyWUuoYPlAK7/Ghfp5RZt/HGSr5cavcxixw3JpkZfdvvdzGrTIds8Bx66VSht09JvJBrtPHE+QS8UeyrucQNV5AbtrxIeCB/MclwE3Aw/njq4H5Wdear3c5uS41DwLrht9XoB34D+BJ4A5gZta1jqq7GdgBtIw4VlLvMblBdAvQT25N77sP9b6S615zbf57+2FgVYnUu57c2uTh7+XP5899S/775QHgPuDXS+g9PuT3AfCR/Hv8OHBxKdSbP/4l4D2jzs38PT7Mz7OS/T4utQ9KfNw6zN9xSf08HVWz41Zx6iurMeswNZfsuHWIekt2zDpUzfnjX8Jx66CPyD+hJEmSJGmCynWJoCRJkiSVHAOWJEmSJBWIAUuSJEmSCsSAJUmSJEkFYsCSJEmSpAIxYEklLiJeFxH/knUdkiSNh+OWKp0BS5IkSZIKxIAlFUhE/FZE/CIiHoiIf4qI6ojYGxGfiYh1EfEfETE7f+4ZEXFXRDwUEbdGRFv++PERcUdEPBgR90XEy/JPPy0ivhkRj0XEV/JXJ5ck6Zg5bknFYcCSCiAiTgL+G3B+SukMYBD4TaAZWJNSOhn4MfCx/Kd8GfjTlNJp5K4WPnz8K8C1KaXTgVeRu2I6wJnAHwErgeXA+UX+kiRJU5jjllQ8NVkXIE0RFwKvAO7J/5KuEXgBGAK+nj/nn4FvR0QL0JpS+nH++I3ALRExHViYUroVIKXUC5B/vl+klDry9x8AlgI/LfpXJUmaqhy3pCIxYEmFEcCNKaUPH3Qw4s9GnZeO8fn3j7g9iP92JUkT47glFYlLBKXC+A/grRExByAiZkbEceT+jb01f847gZ+mlLqAXRHx6vzx3wZ+nFLaA3RExJvyz1EfEU2T+UVIkiqG45ZUJP42QSqAlNIjEfFR4PsRUQX0A+8D9gFn5x97gdx6d4ArgM/nB6INwO/mj/828E8R8Yn8c7xtEr8MSVKFcNySiidSOtaZX0lHEhF7U0rTsq5DkqTxcNySJs4lgpIkSZJUIM5gSZIkSVKBOIMlSZIkSQViwJIkSZKkAjFgSZIkSVKBGLAkSZIkqUAMWJIkSZJUIP8/3e/IyGk+hfQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1\n",
      "\tval_f1           \t (min:    0.248, max:    0.808, cur:    0.804)\n",
      "Loss\n",
      "\tvalidation       \t (min:    0.023, max:    0.088, cur:    0.088)\n",
      "train_acc\n",
      "\ttrain_acc        \t (min:    0.333, max:    1.000, cur:    1.000)\n",
      "train_loss\n",
      "\ttraining         \t (min:    0.000, max:    0.071, cur:    0.000)\n"
     ]
    }
   ],
   "source": [
    "cfg = {'alpha': 0.41423899852781415, 'gamma': 4.605796260288279, 'noise': 0.03653895338824281, 'neurons': 2117, 'relu': 'Leaky', 'dropout1': 0.09197427109578823, 'dropout2': 0.10944076754797236, 'layers': 2}\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"alpha\": cfg['alpha'], \"gamma\": cfg[\"gamma\"], \"reduction\": 'mean'}\n",
    "criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "\n",
    "class NetDDDOptuna(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "        self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "        sz = cfg['neurons']\n",
    "\n",
    "        if cfg['relu']=='relu':\n",
    "            relu=nn.ReLU\n",
    "        else:\n",
    "            relu=nn.LeakyReLU\n",
    "\n",
    "\n",
    "        if cfg['layers']==1:\n",
    "            self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                   nn.Dropout(cfg['dropout1']),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Dropout(cfg['dropout2']),\n",
    "                                   nn.Linear(sz,3))\n",
    "\n",
    "        if cfg['layers']==2:\n",
    "            self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                   nn.Dropout(cfg['dropout1']),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Dropout(cfg['dropout2']),\n",
    "                                   nn.Linear(sz,3))\n",
    "\n",
    "        if cfg['layers']==3:\n",
    "            self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "                                   nn.Dropout(cfg['dropout1']),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Linear(sz,sz),\n",
    "                                   relu(),\n",
    "                                   nn.Dropout(cfg['dropout2']),\n",
    "                                   nn.Linear(sz,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.n(x)\n",
    "        return self.m(x)\n",
    "epochs = 200\n",
    "batch_size = 500\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "\n",
    "\n",
    "unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "#     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "\n",
    "\n",
    "clip_value = 1\n",
    "\n",
    "model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.register_hook(lambda grad: torch.clamp(grad, -clip_value, clip_value))\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "#     optimizer = AdaHessian(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs, pct_start=0.3, div_factor=1000, final_div_factor=1000)\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "train_accs=[]\n",
    "val_accs=[]\n",
    "val_f1s = []\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    correct=0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()  #normal 1st order opt\n",
    "#             loss.backward(create_graph=True) # adahessian\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        ema.update()\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        train_loss+=loss.item()\n",
    "#     scheduler.step()\n",
    "    train_loss/=len(train_loader)\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    val_f1 = 0\n",
    "    with torch.no_grad():\n",
    "        with ema.average_parameters():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model.m(data)\n",
    "                vl=criterion(output, target).item()\n",
    "                val_loss += vl\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "    val_loss /= float(len(val_loader))\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "    val_f1 /= float(len(val_loader))\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    logs={}\n",
    "    logs['train_loss'] = train_loss\n",
    "    logs['val_loss'] = val_loss\n",
    "    logs['train_acc'] = acc\n",
    "#     logs['val_acc'] = val_acc\n",
    "    logs['val_f1'] = val_f1\n",
    "\n",
    "\n",
    "    if val_f1>=0.825:\n",
    "        print('val_f1>=0.825')\n",
    "        break\n",
    "\n",
    "    liveloss.update(logs)\n",
    "    if epoch%5==0:\n",
    "        liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # [I 2022-02-24 01:47:56,827] Trial 35 finished with value: 0.8130246066637513 and parameters: {'smoothing': 2.2731385669022297e-06, 'batch_size': 961, 'noise': 0.005599400703712527, 'neurons': 3022, 'relu': 'Leaky', 'dropout1': 0.004017445332648056, 'dropout2': 0.6251959618185807, 'lr': 0.09806801492571182}. Best is trial 35 with value: 0.8130246066637513.\n",
    "\n",
    "# cfg ={'alpha': 0.58952085048941,\n",
    "#       'gamma': 3.4880484258622437,\n",
    "#       'batch_size': 5000,#488,\n",
    "#       'noise': 0.06595507038359001/10,\n",
    "#       'neurons': 3775,\n",
    "#       'relu': 'Leaky',\n",
    "#       'dropout1': 0.13587081895474534,\n",
    "#       'dropout2': 0.877662163749141,\n",
    "#       'lr': 0.01}#0.2811878155016364}\n",
    "\n",
    "# # smoothing=cfg[\"smoothing\"]\n",
    "# # criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "# # criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# kwargs = {\"alpha\": 0.58952085048941, \"gamma\": 3.4880484258622437, \"reduction\": 'mean'}\n",
    "# criterion = kornia.losses.FocalLoss(**kwargs)\n",
    "# # def criterion(a,b):\n",
    "# #     return kornia.losses.FocalLoss(**kwargs)(a,b) + nn.CrossEntropyLoss(label_smoothing=0.1)(a,b)\n",
    "\n",
    "\n",
    "# class NetDDDOptuna(nn.Module):\n",
    "#     def __init__(self,cfg):\n",
    "#         super(NetDDDOptuna, self).__init__()\n",
    "\n",
    "#         self.n = GaussianNoise(cfg['noise'])\n",
    "\n",
    "#         sz = cfg['neurons']\n",
    "\n",
    "#         if cfg['relu']=='relu':\n",
    "#             relu=nn.ReLU\n",
    "#         else:\n",
    "#             relu=nn.LeakyReLU\n",
    "\n",
    "#         self.m = nn.Sequential(nn.Linear(512, sz),\n",
    "#                                    nn.Dropout(cfg['dropout1']),\n",
    "#                                    relu(),\n",
    "#                                    nn.Linear(sz,sz),\n",
    "#                                    relu(),\n",
    "# #                                    nn.Linear(sz,sz),\n",
    "# #                                    relu(),\n",
    "# #                                    nn.Linear(sz,sz),\n",
    "# #                                    relu(),\n",
    "#                                    nn.Dropout(cfg['dropout2']),\n",
    "#                                    nn.Linear(sz,3))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.n(x)\n",
    "#         return self.m(x)\n",
    "\n",
    "# epochs = 200\n",
    "# batch_size = cfg[\"batch_size\"]\n",
    "# train_loader = DataLoader(ds_train, batch_size=batch_size)\n",
    "# val_loader = DataLoader(ds_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# noise =cfg[\"noise\"]\n",
    "# neurons = [\"neurons\"]\n",
    "# relu = cfg[\"relu\"]\n",
    "# dropout1 = cfg[\"dropout1\"]\n",
    "# dropout2 = cfg[\"dropout2\"]\n",
    "\n",
    "\n",
    "\n",
    "# lr = cfg[\"lr\"]\n",
    "\n",
    "\n",
    "\n",
    "# unique_name=datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "# #     writer = torch.utils.tensorboard.SummaryWriter('./logs/pt/'+unique_name)\n",
    "\n",
    "\n",
    "# clip_value = 1\n",
    "\n",
    "# for xx in range(10):\n",
    "#     model = NetDDDOptuna(cfg).to(device)\n",
    "\n",
    "#     for p in model.parameters():\n",
    "#         p.register_hook(lambda grad: torch.clamp(grad, -clip_value, clip_value))\n",
    "\n",
    "#     ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "# #     optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# #     optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "#     optimizer = AdaHessian(model.parameters(), lr=lr)\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "#                                                     max_lr=lr,\n",
    "#                                                     steps_per_epoch=len(train_loader),\n",
    "#                                                     epochs=epochs, pct_start=0.1, div_factor=1000, final_div_factor=1000)\n",
    "#     # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5, 2)\n",
    "#     # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00001, max_lr=0.3, mode='triangular2',step_size_up=20)\n",
    "\n",
    "# #     lr = lr/10\n",
    "\n",
    "\n",
    "#     train_losses=[]\n",
    "#     val_losses=[]\n",
    "#     train_accs=[]\n",
    "#     val_accs=[]\n",
    "#     val_f1s = []\n",
    "\n",
    "#     liveloss = PlotLosses()\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         model.train()\n",
    "#         train_loss=0\n",
    "#         correct=0\n",
    "#         for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, target)\n",
    "# #             loss.backward()  #normal 1st order opt\n",
    "#             loss.backward(create_graph=True) # adahessian\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "\n",
    "#             ema.update()\n",
    "\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#             train_loss+=loss.item()\n",
    "#     #     scheduler.step()\n",
    "#         train_loss/=len(train_loader)\n",
    "#         acc = correct / len(train_loader.dataset)\n",
    "#         train_losses.append(train_loss)\n",
    "#         train_accs.append(acc)\n",
    "\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         correct = 0\n",
    "#         val_f1 = 0\n",
    "#         with torch.no_grad():\n",
    "#             with ema.average_parameters():\n",
    "#                 for data, target in val_loader:\n",
    "#                     data, target = data.to(device), target.to(device)\n",
    "#                     output = model(data)\n",
    "#                     vl=criterion(output, target).item()\n",
    "#                     val_loss += vl\n",
    "#                     pred = output.argmax(dim=1, keepdim=True)\n",
    "#                     correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#                     val_f1+=f1_score(target.view_as(pred).cpu(), pred.cpu(), average='weighted')\n",
    "\n",
    "\n",
    "#         val_loss /= float(len(val_loader))\n",
    "#         val_acc = correct / len(val_loader.dataset)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "#         val_f1 /= float(len(val_loader))\n",
    "#         val_f1s.append(val_f1)\n",
    "\n",
    "#         logs={}\n",
    "#         logs['train_loss'] = train_loss\n",
    "#         logs['val_loss'] = val_loss\n",
    "#         logs['train_acc'] = acc\n",
    "#     #     logs['val_acc'] = val_acc\n",
    "#         logs['val_f1'] = val_f1\n",
    "#         if val_f1>=0.825:\n",
    "#             print('val_f1>=0.825')\n",
    "#             break\n",
    "\n",
    "\n",
    "#     #         # log scalars to Tensorboard\n",
    "#     #         writer.add_scalar('val/f1', val_f1, epoch)\n",
    "#     #         writer.add_scalar('train/loss', train_loss, epoch)\n",
    "#     #         writer.add_scalar('val/loss', val_loss, epoch)\n",
    "\n",
    "#         liveloss.update(logs)\n",
    "#         if epoch%5==0:\n",
    "#             liveloss.send()\n",
    "    \n",
    "#     if val_f1>=0.825:\n",
    "#         print('val_f1>=0.825')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044863664160748"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1643711867290,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "WHNi9e7TP8pz",
    "outputId": "4dc030f1-eb3b-4c34-92f2-87c304e78d5f"
   },
   "outputs": [],
   "source": [
    "submission_embeddings = [literal_eval(embedding)  for embedding in submission['embeddings'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3001, 512])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(normalize_X(submission_embeddings))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3001, 512])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor((submission_embeddings-np.array(submission_embeddings).mean(axis=0))/np.array(submission_embeddings).std(axis=0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x.mean(axis=0),label='test')\n",
    "plt.plot(normalize_X(X_val).mean(axis=0),label='val')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3001, 3)\n"
     ]
    }
   ],
   "source": [
    "tta = 100\n",
    "results=[]\n",
    "with torch.no_grad():\n",
    "#     with ema.average_parameters():\n",
    "    for i in range(tta):\n",
    "        results.append(model.m(x.cuda()).cpu().numpy())\n",
    "results = np.array(results).mean(axis=0)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     with ema.average_parameters():\n",
    "#         result = model.m(x.cuda()).cpu()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ARGMAX (one hot)  MEAN STD\n",
    "predictions = np.argmax(results,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):\n",
    "    if a==0:\n",
    "        return 'negative'\n",
    "    if a==1:\n",
    "        return 'neutral'\n",
    "    if a==2:\n",
    "        return 'positive'\n",
    "\n",
    "result = list(map(convert, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['negative', 'neutral', 'positive'], dtype='<U8'),\n",
       " array([ 963, 1050,  988]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1643711867292,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "J4vBe0mAQDJv",
    "outputId": "65e20e41-bfcf-4ab6-bb49-90569b52d2b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.08109518140554428, 0.3090009093284607, 1.36...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.6809610724449158, 1.1909409761428833, 0.892...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.14851869642734528, 0.7872061133384705, 0.89...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.44697386026382446, 0.36429283022880554, 0.7...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.8009324073791504, 0.26081395149230957, 0.40...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[0.9138844609260559, 0.9460961222648621, 0.571...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[0.7667452096939087, 0.7896291613578796, 0.648...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[0.8158280849456787, 2.404792070388794, 0.9924...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[0.4161085784435272, 0.3146701455116272, 1.139...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>[0.7037264108657837, 0.6421875357627869, 1.215...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.08109518140554428, 0.3090009093284607, 1.36...   neutral\n",
       "1     [0.6809610724449158, 1.1909409761428833, 0.892...   neutral\n",
       "2     [0.14851869642734528, 0.7872061133384705, 0.89...   neutral\n",
       "3     [0.44697386026382446, 0.36429283022880554, 0.7...   neutral\n",
       "4     [1.8009324073791504, 0.26081395149230957, 0.40...  negative\n",
       "...                                                 ...       ...\n",
       "2996  [0.9138844609260559, 0.9460961222648621, 0.571...  negative\n",
       "2997  [0.7667452096939087, 0.7896291613578796, 0.648...  negative\n",
       "2998  [0.8158280849456787, 2.404792070388794, 0.9924...   neutral\n",
       "2999  [0.4161085784435272, 0.3146701455116272, 1.139...  positive\n",
       "3000  [0.7037264108657837, 0.6421875357627869, 1.215...  negative\n",
       "\n",
       "[3001 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['label'] = result\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30oDKdd7HV8R"
   },
   "source": [
    "### Saving the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Qv7xSbHQHVPg"
   },
   "outputs": [],
   "source": [
    "# Saving the predictions\n",
    "# !rm -rf assets\n",
    "# !mkdir assets\n",
    "submission.to_csv(os.path.join(\"assets\", \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aicrowd.magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext aicrowd.magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/OKnOZbosE0_W0xfg60O5ImqNzi4Y69X1tYTkz5KYvNk\u001b[0m\n",
      "\u001b[32mAPI Key valid\u001b[0m\n",
      "\u001b[32mGitlab access token valid\u001b[0m\n",
      "\u001b[32mSaved details successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357,
     "referenced_widgets": [
      "4660207a213e42b799859c22675d2476",
      "45f6d3e90b9f46f29b8cdc49f069bcc5"
     ]
    },
    "executionInfo": {
     "elapsed": 38827,
     "status": "ok",
     "timestamp": 1643713380919,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "JyrIU1uXHMjb",
    "outputId": "867e512d-72b1-4b5a-a584-4f0d9c9c6f21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mAn unexpected error occured!\u001b[0m\n",
      "cannot unpack non-iterable NoneType object\n",
      "To get more information, you can run this command with -v.\n",
      "To increase level of verbosity, you can go upto -vvvvv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using notebook: pytorch-sentiment.ipynb for submission...\n",
      "Removing existing files from submission directory...\n",
      "Scrubbing API keys from the notebook...\n",
      "Collecting notebook...\n",
      "WARNING: Got more than 1 jupyter server, selecting the latest session\n"
     ]
    }
   ],
   "source": [
    "%aicrowd notebook submit -c sentiment-classification -a assets --no-verify -n pytorch-sentiment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
