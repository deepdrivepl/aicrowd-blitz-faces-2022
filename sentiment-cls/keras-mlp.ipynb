{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEWUMWN9JgZs"
   },
   "source": [
    "![](https://images.aicrowd.com/raw_images/challenges/banner_file/1023/a8ebe297c369ea4a7697.png)\n",
    "\n",
    "<h2><center>Starter Code for Sentiment Classification</center></h2>\n",
    "\n",
    "\n",
    "In this baseline we will be training an sklearn model to do a multi-class classificattion of sentiment from face embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXUiejgu26rH"
   },
   "source": [
    "## Downloading Dataset\n",
    "\n",
    "Installing puzzle datasets via `aicrowd-cli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10358,
     "status": "ok",
     "timestamp": 1643711621853,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "vuvPB05qFe41",
    "outputId": "55484aea-183d-4a56-83b5-eed55a99f7d0"
   },
   "outputs": [],
   "source": [
    "# !pip install aicrowd-cli\n",
    "\n",
    "# Make sure to re-run below code whenever you restart colab notebook\n",
    "# %load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19267,
     "status": "ok",
     "timestamp": 1643711641079,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "ZQH9HAy23I7Y",
    "outputId": "dd9b6e7a-e08d-45e2-aa9d-2921331da051"
   },
   "outputs": [],
   "source": [
    "# # Logging in from our AIcrowd account. Make sure you have accepted the puzzle rules before logging in!  \n",
    "\n",
    "# %aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "23736fb1fe9941d39e74c528bfb42b72",
      "356bb9aeb3d942789fb47d03ee959004",
      "6d6465e7dcc14b028433dafa2a19425e",
      "f5ed31c8977c497cbfec64e30da03832",
      "f2c058254a184182afcd4863966fe3b0",
      "bd3b2ca98236429696a87022959d0801",
      "d84b10f328b34c2faed9a043df506299",
      "f2c198b39f67459da417208e66229249",
      "dd2083b61e874577883492c7afbc846c",
      "cac22b36b89f447da218aa89ada9e7dd",
      "7f04cb429d2846b7975ee2f755f124d3",
      "4635077ae52e421e962eb0073daab11a",
      "2827392c9da7413ab6b243fd889f2898",
      "a6970f61c501447fadf6ea6f41fccf97",
      "6e131d04bbcb43568745f77b9841fdd9",
      "5007344417f848afb17cafc21c1318e7",
      "b507f431b4f34a3bb1b3bb857d999537",
      "170d0d740db442d3905be5531b06a61f",
      "32cfaa5a941d4d00b3cbfbe11752219f",
      "75ed77729b3742f4bde159b2b98b9668",
      "d311dd0574cb403d9715060713cf75cd",
      "dd77e70c4b134b85b2932d58453f5a68",
      "c19725d50f074ec6bd8ab3cc0ae57e0a",
      "acf1c7050df144f09ae546fedb526c56",
      "2a9ce6366369440cb2a718a99e319ac3",
      "9fd78fe2d4e24537939c8b4410d33cd4",
      "b83309f18f984170950a161640014ea1",
      "93b4a902120d4088a6b2af9901271e9e",
      "785c99db6c094914b3a68ee18f271e8d",
      "8547805f4cd64e43808e0872b2fb0bc6",
      "8ad49a922f5d4340840e874bbbfe7b0d",
      "0aa4ed5fb03448ef84d3a135c16ec784",
      "8bd929029c0f4114a7ef0c8d1fd00617"
     ]
    },
    "executionInfo": {
     "elapsed": 20995,
     "status": "ok",
     "timestamp": 1643711661964,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "GOiUWHo53W6n",
    "outputId": "6631f173-8ec8-4f72-bdbf-1cc82dd1fb3e"
   },
   "outputs": [],
   "source": [
    "# # Creating a new data directory and downloading the dataset \n",
    "\n",
    "# !rm -rf data\n",
    "# !mkdir data\n",
    "# %aicrowd ds dl -c sentiment-classification -o data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4t_xZL73krM"
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "In this baseline, we will be sing sklearn [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify the sentiment of face embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ReMrWg8l3mRU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-mLdFyU3-Tw"
   },
   "source": [
    "## Reading Dataset\n",
    "\n",
    "As mented in the challenge readme, we have three different sets provided - train, validation and test respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2476,
     "status": "ok",
     "timestamp": 1643711675304,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "9uR1JofUJQKi",
    "outputId": "f071c14b-646e-4bad-8690-d77cbeb62464"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3206779360771179, 0.988215982913971, 1.0441...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.05074610561132431, 1.0742985010147095, 0.60...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.41962647438049316, 0.4505457878112793, 1.39...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4361684024333954, 0.19191382825374603, 0.83...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6382085084915161, 0.8352395296096802, 0.393...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[2.2057647705078125, 1.1072001457214355, 0.435...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[0.6344252228736877, 1.164398193359375, 0.7155...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[0.9160683155059814, 0.39996421337127686, 0.82...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[0.006456990726292133, 0.18667978048324585, 0....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[1.337027668952942, 0.8853631615638733, 0.6706...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.3206779360771179, 0.988215982913971, 1.0441...  positive\n",
       "1     [0.05074610561132431, 1.0742985010147095, 0.60...  negative\n",
       "2     [0.41962647438049316, 0.4505457878112793, 1.39...  negative\n",
       "3     [0.4361684024333954, 0.19191382825374603, 0.83...  positive\n",
       "4     [0.6382085084915161, 0.8352395296096802, 0.393...   neutral\n",
       "...                                                 ...       ...\n",
       "4995  [2.2057647705078125, 1.1072001457214355, 0.435...   neutral\n",
       "4996  [0.6344252228736877, 1.164398193359375, 0.7155...  negative\n",
       "4997  [0.9160683155059814, 0.39996421337127686, 0.82...  negative\n",
       "4998  [0.006456990726292133, 0.18667978048324585, 0....  positive\n",
       "4999  [1.337027668952942, 0.8853631615638733, 0.6706...  negative\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readging the csv \n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "val = pd.read_csv(\"data/val.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZmyPFxjwOe1c"
   },
   "outputs": [],
   "source": [
    "# Getting the feature and labels from each set. \n",
    "\n",
    "\n",
    "X = np.array([literal_eval(embedding)  for embedding in train['embeddings'].values])\n",
    "y = np.array(train['label'].values)\n",
    "\n",
    "X_val = np.array([literal_eval(embedding)  for embedding in val['embeddings'].values])\n",
    "y_val = np.array(val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 512), (5000,), (2000, 512), (5000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_val.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR_GJfYVPLgg"
   },
   "source": [
    "## Training the model\n",
    "\n",
    "Here, we will be training our model using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1643711781228,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "GEqeuQreOlwy",
    "outputId": "864fc14a-6037-49ed-8080-0f9b5c125f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10915,
     "status": "ok",
     "timestamp": 1643711792085,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "8fne6a1JOoi3",
    "outputId": "dc75a304-ab70-4d9e-f81e-d2dfbdfd5906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hepi-cuRPNow"
   },
   "source": [
    "### Testing the Model\n",
    "\n",
    "Here, we will be evaluator our model using validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1643711812095,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "1v0w1WLbPVK8",
    "outputId": "2d4d28c8-0ff3-4dd6-a5ca-07464c060b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.6729124468148805\n",
      "Accuracy Score : 0.6765\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(f\"F1 Score : {f1_score(y_val, y_pred, average='weighted')}\")\n",
    "print(f\"Accuracy Score : {accuracy_score(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.integration import TFKerasPruningCallback, TensorBoardCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y=='positive']=2\n",
    "y[y=='negative']=0\n",
    "y[y=='neutral']=1\n",
    "y = tf.one_hot(y,3)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([10000,  5000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[y_val=='positive']=2\n",
    "y_val[y_val=='negative']=0\n",
    "y_val[y_val=='neutral']=1\n",
    "y_val = tf.one_hot(y_val,3)\n",
    "y_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1(y_val, y_pred, sample_weight=None):\n",
    "    return f1_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1),average='weighted')\n",
    "\n",
    "def my_acc(y_val, y_pred, sample_weight=None):\n",
    "    return accuracy_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1))\n",
    "\n",
    "def getModel(neurons0=1024,neurons1=1024,neurons2=1024, layers1=3, layers2=3, dropout=0.5, lr=3e-3, ln=0, noise=1):\n",
    "    ls=[tf.keras.layers.Dense(neurons0, activation='relu', input_shape=(512,))]\n",
    "    \n",
    "    if noise>0:\n",
    "        ls.append(tf.keras.layers.GaussianNoise(0.1))\n",
    "    \n",
    "    if ln>0:\n",
    "        ls.append(tf.keras.layers.LayerNormalization())\n",
    "        \n",
    "    for _ in range(layers1):\n",
    "        ls.append(tf.keras.layers.Dense(neurons1, activation='relu'),)\n",
    "    for _ in range(layers2):\n",
    "        ls.append(tf.keras.layers.Dense(neurons2, activation='relu'),)\n",
    "    if ln>1:\n",
    "        ls.append(tf.keras.layers.LayerNormalization())\n",
    "    ls.append(tf.keras.layers.Dropout(dropout))\n",
    "    ls.append(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "    model = tf.keras.models.Sequential(ls)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['mae','mse','accuracy',my_f1,my_acc],\n",
    "                  run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "# def getModelCls():\n",
    "#     model = tf.keras.models.Sequential([tf.keras.layers.Dense(1024, activation='relu', input_shape=(512,)),\n",
    "# #                                         tf.keras.layers.Dropout(0.25),\n",
    "#                                         tf.keras.layers.LayerNormalization(),\n",
    "#                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "#                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "#                                         tf.keras.layers.Dropout(0.5),\n",
    "#                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "#                                         tf.keras.layers.LayerNormalization(),\n",
    "#                                         tf.keras.layers.Dropout(0.5),\n",
    "#                                         tf.keras.layers.Dense(3, activation='softmax')])\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['mae','mse','accuracy',my_f1,my_acc],\n",
    "#                   run_eagerly=True)\n",
    "#     return model\n",
    "# model = getModelCls()\n",
    "# model.summary()\n",
    "\n",
    "# model.fit(X/10.0,y,\n",
    "#           validation_data=(X_val/10.0,y_val),\n",
    "#           batch_size=1024,\n",
    "#           epochs=500,\n",
    "#           verbose=0,\n",
    "#          callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir=\"logs/0/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "#     histogram_freq=1,\n",
    "#     write_graph=True,\n",
    "#     update_freq=\"epoch\"),#PlotLossesKerasTF(),\n",
    "# #                    tf.keras.callbacks.ModelCheckpoint(\n",
    "# #     'checkpoint',\n",
    "# #     monitor=\"val_my_f1\",\n",
    "# #     verbose=1,\n",
    "# #     save_best_only=True,\n",
    "# #     save_weights_only=False,\n",
    "# #     mode=\"max\",\n",
    "# #     save_freq=\"epoch\",),\n",
    "#                     tf.keras.callbacks.EarlyStopping(\n",
    "#                                     monitor=\"val_my_f1\",\n",
    "#                                     patience=100,\n",
    "#                                     verbose=1,\n",
    "#                                     mode=\"max\",\n",
    "#                                     restore_best_weights=True,\n",
    "#                                 ),\n",
    "#                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor=\"val_my_f1\",\n",
    "#     factor=0.3,\n",
    "#     patience=10,\n",
    "#     verbose=1,\n",
    "#     mode=\"max\",\n",
    "#     min_delta=0.0001,\n",
    "#     cooldown=0,\n",
    "#     min_lr=1e-10,\n",
    "# )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=100\n",
    "def objective(trial):\n",
    "    neurons0 = trial.suggest_int(\"neurons0\", 16, 2048, log=True)\n",
    "    neurons1 = trial.suggest_int(\"neurons1\", 16, 2048, log=True)\n",
    "    neurons2 = trial.suggest_int(\"neurons2\", 16, 2048, log=True)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.9)\n",
    "    layers1 = trial.suggest_int(\"layers1\", 0, 3)\n",
    "    layers2 = trial.suggest_int(\"layers2\", 0, 3)\n",
    "    ln = trial.suggest_int(\"layer_norms\", 0, 2)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 1024)\n",
    "    noise = trial.suggest_int(\"noise\", 0, 1)\n",
    "\n",
    "    model = getModel(neurons0=neurons0,\n",
    "                     neurons1=neurons1,\n",
    "                     neurons2=neurons2,\n",
    "                     layers1=layers1,\n",
    "                     layers2=layers2,\n",
    "                     dropout=dropout,\n",
    "                     lr=lr,\n",
    "                     ln=ln,\n",
    "                     noise=noise)\n",
    "    \n",
    "    history = model.fit(X/10.0,y,\n",
    "              validation_data=(X_val/10.0,y_val),\n",
    "              batch_size=batch_size,\n",
    "              epochs=max_epochs,\n",
    "              verbose=0,\n",
    "             callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                            log_dir=\"logs/optuna2/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                            histogram_freq=1,\n",
    "                            write_graph=True,\n",
    "                            update_freq=\"epoch\"),\n",
    "                        TFKerasPruningCallback(trial, \"val_my_f1\"),\n",
    "                        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_my_f1\",\n",
    "        factor=0.3,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"max\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=1e-10,\n",
    "    )])\n",
    "    \n",
    "    return max(history.history['val_my_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-77d3958e3b70>:2: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.\n",
      "  pruner=optuna.pruners.PatientPruner(optuna.pruners.HyperbandPruner(\n",
      "\u001b[32m[I 2022-02-08 22:58:26,437]\u001b[0m A new study created in memory with name: no-name-f4de1cc7-a0e4-4f62-ae52-3ba3e845d81e\u001b[0m\n",
      "<ipython-input-31-77d3958e3b70>:4: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  study.optimize(objective, callbacks=[TensorBoardCallback('optuna-keras-logs2','val_my_f1')])\n",
      "\u001b[32m[I 2022-02-08 23:31:24,239]\u001b[0m Trial 0 finished with value: 0.19902470707893372 and parameters: {'neurons0': 122, 'neurons1': 1517, 'neurons2': 38, 'lr': 0.041744602692887586, 'dropout': 0.8409820791659567, 'layers1': 3, 'layers2': 3, 'layer_norms': 1, 'batch_size': 30, 'noise': 0}. Best is trial 0 with value: 0.19902470707893372.\u001b[0m\n",
      "\u001b[32m[I 2022-02-08 23:33:14,282]\u001b[0m Trial 1 finished with value: 0.7856473922729492 and parameters: {'neurons0': 65, 'neurons1': 52, 'neurons2': 396, 'lr': 0.000834643177753537, 'dropout': 0.40287553934092024, 'layers1': 2, 'layers2': 1, 'layer_norms': 1, 'batch_size': 628, 'noise': 1}. Best is trial 1 with value: 0.7856473922729492.\u001b[0m\n",
      "\u001b[32m[I 2022-02-08 23:49:26,514]\u001b[0m Trial 2 finished with value: 0.7977240681648254 and parameters: {'neurons0': 151, 'neurons1': 640, 'neurons2': 308, 'lr': 7.211301280955427e-06, 'dropout': 0.2341442927782704, 'layers1': 3, 'layers2': 1, 'layer_norms': 1, 'batch_size': 58, 'noise': 1}. Best is trial 2 with value: 0.7977240681648254.\u001b[0m\n",
      "\u001b[32m[I 2022-02-08 23:52:34,067]\u001b[0m Trial 3 finished with value: 0.7876929640769958 and parameters: {'neurons0': 152, 'neurons1': 738, 'neurons2': 55, 'lr': 2.607645399243224e-07, 'dropout': 0.20099451926396902, 'layers1': 0, 'layers2': 0, 'layer_norms': 2, 'batch_size': 291, 'noise': 1}. Best is trial 2 with value: 0.7977240681648254.\u001b[0m\n",
      "\u001b[32m[I 2022-02-08 23:55:14,636]\u001b[0m Trial 4 finished with value: 0.7998633980751038 and parameters: {'neurons0': 1237, 'neurons1': 29, 'neurons2': 30, 'lr': 3.498591927516629e-05, 'dropout': 0.8609221138886495, 'layers1': 1, 'layers2': 3, 'layer_norms': 2, 'batch_size': 373, 'noise': 0}. Best is trial 4 with value: 0.7998633980751038.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:07:50,449]\u001b[0m Trial 5 finished with value: 0.7919817566871643 and parameters: {'neurons0': 85, 'neurons1': 167, 'neurons2': 64, 'lr': 0.001902167753338399, 'dropout': 0.7958360253607181, 'layers1': 3, 'layers2': 1, 'layer_norms': 0, 'batch_size': 68, 'noise': 0}. Best is trial 4 with value: 0.7998633980751038.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:09:36,316]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:30:57,061]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:32:18,736]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:33:51,694]\u001b[0m Trial 9 finished with value: 0.8073459267616272 and parameters: {'neurons0': 814, 'neurons1': 260, 'neurons2': 1015, 'lr': 0.005669552858014781, 'dropout': 0.7587490002765426, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 883, 'noise': 0}. Best is trial 9 with value: 0.8073459267616272.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:35:57,386]\u001b[0m Trial 10 finished with value: 0.8004769086837769 and parameters: {'neurons0': 1334, 'neurons1': 323, 'neurons2': 1997, 'lr': 0.0010605394407472864, 'dropout': 0.6197059585008772, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 1013, 'noise': 0}. Best is trial 9 with value: 0.8073459267616272.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:37:45,196]\u001b[0m Trial 11 finished with value: 0.8109784722328186 and parameters: {'neurons0': 1733, 'neurons1': 315, 'neurons2': 1601, 'lr': 0.0014002866254862498, 'dropout': 0.628372965936472, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 1018, 'noise': 0}. Best is trial 11 with value: 0.8109784722328186.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:38:24,443]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:38:53,392]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:39:20,609]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:40:19,823]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 75.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:41:46,398]\u001b[0m Trial 16 finished with value: 0.8033835291862488 and parameters: {'neurons0': 878, 'neurons1': 513, 'neurons2': 17, 'lr': 0.00028549475474371887, 'dropout': 0.5547931859626323, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 677, 'noise': 0}. Best is trial 11 with value: 0.8109784722328186.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:43:06,149]\u001b[0m Trial 17 finished with value: 0.814997673034668 and parameters: {'neurons0': 311, 'neurons1': 242, 'neurons2': 1229, 'lr': 0.0820352620990874, 'dropout': 0.7151135927436263, 'layers1': 0, 'layers2': 2, 'layer_norms': 0, 'batch_size': 931, 'noise': 0}. Best is trial 17 with value: 0.814997673034668.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:43:53,682]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:45:41,959]\u001b[0m Trial 19 finished with value: 0.8076289296150208 and parameters: {'neurons0': 313, 'neurons1': 204, 'neurons2': 125, 'lr': 2.9737085898637592e-05, 'dropout': 0.6713117214464724, 'layers1': 0, 'layers2': 2, 'layer_norms': 1, 'batch_size': 510, 'noise': 0}. Best is trial 17 with value: 0.814997673034668.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:46:31,205]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 62.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:47:17,609]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:48:40,448]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 74.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:49:40,480]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:50:43,995]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 90.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:51:19,645]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:52:14,476]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:53:05,481]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:54:01,057]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:55:03,815]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:55:38,596]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:56:07,381]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:56:43,381]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:58:01,429]\u001b[0m Trial 33 finished with value: 0.8190227150917053 and parameters: {'neurons0': 663, 'neurons1': 137, 'neurons2': 402, 'lr': 0.0016036107080614123, 'dropout': 0.6424793755009226, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 965, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:58:41,858]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 53.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 00:59:09,310]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:00:34,573]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 72.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:01:05,274]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:02:41,610]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 70.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:03:29,386]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:04:31,083]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:05:09,854]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:05:49,159]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:06:26,266]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:07:23,093]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:08:38,907]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 91.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:09:22,320]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 77.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:10:03,008]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 53.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:11:56,251]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-09 01:12:28,307]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:13:15,135]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 40.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:14:18,384]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:15:25,959]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 68.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:16:29,684]\u001b[0m Trial 53 finished with value: 0.7902214527130127 and parameters: {'neurons0': 472, 'neurons1': 449, 'neurons2': 24, 'lr': 0.0006656531551203954, 'dropout': 0.6909650105143859, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 1020, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:17:09,355]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:18:48,482]\u001b[0m Trial 55 finished with value: 0.8157367706298828 and parameters: {'neurons0': 547, 'neurons1': 1355, 'neurons2': 32, 'lr': 2.1979996785471997e-05, 'dropout': 0.462770065893936, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 634, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:19:31,537]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:20:07,074]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:21:11,494]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:22:21,315]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:23:54,983]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 43.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:24:29,718]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:25:22,096]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:26:02,194]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:26:44,741]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:29:17,153]\u001b[0m Trial 65 finished with value: 0.8138645887374878 and parameters: {'neurons0': 1950, 'neurons1': 179, 'neurons2': 1733, 'lr': 2.6618271762777705e-05, 'dropout': 0.6570658317784046, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 644, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:30:05,095]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:31:32,666]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:33:52,560]\u001b[0m Trial 68 finished with value: 0.8122679591178894 and parameters: {'neurons0': 1751, 'neurons1': 62, 'neurons2': 1226, 'lr': 1.1223089519669368e-05, 'dropout': 0.8536807583997343, 'layers1': 0, 'layers2': 2, 'layer_norms': 0, 'batch_size': 462, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:34:33,343]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:35:50,643]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:37:53,383]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:38:48,842]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:39:45,843]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:42:05,469]\u001b[0m Trial 74 finished with value: 0.7784993052482605 and parameters: {'neurons0': 16, 'neurons1': 149, 'neurons2': 1730, 'lr': 1.2596292686744179e-06, 'dropout': 0.7398519426209399, 'layers1': 0, 'layers2': 2, 'layer_norms': 0, 'batch_size': 516, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:42:39,966]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:43:10,397]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:46:55,599]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:47:45,565]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:48:30,398]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:49:52,045]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 77.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:51:35,064]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:53:04,496]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 86.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:53:35,485]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 24.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:55:16,169]\u001b[0m Trial 84 finished with value: 0.7979942560195923 and parameters: {'neurons0': 799, 'neurons1': 175, 'neurons2': 748, 'lr': 0.00188672915588019, 'dropout': 0.6763669956411505, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 663, 'noise': 0}. Best is trial 33 with value: 0.8190227150917053.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:56:05,698]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 38.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:56:43,425]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:57:50,321]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 82.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 01:58:44,661]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 75.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:00:00,819]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 72.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:00:36,843]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:01:25,554]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:01:56,579]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 24.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:02:52,822]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 36.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:03:49,813]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 54.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:04:58,710]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 36.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:05:43,303]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:06:33,018]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 53.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:07:26,619]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:08:10,578]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:09:05,657]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:10:07,702]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 36.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:12:05,577]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 45.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:13:56,480]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:14:24,067]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 32.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:14:51,560]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 17.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:17:10,790]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 68.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:18:01,151]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:19:11,942]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:20:06,637]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 91.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:21:39,289]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:22:05,671]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 23.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:22:37,295]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:23:10,810]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:24:19,132]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:25:04,387]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 38.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:25:37,392]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:26:43,373]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:27:43,585]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:28:36,338]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:29:14,032]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:30:14,735]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 65.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:41:42,345]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:45:12,059]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:49:57,910]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 53.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-09 02:50:58,332]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:52:06,945]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 21.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:52:44,439]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 02:53:11,689]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 33.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:01:06,612]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 18.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:01:39,347]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 40.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:05:40,693]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 45.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:15:20,209]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 69.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:15:59,921]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:22:15,917]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:23:22,541]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:33:43,217]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:34:28,619]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 33.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:35:03,296]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:36:15,968]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 36.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:37:51,561]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 74.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:38:34,145]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:39:27,012]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 80.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:40:47,542]\u001b[0m Trial 143 finished with value: 0.8196468353271484 and parameters: {'neurons0': 642, 'neurons1': 434, 'neurons2': 38, 'lr': 0.0012261415398416226, 'dropout': 0.7342325341725875, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 963, 'noise': 0}. Best is trial 143 with value: 0.8196468353271484.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:41:21,553]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:42:19,692]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 72.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:44:11,746]\u001b[0m Trial 146 finished with value: 0.8154854774475098 and parameters: {'neurons0': 611, 'neurons1': 328, 'neurons2': 1556, 'lr': 2.2294599743867813e-05, 'dropout': 0.7442247563261035, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 948, 'noise': 0}. Best is trial 143 with value: 0.8196468353271484.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:44:50,443]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:45:19,432]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:45:58,031]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:46:28,581]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 25.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:47:16,600]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:48:05,205]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 54.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:49:04,232]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 65.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 03:50:02,510]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 05:43:02,971]\u001b[0m Trial 155 finished with value: 0.8077451586723328 and parameters: {'neurons0': 1657, 'neurons1': 269, 'neurons2': 17, 'lr': 0.0005168510646535249, 'dropout': 0.8030323852509512, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 9, 'noise': 0}. Best is trial 143 with value: 0.8196468353271484.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 05:56:24,147]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:41:47,588]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 83.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:42:44,047]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:43:37,555]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 58.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:44:05,686]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:44:54,789]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 32.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 06:56:37,386]\u001b[0m Trial 162 finished with value: 0.807265043258667 and parameters: {'neurons0': 1468, 'neurons1': 213, 'neurons2': 1423, 'lr': 0.0013424064998985485, 'dropout': 0.7455043438326832, 'layers1': 0, 'layers2': 3, 'layer_norms': 0, 'batch_size': 91, 'noise': 0}. Best is trial 143 with value: 0.8196468353271484.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:24:20,622]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:36:39,892]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 70.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:41:15,554]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:42:39,579]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:52:18,726]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 33.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:53:04,579]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:56:01,075]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 23.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 07:58:23,037]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 08:05:07,391]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 08:10:51,531]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 08:13:39,635]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 32.\u001b[0m\n",
      "\u001b[32m[I 2022-02-09 08:20:53,325]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[33m[W 2022-02-09 08:26:54,452]\u001b[0m Trial 175 failed because of the following error: AssertionError('Concurrent access?')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karol/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-30-d0211f6fd32d>\", line 24, in objective\n",
      "    history = model.fit(X/10.0,y,\n",
      "  File \"/home/karol/anaconda3/envs/pytorch11/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/karol/anaconda3/envs/pytorch11/lib/python3.8/site-packages/tensorflow/python/util/tf_stack.py\", line 61, in __exit__\n",
      "    assert top is self, 'Concurrent access?'\n",
      "AssertionError: Concurrent access?\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Concurrent access?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-77d3958e3b70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                             pruner=optuna.pruners.PatientPruner(optuna.pruners.HyperbandPruner(\n\u001b[1;32m      3\u001b[0m         min_resource=1, max_resource=max_epochs, reduction_factor=3), patience=10))\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optuna-keras-logs2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_my_f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d0211f6fd32d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     22\u001b[0m                      noise=noise)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     history = model.fit(X/10.0,y,\n\u001b[0m\u001b[1;32m     25\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch11/lib/python3.8/site-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Concurrent access?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Concurrent access?"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            pruner=optuna.pruners.PatientPruner(optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=max_epochs, reduction_factor=3), patience=10))\n",
    "study.optimize(objective, callbacks=[TensorBoardCallback('optuna-keras-logs2','val_my_f1')])\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 1.0993 - mae: 0.4439 - mse: 0.2224 - accuracy: 0.3324 - my_f1: 0.3186 - my_acc: 0.3393 - val_loss: 1.0815 - val_mae: 0.4406 - val_mse: 0.2185 - val_accuracy: 0.4870 - val_my_f1: 0.5245 - val_my_acc: 0.5243 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 1.0753 - mae: 0.4372 - mse: 0.2174 - accuracy: 0.3788 - my_f1: 0.3792 - my_acc: 0.3831 - val_loss: 1.0311 - val_mae: 0.4281 - val_mse: 0.2077 - val_accuracy: 0.6090 - val_my_f1: 0.6034 - val_my_acc: 0.6129 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 1.0408 - mae: 0.4264 - mse: 0.2104 - accuracy: 0.4226 - my_f1: 0.4291 - my_acc: 0.4312 - val_loss: 0.9797 - val_mae: 0.4135 - val_mse: 0.1976 - val_accuracy: 0.6125 - val_my_f1: 0.6122 - val_my_acc: 0.6153 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 1.0016 - mae: 0.4125 - mse: 0.2036 - accuracy: 0.4446 - my_f1: 0.4445 - my_acc: 0.4430 - val_loss: 0.9248 - val_mae: 0.3977 - val_mse: 0.1854 - val_accuracy: 0.6380 - val_my_f1: 0.6153 - val_my_acc: 0.6413 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.9589 - mae: 0.3973 - mse: 0.1943 - accuracy: 0.5200 - my_f1: 0.5142 - my_acc: 0.5228 - val_loss: 0.8646 - val_mae: 0.3776 - val_mse: 0.1729 - val_accuracy: 0.6555 - val_my_f1: 0.6383 - val_my_acc: 0.6617 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 1s 168ms/step - loss: 0.9157 - mae: 0.3784 - mse: 0.1861 - accuracy: 0.5550 - my_f1: 0.5481 - my_acc: 0.5516 - val_loss: 0.8148 - val_mae: 0.3595 - val_mse: 0.1627 - val_accuracy: 0.6630 - val_my_f1: 0.6394 - val_my_acc: 0.6669 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.8806 - mae: 0.3661 - mse: 0.1791 - accuracy: 0.5708 - my_f1: 0.5654 - my_acc: 0.5740 - val_loss: 0.7799 - val_mae: 0.3435 - val_mse: 0.1556 - val_accuracy: 0.6640 - val_my_f1: 0.6349 - val_my_acc: 0.6718 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.8449 - mae: 0.3517 - mse: 0.1713 - accuracy: 0.5918 - my_f1: 0.5785 - my_acc: 0.5864 - val_loss: 0.7308 - val_mae: 0.3221 - val_mse: 0.1460 - val_accuracy: 0.6825 - val_my_f1: 0.6678 - val_my_acc: 0.6929 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.8205 - mae: 0.3390 - mse: 0.1670 - accuracy: 0.6100 - my_f1: 0.6101 - my_acc: 0.6145 - val_loss: 0.6965 - val_mae: 0.3089 - val_mse: 0.1387 - val_accuracy: 0.6975 - val_my_f1: 0.6642 - val_my_acc: 0.6949 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.7895 - mae: 0.3257 - mse: 0.1597 - accuracy: 0.6474 - my_f1: 0.6356 - my_acc: 0.6498 - val_loss: 0.6729 - val_mae: 0.3002 - val_mse: 0.1338 - val_accuracy: 0.7185 - val_my_f1: 0.6947 - val_my_acc: 0.7178 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.7679 - mae: 0.3192 - mse: 0.1558 - accuracy: 0.6524 - my_f1: 0.6511 - my_acc: 0.6570 - val_loss: 0.6643 - val_mae: 0.2952 - val_mse: 0.1320 - val_accuracy: 0.7130 - val_my_f1: 0.6983 - val_my_acc: 0.7140 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.7551 - mae: 0.3126 - mse: 0.1527 - accuracy: 0.6658 - my_f1: 0.6589 - my_acc: 0.6671 - val_loss: 0.6364 - val_mae: 0.2814 - val_mse: 0.1270 - val_accuracy: 0.7250 - val_my_f1: 0.7344 - val_my_acc: 0.7472 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.7367 - mae: 0.3051 - mse: 0.1489 - accuracy: 0.6754 - my_f1: 0.6750 - my_acc: 0.6813 - val_loss: 0.6250 - val_mae: 0.2740 - val_mse: 0.1251 - val_accuracy: 0.7270 - val_my_f1: 0.7286 - val_my_acc: 0.7403 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.7206 - mae: 0.2984 - mse: 0.1458 - accuracy: 0.6888 - my_f1: 0.6738 - my_acc: 0.6827 - val_loss: 0.6099 - val_mae: 0.2701 - val_mse: 0.1220 - val_accuracy: 0.7320 - val_my_f1: 0.7399 - val_my_acc: 0.7521 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.7090 - mae: 0.2948 - mse: 0.1436 - accuracy: 0.6898 - my_f1: 0.6794 - my_acc: 0.6864 - val_loss: 0.6035 - val_mae: 0.2684 - val_mse: 0.1208 - val_accuracy: 0.7330 - val_my_f1: 0.7353 - val_my_acc: 0.7445 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.6922 - mae: 0.2880 - mse: 0.1399 - accuracy: 0.7066 - my_f1: 0.7057 - my_acc: 0.7126 - val_loss: 0.5978 - val_mae: 0.2644 - val_mse: 0.1200 - val_accuracy: 0.7320 - val_my_f1: 0.7389 - val_my_acc: 0.7479 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6928 - mae: 0.2868 - mse: 0.1398 - accuracy: 0.7042 - my_f1: 0.7009 - my_acc: 0.7055 - val_loss: 0.6091 - val_mae: 0.2589 - val_mse: 0.1227 - val_accuracy: 0.7415 - val_my_f1: 0.7442 - val_my_acc: 0.7504 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.7247 - mae: 0.2927 - mse: 0.1461 - accuracy: 0.6876 - my_f1: 0.6847 - my_acc: 0.6904 - val_loss: 0.6859 - val_mae: 0.2709 - val_mse: 0.1379 - val_accuracy: 0.6985 - val_my_f1: 0.6807 - val_my_acc: 0.6956 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.7313 - mae: 0.2989 - mse: 0.1485 - accuracy: 0.6718 - my_f1: 0.6614 - my_acc: 0.6665 - val_loss: 0.6225 - val_mae: 0.2693 - val_mse: 0.1252 - val_accuracy: 0.7450 - val_my_f1: 0.7522 - val_my_acc: 0.7569 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.6994 - mae: 0.2934 - mse: 0.1414 - accuracy: 0.6954 - my_f1: 0.7019 - my_acc: 0.7066 - val_loss: 0.5858 - val_mae: 0.2603 - val_mse: 0.1175 - val_accuracy: 0.7425 - val_my_f1: 0.7495 - val_my_acc: 0.7594 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.6797 - mae: 0.2819 - mse: 0.1365 - accuracy: 0.7158 - my_f1: 0.7091 - my_acc: 0.7155 - val_loss: 0.5775 - val_mae: 0.2506 - val_mse: 0.1162 - val_accuracy: 0.7485 - val_my_f1: 0.7624 - val_my_acc: 0.7677 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.6655 - mae: 0.2744 - mse: 0.1344 - accuracy: 0.7152 - my_f1: 0.7188 - my_acc: 0.7208 - val_loss: 0.5681 - val_mae: 0.2495 - val_mse: 0.1145 - val_accuracy: 0.7390 - val_my_f1: 0.7419 - val_my_acc: 0.7486 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.6749 - mae: 0.2780 - mse: 0.1361 - accuracy: 0.7136 - my_f1: 0.6993 - my_acc: 0.7070 - val_loss: 0.5801 - val_mae: 0.2560 - val_mse: 0.1171 - val_accuracy: 0.7380 - val_my_f1: 0.7468 - val_my_acc: 0.7521 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.6606 - mae: 0.2762 - mse: 0.1333 - accuracy: 0.7164 - my_f1: 0.7127 - my_acc: 0.7138 - val_loss: 0.5691 - val_mae: 0.2543 - val_mse: 0.1145 - val_accuracy: 0.7445 - val_my_f1: 0.7526 - val_my_acc: 0.7566 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.6686 - mae: 0.2776 - mse: 0.1341 - accuracy: 0.7254 - my_f1: 0.7190 - my_acc: 0.7253 - val_loss: 0.5610 - val_mae: 0.2472 - val_mse: 0.1130 - val_accuracy: 0.7450 - val_my_f1: 0.7459 - val_my_acc: 0.7528 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6462 - mae: 0.2704 - mse: 0.1296 - accuracy: 0.7326 - my_f1: 0.7278 - my_acc: 0.7315 - val_loss: 0.5562 - val_mae: 0.2446 - val_mse: 0.1122 - val_accuracy: 0.7505 - val_my_f1: 0.7731 - val_my_acc: 0.7732 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.6504 - mae: 0.2686 - mse: 0.1301 - accuracy: 0.7368 - my_f1: 0.7347 - my_acc: 0.7380 - val_loss: 0.5665 - val_mae: 0.2452 - val_mse: 0.1150 - val_accuracy: 0.7430 - val_my_f1: 0.7536 - val_my_acc: 0.7597 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6689 - mae: 0.2719 - mse: 0.1338 - accuracy: 0.7210 - my_f1: 0.7194 - my_acc: 0.7244 - val_loss: 0.5559 - val_mae: 0.2457 - val_mse: 0.1125 - val_accuracy: 0.7460 - val_my_f1: 0.7701 - val_my_acc: 0.7701 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.6445 - mae: 0.2708 - mse: 0.1304 - accuracy: 0.7274 - my_f1: 0.7272 - my_acc: 0.7299 - val_loss: 0.5521 - val_mae: 0.2433 - val_mse: 0.1113 - val_accuracy: 0.7505 - val_my_f1: 0.7588 - val_my_acc: 0.7649 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.6372 - mae: 0.2674 - mse: 0.1282 - accuracy: 0.7422 - my_f1: 0.7401 - my_acc: 0.7434 - val_loss: 0.5460 - val_mae: 0.2381 - val_mse: 0.1100 - val_accuracy: 0.7495 - val_my_f1: 0.7638 - val_my_acc: 0.7684 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 1s 184ms/step - loss: 0.6433 - mae: 0.2668 - mse: 0.1296 - accuracy: 0.7262 - my_f1: 0.7174 - my_acc: 0.7230 - val_loss: 0.5429 - val_mae: 0.2367 - val_mse: 0.1095 - val_accuracy: 0.7575 - val_my_f1: 0.7792 - val_my_acc: 0.7822 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.6327 - mae: 0.2620 - mse: 0.1263 - accuracy: 0.7400 - my_f1: 0.7374 - my_acc: 0.7408 - val_loss: 0.5442 - val_mae: 0.2344 - val_mse: 0.1096 - val_accuracy: 0.7585 - val_my_f1: 0.7704 - val_my_acc: 0.7746 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.6328 - mae: 0.2605 - mse: 0.1271 - accuracy: 0.7386 - my_f1: 0.7407 - my_acc: 0.7432 - val_loss: 0.5381 - val_mae: 0.2322 - val_mse: 0.1086 - val_accuracy: 0.7625 - val_my_f1: 0.7835 - val_my_acc: 0.7857 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.6196 - mae: 0.2555 - mse: 0.1246 - accuracy: 0.7408 - my_f1: 0.7412 - my_acc: 0.7444 - val_loss: 0.5361 - val_mae: 0.2334 - val_mse: 0.1081 - val_accuracy: 0.7575 - val_my_f1: 0.7779 - val_my_acc: 0.7822 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 1s 207ms/step - loss: 0.6265 - mae: 0.2616 - mse: 0.1261 - accuracy: 0.7434 - my_f1: 0.7380 - my_acc: 0.7445 - val_loss: 0.5352 - val_mae: 0.2360 - val_mse: 0.1081 - val_accuracy: 0.7555 - val_my_f1: 0.7751 - val_my_acc: 0.7767 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 1s 210ms/step - loss: 0.6130 - mae: 0.2593 - mse: 0.1249 - accuracy: 0.7398 - my_f1: 0.7372 - my_acc: 0.7384 - val_loss: 0.5317 - val_mae: 0.2308 - val_mse: 0.1074 - val_accuracy: 0.7545 - val_my_f1: 0.7681 - val_my_acc: 0.7718 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 0.6198 - mae: 0.2569 - mse: 0.1250 - accuracy: 0.7398 - my_f1: 0.7253 - my_acc: 0.7333 - val_loss: 0.5352 - val_mae: 0.2319 - val_mse: 0.1083 - val_accuracy: 0.7610 - val_my_f1: 0.7950 - val_my_acc: 0.7930 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6283 - mae: 0.2582 - mse: 0.1260 - accuracy: 0.7362 - my_f1: 0.7367 - my_acc: 0.7368 - val_loss: 0.5363 - val_mae: 0.2316 - val_mse: 0.1088 - val_accuracy: 0.7565 - val_my_f1: 0.7560 - val_my_acc: 0.7649 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.6337 - mae: 0.2604 - mse: 0.1281 - accuracy: 0.7364 - my_f1: 0.7192 - my_acc: 0.7340 - val_loss: 0.5355 - val_mae: 0.2302 - val_mse: 0.1075 - val_accuracy: 0.7670 - val_my_f1: 0.7851 - val_my_acc: 0.7888 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.6192 - mae: 0.2603 - mse: 0.1252 - accuracy: 0.7472 - my_f1: 0.7478 - my_acc: 0.7485 - val_loss: 0.5332 - val_mae: 0.2319 - val_mse: 0.1072 - val_accuracy: 0.7685 - val_my_f1: 0.7845 - val_my_acc: 0.7857 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 0.6053 - mae: 0.2560 - mse: 0.1227 - accuracy: 0.7530 - my_f1: 0.7421 - my_acc: 0.7521 - val_loss: 0.5282 - val_mae: 0.2269 - val_mse: 0.1074 - val_accuracy: 0.7615 - val_my_f1: 0.7722 - val_my_acc: 0.7767 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.6157 - mae: 0.2541 - mse: 0.1240 - accuracy: 0.7426 - my_f1: 0.7419 - my_acc: 0.7452 - val_loss: 0.5254 - val_mae: 0.2243 - val_mse: 0.1060 - val_accuracy: 0.7705 - val_my_f1: 0.7847 - val_my_acc: 0.7871 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 1s 174ms/step - loss: 0.5952 - mae: 0.2500 - mse: 0.1205 - accuracy: 0.7524 - my_f1: 0.7484 - my_acc: 0.7530 - val_loss: 0.5552 - val_mae: 0.2265 - val_mse: 0.1112 - val_accuracy: 0.7575 - val_my_f1: 0.7565 - val_my_acc: 0.7614 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 1s 178ms/step - loss: 0.6073 - mae: 0.2513 - mse: 0.1216 - accuracy: 0.7526 - my_f1: 0.7493 - my_acc: 0.7524 - val_loss: 0.5671 - val_mae: 0.2273 - val_mse: 0.1134 - val_accuracy: 0.7525 - val_my_f1: 0.7477 - val_my_acc: 0.7538 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.5993 - mae: 0.2488 - mse: 0.1207 - accuracy: 0.7528 - my_f1: 0.7553 - my_acc: 0.7570 - val_loss: 0.5461 - val_mae: 0.2237 - val_mse: 0.1096 - val_accuracy: 0.7645 - val_my_f1: 0.7628 - val_my_acc: 0.7704 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.6096 - mae: 0.2507 - mse: 0.1220 - accuracy: 0.7552 - my_f1: 0.7423 - my_acc: 0.7510 - val_loss: 0.5163 - val_mae: 0.2223 - val_mse: 0.1045 - val_accuracy: 0.7705 - val_my_f1: 0.7849 - val_my_acc: 0.7871 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5879 - mae: 0.2448 - mse: 0.1169 - accuracy: 0.7654 - my_f1: 0.7672 - my_acc: 0.7686\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.5879 - mae: 0.2448 - mse: 0.1169 - accuracy: 0.7654 - my_f1: 0.7672 - my_acc: 0.7686 - val_loss: 0.5257 - val_mae: 0.2224 - val_mse: 0.1056 - val_accuracy: 0.7685 - val_my_f1: 0.7728 - val_my_acc: 0.7774 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.5944 - mae: 0.2499 - mse: 0.1199 - accuracy: 0.7574 - my_f1: 0.7468 - my_acc: 0.7522 - val_loss: 0.5150 - val_mae: 0.2231 - val_mse: 0.1044 - val_accuracy: 0.7615 - val_my_f1: 0.7730 - val_my_acc: 0.7767 - lr: 3.0000e-04\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5990 - mae: 0.2505 - mse: 0.1205 - accuracy: 0.7530 - my_f1: 0.7403 - my_acc: 0.7455 - val_loss: 0.5183 - val_mae: 0.2224 - val_mse: 0.1045 - val_accuracy: 0.7740 - val_my_f1: 0.7810 - val_my_acc: 0.7853 - lr: 3.0000e-04\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.5892 - mae: 0.2460 - mse: 0.1178 - accuracy: 0.7600 - my_f1: 0.7598 - my_acc: 0.7639 - val_loss: 0.5149 - val_mae: 0.2223 - val_mse: 0.1044 - val_accuracy: 0.7680 - val_my_f1: 0.7833 - val_my_acc: 0.7853 - lr: 3.0000e-04\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 1s 171ms/step - loss: 0.5873 - mae: 0.2467 - mse: 0.1189 - accuracy: 0.7512 - my_f1: 0.7419 - my_acc: 0.7469 - val_loss: 0.5143 - val_mae: 0.2191 - val_mse: 0.1039 - val_accuracy: 0.7725 - val_my_f1: 0.7796 - val_my_acc: 0.7843 - lr: 3.0000e-04\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.5898 - mae: 0.2437 - mse: 0.1186 - accuracy: 0.7600 - my_f1: 0.7519 - my_acc: 0.7574 - val_loss: 0.5140 - val_mae: 0.2180 - val_mse: 0.1038 - val_accuracy: 0.7760 - val_my_f1: 0.7830 - val_my_acc: 0.7867 - lr: 3.0000e-04\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5810 - mae: 0.2427 - mse: 0.1174 - accuracy: 0.7624 - my_f1: 0.7603 - my_acc: 0.7631 - val_loss: 0.5119 - val_mae: 0.2188 - val_mse: 0.1037 - val_accuracy: 0.7735 - val_my_f1: 0.7871 - val_my_acc: 0.7891 - lr: 3.0000e-04\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5878 - mae: 0.2435 - mse: 0.1169 - accuracy: 0.7650 - my_f1: 0.7702 - my_acc: 0.7734 - val_loss: 0.5113 - val_mae: 0.2186 - val_mse: 0.1037 - val_accuracy: 0.7660 - val_my_f1: 0.7753 - val_my_acc: 0.7798 - lr: 3.0000e-04\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5815 - mae: 0.2434 - mse: 0.1167 - accuracy: 0.7638 - my_f1: 0.7615 - my_acc: 0.7672 - val_loss: 0.5123 - val_mae: 0.2195 - val_mse: 0.1035 - val_accuracy: 0.7710 - val_my_f1: 0.7838 - val_my_acc: 0.7874 - lr: 3.0000e-04\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5753 - mae: 0.2430 - mse: 0.1170 - accuracy: 0.7618 - my_f1: 0.7568 - my_acc: 0.7604 - val_loss: 0.5133 - val_mae: 0.2201 - val_mse: 0.1036 - val_accuracy: 0.7750 - val_my_f1: 0.7788 - val_my_acc: 0.7819 - lr: 3.0000e-04\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5749 - mae: 0.2430 - mse: 0.1158 - accuracy: 0.7678 - my_f1: 0.7609 - my_acc: 0.7641\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.5749 - mae: 0.2430 - mse: 0.1158 - accuracy: 0.7678 - my_f1: 0.7609 - my_acc: 0.7641 - val_loss: 0.5146 - val_mae: 0.2184 - val_mse: 0.1037 - val_accuracy: 0.7755 - val_my_f1: 0.7824 - val_my_acc: 0.7864 - lr: 3.0000e-04\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 1s 149ms/step - loss: 0.5772 - mae: 0.2409 - mse: 0.1163 - accuracy: 0.7678 - my_f1: 0.7613 - my_acc: 0.7663 - val_loss: 0.5118 - val_mae: 0.2184 - val_mse: 0.1034 - val_accuracy: 0.7710 - val_my_f1: 0.7750 - val_my_acc: 0.7791 - lr: 9.0000e-05\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5885 - mae: 0.2451 - mse: 0.1175 - accuracy: 0.7682 - my_f1: 0.7627 - my_acc: 0.7667 - val_loss: 0.5111 - val_mae: 0.2184 - val_mse: 0.1035 - val_accuracy: 0.7710 - val_my_f1: 0.7754 - val_my_acc: 0.7791 - lr: 9.0000e-05\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.5811 - mae: 0.2435 - mse: 0.1179 - accuracy: 0.7610 - my_f1: 0.7574 - my_acc: 0.7626 - val_loss: 0.5129 - val_mae: 0.2179 - val_mse: 0.1035 - val_accuracy: 0.7715 - val_my_f1: 0.7793 - val_my_acc: 0.7836 - lr: 9.0000e-05\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 1s 149ms/step - loss: 0.5717 - mae: 0.2385 - mse: 0.1144 - accuracy: 0.7730 - my_f1: 0.7621 - my_acc: 0.7672 - val_loss: 0.5115 - val_mae: 0.2184 - val_mse: 0.1034 - val_accuracy: 0.7740 - val_my_f1: 0.7773 - val_my_acc: 0.7812 - lr: 9.0000e-05\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.5817 - mae: 0.2436 - mse: 0.1175 - accuracy: 0.7632 - my_f1: 0.7534 - my_acc: 0.7594 - val_loss: 0.5120 - val_mae: 0.2181 - val_mse: 0.1034 - val_accuracy: 0.7720 - val_my_f1: 0.7790 - val_my_acc: 0.7839 - lr: 9.0000e-05\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5789 - mae: 0.2415 - mse: 0.1159 - accuracy: 0.7706 - my_f1: 0.7634 - my_acc: 0.7687 - val_loss: 0.5137 - val_mae: 0.2179 - val_mse: 0.1035 - val_accuracy: 0.7765 - val_my_f1: 0.7824 - val_my_acc: 0.7871 - lr: 9.0000e-05\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.5956 - mae: 0.2469 - mse: 0.1192 - accuracy: 0.7574 - my_f1: 0.7519 - my_acc: 0.7566 - val_loss: 0.5110 - val_mae: 0.2192 - val_mse: 0.1037 - val_accuracy: 0.7710 - val_my_f1: 0.7849 - val_my_acc: 0.7874 - lr: 9.0000e-05\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.5791 - mae: 0.2436 - mse: 0.1166 - accuracy: 0.7690 - my_f1: 0.7611 - my_acc: 0.7659 - val_loss: 0.5116 - val_mae: 0.2178 - val_mse: 0.1033 - val_accuracy: 0.7730 - val_my_f1: 0.7804 - val_my_acc: 0.7846 - lr: 9.0000e-05\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.5707 - mae: 0.2407 - mse: 0.1151 - accuracy: 0.7660 - my_f1: 0.7592 - my_acc: 0.7633 - val_loss: 0.5130 - val_mae: 0.2180 - val_mse: 0.1035 - val_accuracy: 0.7740 - val_my_f1: 0.7819 - val_my_acc: 0.7853 - lr: 9.0000e-05\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5797 - mae: 0.2423 - mse: 0.1163 - accuracy: 0.7662 - my_f1: 0.7621 - my_acc: 0.7649\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.5797 - mae: 0.2423 - mse: 0.1163 - accuracy: 0.7662 - my_f1: 0.7621 - my_acc: 0.7649 - val_loss: 0.5108 - val_mae: 0.2179 - val_mse: 0.1033 - val_accuracy: 0.7735 - val_my_f1: 0.7823 - val_my_acc: 0.7850 - lr: 9.0000e-05\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 0.5765 - mae: 0.2415 - mse: 0.1161 - accuracy: 0.7650 - my_f1: 0.7648 - my_acc: 0.7683 - val_loss: 0.5106 - val_mae: 0.2176 - val_mse: 0.1032 - val_accuracy: 0.7725 - val_my_f1: 0.7764 - val_my_acc: 0.7801 - lr: 2.7000e-05\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.5695 - mae: 0.2395 - mse: 0.1139 - accuracy: 0.7758 - my_f1: 0.7766 - my_acc: 0.7791 - val_loss: 0.5096 - val_mae: 0.2176 - val_mse: 0.1031 - val_accuracy: 0.7720 - val_my_f1: 0.7808 - val_my_acc: 0.7839 - lr: 2.7000e-05\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5704 - mae: 0.2417 - mse: 0.1150 - accuracy: 0.7654 - my_f1: 0.7546 - my_acc: 0.7591 - val_loss: 0.5099 - val_mae: 0.2171 - val_mse: 0.1031 - val_accuracy: 0.7710 - val_my_f1: 0.7752 - val_my_acc: 0.7791 - lr: 2.7000e-05\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 0.5665 - mae: 0.2404 - mse: 0.1150 - accuracy: 0.7668 - my_f1: 0.7641 - my_acc: 0.7684 - val_loss: 0.5105 - val_mae: 0.2166 - val_mse: 0.1031 - val_accuracy: 0.7735 - val_my_f1: 0.7768 - val_my_acc: 0.7808 - lr: 2.7000e-05\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.5729 - mae: 0.2389 - mse: 0.1147 - accuracy: 0.7682 - my_f1: 0.7602 - my_acc: 0.7652 - val_loss: 0.5104 - val_mae: 0.2164 - val_mse: 0.1031 - val_accuracy: 0.7720 - val_my_f1: 0.7759 - val_my_acc: 0.7798 - lr: 2.7000e-05\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5722 - mae: 0.2389 - mse: 0.1149 - accuracy: 0.7752 - my_f1: 0.7706 - my_acc: 0.7749 - val_loss: 0.5093 - val_mae: 0.2166 - val_mse: 0.1030 - val_accuracy: 0.7720 - val_my_f1: 0.7807 - val_my_acc: 0.7839 - lr: 2.7000e-05\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.5772 - mae: 0.2402 - mse: 0.1151 - accuracy: 0.7690 - my_f1: 0.7685 - my_acc: 0.7724 - val_loss: 0.5090 - val_mae: 0.2168 - val_mse: 0.1031 - val_accuracy: 0.7725 - val_my_f1: 0.7857 - val_my_acc: 0.7884 - lr: 2.7000e-05\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 1s 184ms/step - loss: 0.5663 - mae: 0.2392 - mse: 0.1144 - accuracy: 0.7688 - my_f1: 0.7735 - my_acc: 0.7781 - val_loss: 0.5095 - val_mae: 0.2166 - val_mse: 0.1030 - val_accuracy: 0.7715 - val_my_f1: 0.7804 - val_my_acc: 0.7836 - lr: 2.7000e-05\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 1s 205ms/step - loss: 0.5708 - mae: 0.2390 - mse: 0.1139 - accuracy: 0.7742 - my_f1: 0.7725 - my_acc: 0.7762 - val_loss: 0.5107 - val_mae: 0.2162 - val_mse: 0.1031 - val_accuracy: 0.7715 - val_my_f1: 0.7758 - val_my_acc: 0.7794 - lr: 2.7000e-05\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5682 - mae: 0.2373 - mse: 0.1135 - accuracy: 0.7782 - my_f1: 0.7793 - my_acc: 0.7826\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.5682 - mae: 0.2373 - mse: 0.1135 - accuracy: 0.7782 - my_f1: 0.7793 - my_acc: 0.7826 - val_loss: 0.5114 - val_mae: 0.2160 - val_mse: 0.1031 - val_accuracy: 0.7735 - val_my_f1: 0.7809 - val_my_acc: 0.7850 - lr: 2.7000e-05\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.5737 - mae: 0.2397 - mse: 0.1153 - accuracy: 0.7658 - my_f1: 0.7665 - my_acc: 0.7711 - val_loss: 0.5112 - val_mae: 0.2161 - val_mse: 0.1031 - val_accuracy: 0.7725 - val_my_f1: 0.7764 - val_my_acc: 0.7801 - lr: 8.1000e-06\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.5803 - mae: 0.2420 - mse: 0.1161 - accuracy: 0.7628 - my_f1: 0.7610 - my_acc: 0.7664 - val_loss: 0.5108 - val_mae: 0.2161 - val_mse: 0.1031 - val_accuracy: 0.7725 - val_my_f1: 0.7764 - val_my_acc: 0.7801 - lr: 8.1000e-06\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.5713 - mae: 0.2385 - mse: 0.1144 - accuracy: 0.7686 - my_f1: 0.7676 - my_acc: 0.7728 - val_loss: 0.5103 - val_mae: 0.2161 - val_mse: 0.1030 - val_accuracy: 0.7710 - val_my_f1: 0.7755 - val_my_acc: 0.7791 - lr: 8.1000e-06\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 148ms/step - loss: 0.5652 - mae: 0.2376 - mse: 0.1135 - accuracy: 0.7732 - my_f1: 0.7789 - my_acc: 0.7834 - val_loss: 0.5101 - val_mae: 0.2161 - val_mse: 0.1030 - val_accuracy: 0.7710 - val_my_f1: 0.7755 - val_my_acc: 0.7791 - lr: 8.1000e-06\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 1s 176ms/step - loss: 0.5687 - mae: 0.2396 - mse: 0.1145 - accuracy: 0.7750 - my_f1: 0.7827 - my_acc: 0.7864 - val_loss: 0.5101 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7710 - val_my_f1: 0.7755 - val_my_acc: 0.7791 - lr: 8.1000e-06\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.5751 - mae: 0.2400 - mse: 0.1160 - accuracy: 0.7606 - my_f1: 0.7524 - my_acc: 0.7572 - val_loss: 0.5101 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7705 - val_my_f1: 0.7799 - val_my_acc: 0.7829 - lr: 8.1000e-06\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.5810 - mae: 0.2403 - mse: 0.1164 - accuracy: 0.7612 - my_f1: 0.7592 - my_acc: 0.7628 - val_loss: 0.5100 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7710 - val_my_f1: 0.7803 - val_my_acc: 0.7833 - lr: 8.1000e-06\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.5707 - mae: 0.2386 - mse: 0.1154 - accuracy: 0.7670 - my_f1: 0.7663 - my_acc: 0.7707 - val_loss: 0.5100 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7710 - val_my_f1: 0.7755 - val_my_acc: 0.7791 - lr: 8.1000e-06\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 0.5676 - mae: 0.2371 - mse: 0.1140 - accuracy: 0.7728 - my_f1: 0.7731 - my_acc: 0.7765 - val_loss: 0.5098 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7715 - val_my_f1: 0.7758 - val_my_acc: 0.7794 - lr: 8.1000e-06\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5789 - mae: 0.2401 - mse: 0.1158 - accuracy: 0.7684 - my_f1: 0.7563 - my_acc: 0.7603Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.5789 - mae: 0.2401 - mse: 0.1158 - accuracy: 0.7684 - my_f1: 0.7563 - my_acc: 0.7603 - val_loss: 0.5099 - val_mae: 0.2160 - val_mse: 0.1030 - val_accuracy: 0.7715 - val_my_f1: 0.7758 - val_my_acc: 0.7794 - lr: 8.1000e-06\n",
      "Epoch 87: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neurons0 = 642\n",
    "neurons1 = 434\n",
    "neurons2 = 38\n",
    "lr = 0.0012261\n",
    "dropout = 0.73423\n",
    "layers1 = 0\n",
    "layers2 = 3\n",
    "ln = 0\n",
    "batch_size = 963\n",
    "noise = 1\n",
    "\n",
    "model = getModel(neurons0=neurons0,\n",
    "                 neurons1=neurons1,\n",
    "                 neurons2=neurons2,\n",
    "                 layers1=layers1,\n",
    "                 layers2=layers2,\n",
    "                 dropout=dropout,\n",
    "                 lr=lr,\n",
    "                 ln=ln,\n",
    "                 noise=noise)\n",
    "\n",
    "history = model.fit(X/10.0,y,\n",
    "          validation_data=(X_val/10.0,y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=500,\n",
    "          verbose=1,\n",
    "         callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir=\"logs/optuna2/best/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                        histogram_freq=1,\n",
    "                        write_graph=True,\n",
    "                        update_freq=\"epoch\"),\n",
    "                    tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor=\"val_my_f1\",\n",
    "                                    patience=50,\n",
    "                                    verbose=1,\n",
    "                                    mode=\"max\",\n",
    "                                    restore_best_weights=True,\n",
    "                                ),\n",
    "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_my_f1\",\n",
    "    factor=0.3,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-10,\n",
    ")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X/10.0,y,\n",
    "#           validation_data=(X_val/10.0,y_val),\n",
    "#           batch_size=1024,\n",
    "#           epochs=500,\n",
    "#           verbose=0,\n",
    "#          callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir=\"logs/0/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "#     histogram_freq=1,\n",
    "#     write_graph=True,\n",
    "#     update_freq=\"epoch\"),#PlotLossesKerasTF(),\n",
    "# #                    tf.keras.callbacks.ModelCheckpoint(\n",
    "# #     'checkpoint',\n",
    "# #     monitor=\"val_my_f1\",\n",
    "# #     verbose=1,\n",
    "# #     save_best_only=True,\n",
    "# #     save_weights_only=False,\n",
    "# #     mode=\"max\",\n",
    "# #     save_freq=\"epoch\",),\n",
    "#                     tf.keras.callbacks.EarlyStopping(\n",
    "#                                     monitor=\"val_my_f1\",\n",
    "#                                     patience=100,\n",
    "#                                     verbose=1,\n",
    "#                                     mode=\"max\",\n",
    "#                                     restore_best_weights=True,\n",
    "#                                 ),\n",
    "#                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor=\"val_my_f1\",\n",
    "#     factor=0.3,\n",
    "#     patience=10,\n",
    "#     verbose=1,\n",
    "#     mode=\"max\",\n",
    "#     min_delta=0.0001,\n",
    "#     cooldown=0,\n",
    "#     min_lr=1e-10,\n",
    "# )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.7637943535908992\n",
      "Accuracy Score : 0.761\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val/10.0)\n",
    "# y_pred.shape\n",
    "print(f\"F1 Score : {f1_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1), average='weighted')}\")\n",
    "print(f\"Accuracy Score : {accuracy_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]], dtype=float32)>,\n",
       " array([[1.4942489e-03, 2.8291926e-01, 7.1558642e-01],\n",
       "        [1.0094841e-01, 7.2233212e-01, 1.7671947e-01],\n",
       "        [8.6465949e-01, 1.3228248e-01, 3.0580773e-03],\n",
       "        [1.8148777e-01, 7.6399928e-01, 5.4512929e-02],\n",
       "        [7.9855815e-02, 6.7361981e-01, 2.4652432e-01],\n",
       "        [8.7316757e-01, 1.2421182e-01, 2.6207031e-03],\n",
       "        [7.4558127e-01, 2.4679761e-01, 7.6211370e-03],\n",
       "        [2.4400548e-04, 1.7287822e-01, 8.2687777e-01],\n",
       "        [7.9243368e-01, 2.0136975e-01, 6.1966032e-03],\n",
       "        [9.7946683e-03, 5.5327481e-01, 4.3693057e-01]], dtype=float32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:10],y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqVzEIs4P7X1"
   },
   "source": [
    "## Generating the Predictions\n",
    "\n",
    "Generating Predictions from test data to make submission in the puzzle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1643711867290,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "WHNi9e7TP8pz",
    "outputId": "4dc030f1-eb3b-4c34-92f2-87c304e78d5f"
   },
   "outputs": [],
   "source": [
    "submission_embeddings = [literal_eval(embedding)  for embedding in submission['embeddings'].values]\n",
    "\n",
    "predictions = np.argmax(model.predict(np.array(submission_embeddings)/10.0),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):\n",
    "    if a==0:\n",
    "        return 'negative'\n",
    "    if a==1:\n",
    "        return 'neutral'\n",
    "    if a==2:\n",
    "        return 'positive'\n",
    "\n",
    "result = list(map(convert, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['negative', 'neutral', 'positive'], dtype='<U8'),\n",
       " array([1004, 1083,  914]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1643711867292,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "J4vBe0mAQDJv",
    "outputId": "65e20e41-bfcf-4ab6-bb49-90569b52d2b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.08109518140554428, 0.3090009093284607, 1.36...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.6809610724449158, 1.1909409761428833, 0.892...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.14851869642734528, 0.7872061133384705, 0.89...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.44697386026382446, 0.36429283022880554, 0.7...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.8009324073791504, 0.26081395149230957, 0.40...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[0.9138844609260559, 0.9460961222648621, 0.571...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[0.7667452096939087, 0.7896291613578796, 0.648...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[0.8158280849456787, 2.404792070388794, 0.9924...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[0.4161085784435272, 0.3146701455116272, 1.139...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>[0.7037264108657837, 0.6421875357627869, 1.215...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.08109518140554428, 0.3090009093284607, 1.36...  positive\n",
       "1     [0.6809610724449158, 1.1909409761428833, 0.892...   neutral\n",
       "2     [0.14851869642734528, 0.7872061133384705, 0.89...   neutral\n",
       "3     [0.44697386026382446, 0.36429283022880554, 0.7...   neutral\n",
       "4     [1.8009324073791504, 0.26081395149230957, 0.40...  negative\n",
       "...                                                 ...       ...\n",
       "2996  [0.9138844609260559, 0.9460961222648621, 0.571...  negative\n",
       "2997  [0.7667452096939087, 0.7896291613578796, 0.648...  negative\n",
       "2998  [0.8158280849456787, 2.404792070388794, 0.9924...   neutral\n",
       "2999  [0.4161085784435272, 0.3146701455116272, 1.139...  positive\n",
       "3000  [0.7037264108657837, 0.6421875357627869, 1.215...  negative\n",
       "\n",
       "[3001 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['label'] = result\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30oDKdd7HV8R"
   },
   "source": [
    "### Saving the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Qv7xSbHQHVPg"
   },
   "outputs": [],
   "source": [
    "# Saving the predictions\n",
    "!rm -rf assets\n",
    "!mkdir assets\n",
    "submission.to_csv(os.path.join(\"assets\", \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaFShaKnHH7s"
   },
   "source": [
    "## Submitting our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/Anb7h1ae69c1cBsDUoI8ZfoBk9mkoiU_YJUACGldK5M\u001b[0m\n",
      "\u001b[32mAPI Key valid\u001b[0m\n",
      "\u001b[32mGitlab access token valid\u001b[0m\n",
      "\u001b[32mSaved details successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357,
     "referenced_widgets": [
      "4660207a213e42b799859c22675d2476",
      "45f6d3e90b9f46f29b8cdc49f069bcc5"
     ]
    },
    "executionInfo": {
     "elapsed": 38827,
     "status": "ok",
     "timestamp": 1643713380919,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "JyrIU1uXHMjb",
    "outputId": "867e512d-72b1-4b5a-a584-4f0d9c9c6f21"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using notebook: keras-mlp.ipynb for submission...\n",
      "Removing existing files from submission directory...\n",
      "Scrubbing API keys from the notebook...\n",
      "Collecting notebook...\n",
      "\u001b[31mAn unexpected error occured!\u001b[0m\n",
      "cannot unpack non-iterable NoneType object\n",
      "To get more information, you can run this command with -v.\n",
      "To increase level of verbosity, you can go upto -vvvvv\n"
     ]
    }
   ],
   "source": [
    "%aicrowd notebook submit -c sentiment-classification -a assets --no-verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: submission.csv (deflated 56%)\n"
     ]
    }
   ],
   "source": [
    "! cd assets/ ; zip submission.zip submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYxDSoFLHy-9"
   },
   "source": [
    "Congratulations to making your first submission in the puzzle 🎉  . Let's continue with the journey by improving the baseline & making submission! Don't be shy to ask question related to any errors you are getting or doubts in any part of this notebook in discussion forum or in AIcrowd Discord sever, AIcrew will be happy to help you :)\n",
    "\n",
    "Have a cool new idea that you want to see in the next blitz ? Let us know!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[Baseline] Sentiment Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch11",
   "language": "python",
   "name": "pytorch11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0aa4ed5fb03448ef84d3a135c16ec784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "170d0d740db442d3905be5531b06a61f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23736fb1fe9941d39e74c528bfb42b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d6465e7dcc14b028433dafa2a19425e",
       "IPY_MODEL_f5ed31c8977c497cbfec64e30da03832",
       "IPY_MODEL_f2c058254a184182afcd4863966fe3b0"
      ],
      "layout": "IPY_MODEL_356bb9aeb3d942789fb47d03ee959004"
     }
    },
    "2827392c9da7413ab6b243fd889f2898": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9ce6366369440cb2a718a99e319ac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_785c99db6c094914b3a68ee18f271e8d",
      "placeholder": "​",
      "style": "IPY_MODEL_93b4a902120d4088a6b2af9901271e9e",
      "value": "val.csv: 100%"
     }
    },
    "32cfaa5a941d4d00b3cbfbe11752219f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "356bb9aeb3d942789fb47d03ee959004": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f6d3e90b9f46f29b8cdc49f069bcc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4635077ae52e421e962eb0073daab11a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6970f61c501447fadf6ea6f41fccf97",
       "IPY_MODEL_6e131d04bbcb43568745f77b9841fdd9",
       "IPY_MODEL_5007344417f848afb17cafc21c1318e7"
      ],
      "layout": "IPY_MODEL_2827392c9da7413ab6b243fd889f2898"
     }
    },
    "4660207a213e42b799859c22675d2476": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_45f6d3e90b9f46f29b8cdc49f069bcc5",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">submission.zip</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100.0%</span> • <span style=\"color: #008000; text-decoration-color: #008000\">13.7/13.7 MB</span> • <span style=\"color: #800000; text-decoration-color: #800000\">577.6 kB/s</span> • <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
         "text/plain": "\u001b[1;34msubmission.zip\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m13.7/13.7 MB\u001b[0m • \u001b[31m577.6 kB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5007344417f848afb17cafc21c1318e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd77e70c4b134b85b2932d58453f5a68",
      "placeholder": "​",
      "style": "IPY_MODEL_d311dd0574cb403d9715060713cf75cd",
      "value": " 51.5M/51.5M [00:07&lt;00:00, 7.25MB/s]"
     }
    },
    "6d6465e7dcc14b028433dafa2a19425e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d84b10f328b34c2faed9a043df506299",
      "placeholder": "​",
      "style": "IPY_MODEL_bd3b2ca98236429696a87022959d0801",
      "value": "sample_submission.csv: 100%"
     }
    },
    "6e131d04bbcb43568745f77b9841fdd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75ed77729b3742f4bde159b2b98b9668",
      "max": 51491549,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32cfaa5a941d4d00b3cbfbe11752219f",
      "value": 51491549
     }
    },
    "75ed77729b3742f4bde159b2b98b9668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "785c99db6c094914b3a68ee18f271e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f04cb429d2846b7975ee2f755f124d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8547805f4cd64e43808e0872b2fb0bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ad49a922f5d4340840e874bbbfe7b0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bd929029c0f4114a7ef0c8d1fd00617": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93b4a902120d4088a6b2af9901271e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fd78fe2d4e24537939c8b4410d33cd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ad49a922f5d4340840e874bbbfe7b0d",
      "max": 20596780,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8547805f4cd64e43808e0872b2fb0bc6",
      "value": 20596780
     }
    },
    "a6970f61c501447fadf6ea6f41fccf97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_170d0d740db442d3905be5531b06a61f",
      "placeholder": "​",
      "style": "IPY_MODEL_b507f431b4f34a3bb1b3bb857d999537",
      "value": "train.csv: 100%"
     }
    },
    "acf1c7050df144f09ae546fedb526c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b507f431b4f34a3bb1b3bb857d999537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b83309f18f984170950a161640014ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bd929029c0f4114a7ef0c8d1fd00617",
      "placeholder": "​",
      "style": "IPY_MODEL_0aa4ed5fb03448ef84d3a135c16ec784",
      "value": " 20.6M/20.6M [00:02&lt;00:00, 8.56MB/s]"
     }
    },
    "bd3b2ca98236429696a87022959d0801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c19725d50f074ec6bd8ab3cc0ae57e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a9ce6366369440cb2a718a99e319ac3",
       "IPY_MODEL_9fd78fe2d4e24537939c8b4410d33cd4",
       "IPY_MODEL_b83309f18f984170950a161640014ea1"
      ],
      "layout": "IPY_MODEL_acf1c7050df144f09ae546fedb526c56"
     }
    },
    "cac22b36b89f447da218aa89ada9e7dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d311dd0574cb403d9715060713cf75cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d84b10f328b34c2faed9a043df506299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2083b61e874577883492c7afbc846c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd77e70c4b134b85b2932d58453f5a68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c058254a184182afcd4863966fe3b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f04cb429d2846b7975ee2f755f124d3",
      "placeholder": "​",
      "style": "IPY_MODEL_cac22b36b89f447da218aa89ada9e7dd",
      "value": " 30.9M/30.9M [00:02&lt;00:00, 11.2MB/s]"
     }
    },
    "f2c198b39f67459da417208e66229249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5ed31c8977c497cbfec64e30da03832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd2083b61e874577883492c7afbc846c",
      "max": 30904133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2c198b39f67459da417208e66229249",
      "value": 30904133
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
