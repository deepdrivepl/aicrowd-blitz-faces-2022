{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEWUMWN9JgZs"
   },
   "source": [
    "![](https://images.aicrowd.com/raw_images/challenges/banner_file/1023/a8ebe297c369ea4a7697.png)\n",
    "\n",
    "<h2><center>Starter Code for Sentiment Classification</center></h2>\n",
    "\n",
    "\n",
    "In this baseline we will be training an sklearn model to do a multi-class classificattion of sentiment from face embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXUiejgu26rH"
   },
   "source": [
    "## Downloading Dataset\n",
    "\n",
    "Installing puzzle datasets via `aicrowd-cli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10358,
     "status": "ok",
     "timestamp": 1643711621853,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "vuvPB05qFe41",
    "outputId": "55484aea-183d-4a56-83b5-eed55a99f7d0"
   },
   "outputs": [],
   "source": [
    "# !pip install aicrowd-cli\n",
    "\n",
    "# Make sure to re-run below code whenever you restart colab notebook\n",
    "#%load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19267,
     "status": "ok",
     "timestamp": 1643711641079,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "ZQH9HAy23I7Y",
    "outputId": "dd9b6e7a-e08d-45e2-aa9d-2921331da051"
   },
   "outputs": [],
   "source": [
    "# # Logging in from our AIcrowd account. Make sure you have accepted the puzzle rules before logging in!  \n",
    "\n",
    "#%aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "23736fb1fe9941d39e74c528bfb42b72",
      "356bb9aeb3d942789fb47d03ee959004",
      "6d6465e7dcc14b028433dafa2a19425e",
      "f5ed31c8977c497cbfec64e30da03832",
      "f2c058254a184182afcd4863966fe3b0",
      "bd3b2ca98236429696a87022959d0801",
      "d84b10f328b34c2faed9a043df506299",
      "f2c198b39f67459da417208e66229249",
      "dd2083b61e874577883492c7afbc846c",
      "cac22b36b89f447da218aa89ada9e7dd",
      "7f04cb429d2846b7975ee2f755f124d3",
      "4635077ae52e421e962eb0073daab11a",
      "2827392c9da7413ab6b243fd889f2898",
      "a6970f61c501447fadf6ea6f41fccf97",
      "6e131d04bbcb43568745f77b9841fdd9",
      "5007344417f848afb17cafc21c1318e7",
      "b507f431b4f34a3bb1b3bb857d999537",
      "170d0d740db442d3905be5531b06a61f",
      "32cfaa5a941d4d00b3cbfbe11752219f",
      "75ed77729b3742f4bde159b2b98b9668",
      "d311dd0574cb403d9715060713cf75cd",
      "dd77e70c4b134b85b2932d58453f5a68",
      "c19725d50f074ec6bd8ab3cc0ae57e0a",
      "acf1c7050df144f09ae546fedb526c56",
      "2a9ce6366369440cb2a718a99e319ac3",
      "9fd78fe2d4e24537939c8b4410d33cd4",
      "b83309f18f984170950a161640014ea1",
      "93b4a902120d4088a6b2af9901271e9e",
      "785c99db6c094914b3a68ee18f271e8d",
      "8547805f4cd64e43808e0872b2fb0bc6",
      "8ad49a922f5d4340840e874bbbfe7b0d",
      "0aa4ed5fb03448ef84d3a135c16ec784",
      "8bd929029c0f4114a7ef0c8d1fd00617"
     ]
    },
    "executionInfo": {
     "elapsed": 20995,
     "status": "ok",
     "timestamp": 1643711661964,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "GOiUWHo53W6n",
    "outputId": "6631f173-8ec8-4f72-bdbf-1cc82dd1fb3e"
   },
   "outputs": [],
   "source": [
    "# # Creating a new data directory and downloading the dataset \n",
    "\n",
    "# !rm -rf data\n",
    "# !mkdir data\n",
    "# %aicrowd ds dl -c sentiment-classification -o data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4t_xZL73krM"
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "In this baseline, we will be sing sklearn [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify the sentiment of face embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ReMrWg8l3mRU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-mLdFyU3-Tw"
   },
   "source": [
    "## Reading Dataset\n",
    "\n",
    "As mented in the challenge readme, we have three different sets provided - train, validation and test respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2476,
     "status": "ok",
     "timestamp": 1643711675304,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "9uR1JofUJQKi",
    "outputId": "f071c14b-646e-4bad-8690-d77cbeb62464"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3206779360771179, 0.988215982913971, 1.0441...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.05074610561132431, 1.0742985010147095, 0.60...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.41962647438049316, 0.4505457878112793, 1.39...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4361684024333954, 0.19191382825374603, 0.83...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6382085084915161, 0.8352395296096802, 0.393...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[2.2057647705078125, 1.1072001457214355, 0.435...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[0.6344252228736877, 1.164398193359375, 0.7155...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[0.9160683155059814, 0.39996421337127686, 0.82...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[0.006456990726292133, 0.18667978048324585, 0....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[1.337027668952942, 0.8853631615638733, 0.6706...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.3206779360771179, 0.988215982913971, 1.0441...  positive\n",
       "1     [0.05074610561132431, 1.0742985010147095, 0.60...  negative\n",
       "2     [0.41962647438049316, 0.4505457878112793, 1.39...  negative\n",
       "3     [0.4361684024333954, 0.19191382825374603, 0.83...  positive\n",
       "4     [0.6382085084915161, 0.8352395296096802, 0.393...   neutral\n",
       "...                                                 ...       ...\n",
       "4995  [2.2057647705078125, 1.1072001457214355, 0.435...   neutral\n",
       "4996  [0.6344252228736877, 1.164398193359375, 0.7155...  negative\n",
       "4997  [0.9160683155059814, 0.39996421337127686, 0.82...  negative\n",
       "4998  [0.006456990726292133, 0.18667978048324585, 0....  positive\n",
       "4999  [1.337027668952942, 0.8853631615638733, 0.6706...  negative\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readging the csv \n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "val = pd.read_csv(\"data/val.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZmyPFxjwOe1c"
   },
   "outputs": [],
   "source": [
    "# Getting the feature and labels from each set. \n",
    "\n",
    "\n",
    "X = np.array([literal_eval(embedding)  for embedding in train['embeddings'].values])\n",
    "y = np.array(train['label'].values)\n",
    "\n",
    "X_val = np.array([literal_eval(embedding)  for embedding in val['embeddings'].values])\n",
    "y_val = np.array(val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 512), (5000,), (2000, 512), (5000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_val.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR_GJfYVPLgg"
   },
   "source": [
    "## Training the model\n",
    "\n",
    "Here, we will be training our model using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1643711781228,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "GEqeuQreOlwy",
    "outputId": "864fc14a-6037-49ed-8080-0f9b5c125f0d"
   },
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10915,
     "status": "ok",
     "timestamp": 1643711792085,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "8fne6a1JOoi3",
    "outputId": "dc75a304-ab70-4d9e-f81e-d2dfbdfd5906"
   },
   "outputs": [],
   "source": [
    "# model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hepi-cuRPNow"
   },
   "source": [
    "### Testing the Model\n",
    "\n",
    "Here, we will be evaluator our model using validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1643711812095,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "1v0w1WLbPVK8",
    "outputId": "2d4d28c8-0ff3-4dd6-a5ca-07464c060b28"
   },
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_val)\n",
    "\n",
    "# print(f\"F1 Score : {f1_score(y_val, y_pred, average='weighted')}\")\n",
    "# print(f\"Accuracy Score : {accuracy_score(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.integration import TFKerasPruningCallback, TensorBoardCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y=='positive']=2\n",
    "y[y=='negative']=0\n",
    "y[y=='neutral']=1\n",
    "y = tf.one_hot(y,3)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([10000,  5000], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[y_val=='positive']=2\n",
    "y_val[y_val=='negative']=0\n",
    "y_val[y_val=='neutral']=1\n",
    "y_val = tf.one_hot(y_val,3)\n",
    "y_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n        'EagerTensor' object has no attribute 'astype'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-05f8637f5776>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0m\u001b[0;32m    401\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'astype'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "# y=y.astype(np.float32)\n",
    "# y_val=y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def getModelOld(neurons0=1024,neurons1=1024,neurons2=1024, layers1=3, layers2=3,\n",
    "#              dropout=0.5, lr=3e-3, ln=0, noise=1, num_heads=8, num_atts=1):\n",
    "#     x = tf.keras.layers.InputLayer(input_shape=(512,))\n",
    "    \n",
    "#     ls=[]\n",
    "#     for _ in range(num_atts):\n",
    "#         ls.append(tf.keras.layers.MultiHeadAttention(num_heads, key_dim=1, dropout=dropout))\n",
    "    \n",
    "    \n",
    "#     ls.append(tf.keras.layers.Dense(neurons0, activation='relu'))\n",
    "    \n",
    "#     if noise>0:\n",
    "#         ls.append(tf.keras.layers.GaussianNoise(0.1))\n",
    "    \n",
    "#     if ln>0:\n",
    "#         ls.append(tf.keras.layers.LayerNormalization())\n",
    "        \n",
    "#     for _ in range(layers1):\n",
    "#         ls.append(tf.keras.layers.Dense(neurons1, activation='relu'),)\n",
    "#     for _ in range(layers2):\n",
    "#         ls.append(tf.keras.layers.Dense(neurons2, activation='relu'),)\n",
    "#     if ln>1:\n",
    "#         ls.append(tf.keras.layers.LayerNormalization())\n",
    "#     ls.append(tf.keras.layers.Dropout(dropout))\n",
    "#     ls.append(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "#     model = tf.keras.models.Sequential(ls)\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['mae','mse','accuracy',my_f1,my_acc],\n",
    "#                   run_eagerly=True)\n",
    "#     return model\n",
    "\n",
    "# # def getModelCls():\n",
    "# #     model = tf.keras.models.Sequential([tf.keras.layers.Dense(1024, activation='relu', input_shape=(512,)),\n",
    "# # #                                         tf.keras.layers.Dropout(0.25),\n",
    "# #                                         tf.keras.layers.LayerNormalization(),\n",
    "# #                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "# #                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "# #                                         tf.keras.layers.Dropout(0.5),\n",
    "# #                                         tf.keras.layers.Dense(1024, activation='relu'),\n",
    "# #                                         tf.keras.layers.LayerNormalization(),\n",
    "# #                                         tf.keras.layers.Dropout(0.5),\n",
    "# #                                         tf.keras.layers.Dense(3, activation='softmax')])\n",
    "# #     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "# #                   loss='categorical_crossentropy',\n",
    "# #                   metrics=['mae','mse','accuracy',my_f1,my_acc],\n",
    "# #                   run_eagerly=True)\n",
    "# #     return model\n",
    "# # model = getModelCls()\n",
    "# # model.summary()\n",
    "\n",
    "# # model.fit(X/10.0,y,\n",
    "# #           validation_data=(X_val/10.0,y_val),\n",
    "# #           batch_size=1024,\n",
    "# #           epochs=500,\n",
    "# #           verbose=0,\n",
    "# #          callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "# #     log_dir=\"logs/0/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "# #     histogram_freq=1,\n",
    "# #     write_graph=True,\n",
    "# #     update_freq=\"epoch\"),#PlotLossesKerasTF(),\n",
    "# # #                    tf.keras.callbacks.ModelCheckpoint(\n",
    "# # #     'checkpoint',\n",
    "# # #     monitor=\"val_my_f1\",\n",
    "# # #     verbose=1,\n",
    "# # #     save_best_only=True,\n",
    "# # #     save_weights_only=False,\n",
    "# # #     mode=\"max\",\n",
    "# # #     save_freq=\"epoch\",),\n",
    "# #                     tf.keras.callbacks.EarlyStopping(\n",
    "# #                                     monitor=\"val_my_f1\",\n",
    "# #                                     patience=100,\n",
    "# #                                     verbose=1,\n",
    "# #                                     mode=\"max\",\n",
    "# #                                     restore_best_weights=True,\n",
    "# #                                 ),\n",
    "# #                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "# #     monitor=\"val_my_f1\",\n",
    "# #     factor=0.3,\n",
    "# #     patience=10,\n",
    "# #     verbose=1,\n",
    "# #     mode=\"max\",\n",
    "# #     min_delta=0.0001,\n",
    "# #     cooldown=0,\n",
    "# #     min_lr=1e-10,\n",
    "# # )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1(y_val, y_pred, sample_weight=None):\n",
    "    return f1_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1),average='weighted')\n",
    "\n",
    "def my_acc(y_val, y_pred, sample_weight=None):\n",
    "    return accuracy_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1))\n",
    "\n",
    "def getModel(neurons0=1024,neurons1=1024,neurons2=1024, layers1=3, layers2=3,\n",
    "             dropout=0.5, lr=3e-3, ln=0, noise=1, num_heads=8):\n",
    "    xx = tf.keras.Input(shape=(512,))\n",
    "    if num_heads>0:\n",
    "        x=tf.keras.layers.Reshape((1,512))(xx)\n",
    "        x=tf.keras.layers.MultiHeadAttention(num_heads, key_dim=1, dropout=dropout)(x,x)\n",
    "        x=tf.keras.layers.Dense(neurons0, activation='relu')(tf.keras.layers.Flatten()(x))\n",
    "    else:\n",
    "        x=tf.keras.layers.Dense(neurons0, activation='relu')(xx)\n",
    "\n",
    "    x=tf.keras.layers.GaussianNoise(noise)(x)\n",
    "    \n",
    "    if ln>0:\n",
    "        x=tf.keras.layers.LayerNormalization()(x)\n",
    "        \n",
    "    for _ in range(layers1):\n",
    "        x=tf.keras.layers.Dense(neurons1, activation='relu')(x)\n",
    "    for _ in range(layers2):\n",
    "        x=tf.keras.layers.Dense(neurons2, activation='relu')(x)\n",
    "    if ln>1:\n",
    "        x=tf.keras.layers.LayerNormalization()(x)\n",
    "    x=tf.keras.layers.Dropout(dropout)(x)\n",
    "    x=tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=xx,outputs=x)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['mae','mse','accuracy',my_f1,my_acc],\n",
    "                  run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def getModelHuber(neurons0=1024,neurons1=1024,neurons2=1024, layers1=3, layers2=3,\n",
    "             dropout=0.5, lr=3e-3, ln=0, noise=1, num_heads=8, num_atts=1):\n",
    "    xx = tf.keras.Input(shape=(512,))\n",
    "    if num_atts>0:\n",
    "        x=tf.keras.layers.Reshape((1,512))(xx)\n",
    "        x=tf.keras.layers.MultiHeadAttention(num_heads, key_dim=1, dropout=dropout)(x,x)\n",
    "#         x=tf.keras.layers.Attention()([x,x])\n",
    "\n",
    "        for _ in range(num_atts-1):\n",
    "            x=tf.keras.layers.MultiHeadAttention(num_heads, key_dim=1, dropout=dropout)(x,x)\n",
    "#             x=tf.keras.layers.Attention()([x,x])\n",
    "        x=tf.keras.layers.Dense(neurons0, activation='relu')(tf.keras.layers.Flatten()(x))\n",
    "    else:\n",
    "        x=tf.keras.layers.Dense(neurons0, activation='relu')(xx)\n",
    "\n",
    "    if noise>0:\n",
    "        x=tf.keras.layers.GaussianNoise(0.1)(x)\n",
    "    \n",
    "    if ln>0:\n",
    "        x=tf.keras.layers.LayerNormalization()(x)\n",
    "        \n",
    "    for _ in range(layers1):\n",
    "        x=tf.keras.layers.Dense(neurons1, activation='relu')(x)\n",
    "    for _ in range(layers2):\n",
    "        x=tf.keras.layers.Dense(neurons2, activation='relu')(x)\n",
    "    if ln>1:\n",
    "        x=tf.keras.layers.LayerNormalization()(x)\n",
    "    x=tf.keras.layers.Dropout(dropout)(x)\n",
    "    x=tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.models.Model(inputs=xx,outputs=x)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='huber',\n",
    "                  metrics=['mae','mse'],#,'accuracy',my_f1,my_acc],\n",
    "                  run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "# m = getModel(num_atts=0,num_heads=2)\n",
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "# target = tf.keras.Input(shape=[1,16])\n",
    "# source = tf.keras.Input(shape=[1,16])\n",
    "# output_tensor, weights = layer(target, source,\n",
    "#                                 return_attention_scores=True)\n",
    "# print(output_tensor.shape)\n",
    "\n",
    "# print(weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=100\n",
    "def objective(trial):\n",
    "    neurons0 = trial.suggest_int(\"neurons0\", 16, 128, log=False)\n",
    "    \n",
    "    \n",
    "    lr = 1e-2 #trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.9)\n",
    "    layers1 = trial.suggest_int(\"layers1\", 0, 3)\n",
    "    layers2 = trial.suggest_int(\"layers2\", 0, 3)\n",
    "\n",
    "    if layers1>0:\n",
    "        neurons1 = trial.suggest_int(\"neurons1\", 16, 1024, log=False)\n",
    "    else:\n",
    "        neurons1=0\n",
    "        \n",
    "    if layers2>0:\n",
    "        neurons2 = trial.suggest_int(\"neurons2\", 128, 2048, log=False)\n",
    "    else:\n",
    "        neurons2=0\n",
    "    ln = trial.suggest_int(\"layer_norms\", 0, 2)\n",
    "    batch_size = 256#trial.suggest_int(\"batch_size\", 8, 1024)\n",
    "    noise = trial.suggest_float(\"noise\", 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    disable_att = trial.suggest_categorical('disable_att',['disabled','enabled'])\n",
    "    if disable_att=='disabled':\n",
    "        num_heads=0\n",
    "    else:\n",
    "        num_heads = trial.suggest_int(\"num_heads\", 1, 512)\n",
    "\n",
    "    model = getModel(neurons0=neurons0,\n",
    "                     neurons1=neurons1,\n",
    "                     neurons2=neurons2,\n",
    "                     layers1=layers1,\n",
    "                     layers2=layers2,\n",
    "                     dropout=dropout,\n",
    "                     lr=lr,\n",
    "                     ln=ln,\n",
    "                     noise=noise,\n",
    "                     num_heads=num_heads)\n",
    "    \n",
    "    history = model.fit(X/10.0,y,\n",
    "              validation_data=(X_val/10.0,y_val),\n",
    "              batch_size=batch_size,\n",
    "              epochs=max_epochs,\n",
    "              verbose=0,\n",
    "             callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                            log_dir=\"logs4/optuna/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                            histogram_freq=1,\n",
    "                            write_graph=True,\n",
    "                            update_freq=\"epoch\"),\n",
    "                        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "                        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.3,\n",
    "        patience=20,\n",
    "        verbose=0,\n",
    "        mode=\"max\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=1e-10,\n",
    "\n",
    "    )])\n",
    "    \n",
    "    return max(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\u001b[32m[I 2022-02-14 14:25:58,026]\u001b[0m A new study created in memory with name: no-name-c3446e30-e20d-479e-b41f-f4f8ba203445\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  after removing the cwd from sys.path.\n",
      "\u001b[32m[I 2022-02-14 14:31:36,870]\u001b[0m Trial 0 finished with value: 2.3406832218170166 and parameters: {'neurons0': 63, 'dropout': 0.7693871997161831, 'layers1': 3, 'layers2': 1, 'neurons1': 262, 'neurons2': 1371, 'layer_norms': 2, 'noise': 0.0006250441660476801, 'disable_att': 'disabled'}. Best is trial 0 with value: 2.3406832218170166.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 14:35:51,290]\u001b[0m Trial 1 finished with value: 0.7782848477363586 and parameters: {'neurons0': 88, 'dropout': 0.30759841927868775, 'layers1': 0, 'layers2': 1, 'neurons2': 290, 'layer_norms': 1, 'noise': 0.000355947667389279, 'disable_att': 'disabled'}. Best is trial 1 with value: 0.7782848477363586.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 14:44:59,987]\u001b[0m Trial 2 finished with value: 1.113402009010315 and parameters: {'neurons0': 95, 'dropout': 0.8550511186602808, 'layers1': 0, 'layers2': 2, 'neurons2': 1700, 'layer_norms': 2, 'noise': 0.00015122342187695907, 'disable_att': 'enabled', 'num_heads': 110}. Best is trial 1 with value: 0.7782848477363586.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 14:48:41,077]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 14:53:13,755]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:03:02,950]\u001b[0m Trial 5 finished with value: 0.8754423260688782 and parameters: {'neurons0': 72, 'dropout': 0.49693261346673473, 'layers1': 0, 'layers2': 3, 'neurons2': 1172, 'layer_norms': 1, 'noise': 0.00011283059852535321, 'disable_att': 'enabled', 'num_heads': 186}. Best is trial 1 with value: 0.7782848477363586.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:05:41,642]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:08:11,693]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:14:10,780]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:20:44,583]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:26:38,034]\u001b[0m Trial 10 finished with value: 1.7175142765045166 and parameters: {'neurons0': 122, 'dropout': 0.011768586645525991, 'layers1': 2, 'layers2': 0, 'neurons1': 923, 'layer_norms': 1, 'noise': 0.006688026242020282, 'disable_att': 'disabled'}. Best is trial 1 with value: 0.7782848477363586.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:28:35,906]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:30:25,334]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:40:47,796]\u001b[0m Trial 13 finished with value: 0.9724632501602173 and parameters: {'neurons0': 106, 'dropout': 0.26162931569124714, 'layers1': 0, 'layers2': 3, 'neurons2': 935, 'layer_norms': 1, 'noise': 0.0028800632940123136, 'disable_att': 'enabled', 'num_heads': 498}. Best is trial 1 with value: 0.7782848477363586.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:42:35,548]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 30.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:50:18,049]\u001b[0m Trial 15 finished with value: 0.7515884637832642 and parameters: {'neurons0': 50, 'dropout': 0.46806609816933387, 'layers1': 1, 'layers2': 0, 'neurons1': 23, 'layer_norms': 0, 'noise': 0.0015606054217948873, 'disable_att': 'enabled', 'num_heads': 417}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 15:58:02,151]\u001b[0m Trial 16 finished with value: 0.7762831449508667 and parameters: {'neurons0': 40, 'dropout': 0.43817150714853403, 'layers1': 1, 'layers2': 0, 'neurons1': 17, 'layer_norms': 0, 'noise': 0.002355357846544278, 'disable_att': 'enabled', 'num_heads': 434}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:06:15,392]\u001b[0m Trial 17 finished with value: 0.8802499771118164 and parameters: {'neurons0': 47, 'dropout': 0.4679892585983114, 'layers1': 2, 'layers2': 0, 'neurons1': 25, 'layer_norms': 0, 'noise': 0.0016833435821109078, 'disable_att': 'enabled', 'num_heads': 444}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:14:32,716]\u001b[0m Trial 18 finished with value: 0.9828764200210571 and parameters: {'neurons0': 16, 'dropout': 0.7145487554408646, 'layers1': 1, 'layers2': 0, 'neurons1': 238, 'layer_norms': 0, 'noise': 0.008254459398471019, 'disable_att': 'enabled', 'num_heads': 380}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:21:06,103]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:25:15,896]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:27:30,874]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:31:41,100]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:33:44,150]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:38:24,394]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 54.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:42:14,047]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:45:18,221]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:49:24,887]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:54:00,774]\u001b[0m Trial 28 finished with value: 0.9054540991783142 and parameters: {'neurons0': 41, 'dropout': 0.45694893544652054, 'layers1': 0, 'layers2': 0, 'layer_norms': 1, 'noise': 0.0023949281623226386, 'disable_att': 'disabled'}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:56:22,902]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 16:59:48,319]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:03:57,709]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:09:15,828]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 45.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:14:05,343]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:18:04,986]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:24:20,066]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:32:06,619]\u001b[0m Trial 36 finished with value: 1.0246140956878662 and parameters: {'neurons0': 92, 'dropout': 0.8792645160982993, 'layers1': 0, 'layers2': 1, 'neurons2': 1458, 'layer_norms': 1, 'noise': 0.0001867915462087677, 'disable_att': 'enabled', 'num_heads': 140}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:36:18,496]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:40:10,374]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 42.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:44:40,359]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:48:51,440]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:54:48,682]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 17:59:18,306]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:08:01,418]\u001b[0m Trial 43 finished with value: 0.8500405550003052 and parameters: {'neurons0': 47, 'dropout': 0.26016683133532215, 'layers1': 2, 'layers2': 0, 'neurons1': 89, 'layer_norms': 0, 'noise': 0.0011006598927095223, 'disable_att': 'enabled', 'num_heads': 412}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:11:44,743]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:14:05,050]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 32.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:18:17,782]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:23:32,613]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:25:24,259]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 33.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:31:46,341]\u001b[0m Trial 49 finished with value: 0.7998166680335999 and parameters: {'neurons0': 70, 'dropout': 0.5804193278438133, 'layers1': 1, 'layers2': 0, 'neurons1': 178, 'layer_norms': 0, 'noise': 0.0006243961939391766, 'disable_att': 'enabled', 'num_heads': 105}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-14 18:35:15,086]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 66.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:41:45,285]\u001b[0m Trial 51 finished with value: 0.9023485779762268 and parameters: {'neurons0': 62, 'dropout': 0.7190833503746795, 'layers1': 1, 'layers2': 0, 'neurons1': 166, 'layer_norms': 0, 'noise': 0.0011785708436385493, 'disable_att': 'enabled', 'num_heads': 98}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:47:37,401]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:52:00,288]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 62.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:55:49,040]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 63.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 18:58:25,243]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:02:15,073]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:04:35,223]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:06:40,355]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 31.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:11:54,432]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:16:35,442]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 37.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:21:32,253]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:29:18,175]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:33:20,025]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 40.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:37:40,871]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:40:10,968]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:44:14,852]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:50:11,447]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:53:37,595]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 40.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 19:56:43,811]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:01:13,067]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:08:20,253]\u001b[0m Trial 71 finished with value: 0.8458704352378845 and parameters: {'neurons0': 63, 'dropout': 0.7198289363732007, 'layers1': 1, 'layers2': 0, 'neurons1': 162, 'layer_norms': 0, 'noise': 0.001161420897306839, 'disable_att': 'enabled', 'num_heads': 147}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:15:14,157]\u001b[0m Trial 72 finished with value: 1.0708799362182617 and parameters: {'neurons0': 62, 'dropout': 0.8067502905837209, 'layers1': 1, 'layers2': 0, 'neurons1': 97, 'layer_norms': 0, 'noise': 0.0017727641125401526, 'disable_att': 'enabled', 'num_heads': 128}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:22:37,226]\u001b[0m Trial 73 finished with value: 0.9304779171943665 and parameters: {'neurons0': 71, 'dropout': 0.7317998867125795, 'layers1': 1, 'layers2': 0, 'neurons1': 152, 'layer_norms': 0, 'noise': 0.0009174356033119384, 'disable_att': 'enabled', 'num_heads': 187}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:29:54,521]\u001b[0m Trial 74 finished with value: 0.8678215146064758 and parameters: {'neurons0': 58, 'dropout': 0.6658104092017759, 'layers1': 1, 'layers2': 0, 'neurons1': 229, 'layer_norms': 0, 'noise': 0.001481675791152428, 'disable_att': 'enabled', 'num_heads': 157}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:37:09,408]\u001b[0m Trial 75 finished with value: 0.8159520030021667 and parameters: {'neurons0': 58, 'dropout': 0.6586319642538765, 'layers1': 1, 'layers2': 0, 'neurons1': 216, 'layer_norms': 0, 'noise': 0.000539462765096427, 'disable_att': 'enabled', 'num_heads': 149}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:44:29,611]\u001b[0m Trial 76 finished with value: 0.776334822177887 and parameters: {'neurons0': 55, 'dropout': 0.6867361320958035, 'layers1': 1, 'layers2': 0, 'neurons1': 223, 'layer_norms': 0, 'noise': 0.0005808239323411038, 'disable_att': 'enabled', 'num_heads': 166}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:51:34,341]\u001b[0m Trial 77 finished with value: 0.973050594329834 and parameters: {'neurons0': 53, 'dropout': 0.7686433899437665, 'layers1': 1, 'layers2': 0, 'neurons1': 358, 'layer_norms': 0, 'noise': 0.0005443441525566999, 'disable_att': 'enabled', 'num_heads': 113}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 20:56:41,115]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:04:00,008]\u001b[0m Trial 79 finished with value: 0.8539027571678162 and parameters: {'neurons0': 56, 'dropout': 0.6837924524242773, 'layers1': 1, 'layers2': 0, 'neurons1': 191, 'layer_norms': 0, 'noise': 0.0004795754667792926, 'disable_att': 'enabled', 'num_heads': 150}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:08:11,027]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 86.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:15:21,760]\u001b[0m Trial 81 finished with value: 0.8391633033752441 and parameters: {'neurons0': 56, 'dropout': 0.6893008232546738, 'layers1': 1, 'layers2': 0, 'neurons1': 170, 'layer_norms': 0, 'noise': 0.0005086838223184583, 'disable_att': 'enabled', 'num_heads': 148}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:20:49,220]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 85.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:24:53,957]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:32:19,773]\u001b[0m Trial 84 finished with value: 1.002823829650879 and parameters: {'neurons0': 59, 'dropout': 0.8142809760647959, 'layers1': 1, 'layers2': 0, 'neurons1': 261, 'layer_norms': 0, 'noise': 0.0004208109373439723, 'disable_att': 'enabled', 'num_heads': 174}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:38:56,622]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:43:05,692]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:50:09,553]\u001b[0m Trial 87 finished with value: 1.0114402770996094 and parameters: {'neurons0': 68, 'dropout': 0.7549685246616333, 'layers1': 1, 'layers2': 0, 'neurons1': 44, 'layer_norms': 0, 'noise': 0.0002154088449599995, 'disable_att': 'enabled', 'num_heads': 124}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 21:55:47,725]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 84.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:00:49,043]\u001b[0m Trial 89 finished with value: 1.0095421075820923 and parameters: {'neurons0': 57, 'dropout': 0.840439511256876, 'layers1': 1, 'layers2': 0, 'neurons1': 105, 'layer_norms': 0, 'noise': 0.00017578402283735956, 'disable_att': 'disabled'}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:04:57,923]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 66.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:12:31,714]\u001b[0m Trial 91 finished with value: 0.8121843934059143 and parameters: {'neurons0': 48, 'dropout': 0.7062333185776161, 'layers1': 1, 'layers2': 0, 'neurons1': 195, 'layer_norms': 0, 'noise': 0.0004602725543612834, 'disable_att': 'enabled', 'num_heads': 158}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:16:57,014]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 58.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:20:15,404]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:24:41,693]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 56.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:28:57,194]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 56.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:34:41,739]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:38:00,347]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:45:35,123]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:50:46,242]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 22:57:07,175]\u001b[0m Trial 100 finished with value: 0.9078877568244934 and parameters: {'neurons0': 60, 'dropout': 0.5622400859154659, 'layers1': 1, 'layers2': 0, 'neurons1': 45, 'layer_norms': 0, 'noise': 0.001008850587933056, 'disable_att': 'enabled', 'num_heads': 80}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-14 23:03:10,017]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:07:25,389]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:14:49,023]\u001b[0m Trial 103 finished with value: 0.9641996026039124 and parameters: {'neurons0': 67, 'dropout': 0.7817851385670632, 'layers1': 1, 'layers2': 0, 'neurons1': 88, 'layer_norms': 0, 'noise': 0.0003232355739042078, 'disable_att': 'enabled', 'num_heads': 157}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:19:28,633]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 65.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:22:57,698]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 42.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:29:33,167]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 66.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:33:53,171]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:38:12,522]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 46.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:42:45,135]\u001b[0m Trial 109 finished with value: 0.9999175071716309 and parameters: {'neurons0': 40, 'dropout': 0.23589032278156555, 'layers1': 0, 'layers2': 0, 'layer_norms': 0, 'noise': 0.00029718440480027737, 'disable_att': 'disabled'}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-14 23:51:43,852]\u001b[0m Trial 110 finished with value: 0.8417689204216003 and parameters: {'neurons0': 55, 'dropout': 0.7371874335059416, 'layers1': 1, 'layers2': 1, 'neurons1': 68, 'neurons2': 273, 'layer_norms': 0, 'noise': 0.0004317586163970667, 'disable_att': 'enabled', 'num_heads': 279}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:00:41,914]\u001b[0m Trial 111 finished with value: 0.8410472273826599 and parameters: {'neurons0': 52, 'dropout': 0.7436967471514081, 'layers1': 1, 'layers2': 1, 'neurons1': 70, 'neurons2': 279, 'layer_norms': 0, 'noise': 0.0004335909336654126, 'disable_att': 'enabled', 'num_heads': 277}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:07:53,290]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:16:37,187]\u001b[0m Trial 113 finished with value: 0.9761336445808411 and parameters: {'neurons0': 46, 'dropout': 0.7680402853166385, 'layers1': 1, 'layers2': 1, 'neurons1': 29, 'neurons2': 463, 'layer_norms': 0, 'noise': 0.003403244353176402, 'disable_att': 'enabled', 'num_heads': 274}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:23:02,329]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 67.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:28:15,523]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 58.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:33:46,824]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:39:19,274]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 62.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:46:59,982]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:50:33,066]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 38.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 00:53:11,784]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:00:20,949]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:05:31,565]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 53.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:14:30,890]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:21:09,676]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 98.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:25:10,071]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:30:04,669]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:35:35,920]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 51.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:43:32,443]\u001b[0m Trial 128 finished with value: 0.847211480140686 and parameters: {'neurons0': 69, 'dropout': 0.6467846005773854, 'layers1': 2, 'layers2': 0, 'neurons1': 203, 'layer_norms': 0, 'noise': 0.002516573834463203, 'disable_att': 'enabled', 'num_heads': 151}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:47:35,988]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 43.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:54:40,252]\u001b[0m Trial 130 finished with value: 1.0971907377243042 and parameters: {'neurons0': 78, 'dropout': 0.8736708448660055, 'layers1': 2, 'layers2': 0, 'neurons1': 47, 'layer_norms': 0, 'noise': 0.0012732184998807338, 'disable_att': 'enabled', 'num_heads': 119}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 01:59:11,425]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:04:15,061]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:08:00,901]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:12:33,590]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 58.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:21:13,021]\u001b[0m Trial 135 finished with value: 0.8504438400268555 and parameters: {'neurons0': 52, 'dropout': 0.7102935605368428, 'layers1': 1, 'layers2': 0, 'neurons1': 269, 'layer_norms': 0, 'noise': 0.0005135733054153623, 'disable_att': 'enabled', 'num_heads': 221}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:26:22,382]\u001b[0m Trial 136 finished with value: 0.9664063453674316 and parameters: {'neurons0': 48, 'dropout': 0.7085727950948428, 'layers1': 1, 'layers2': 0, 'neurons1': 307, 'layer_norms': 0, 'noise': 0.0022327194613490373, 'disable_att': 'disabled'}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:30:28,327]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:37:23,626]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 67.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:41:26,085]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:48:04,115]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:52:40,708]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 02:59:07,010]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:04:10,482]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:12:51,598]\u001b[0m Trial 144 finished with value: 0.9479299187660217 and parameters: {'neurons0': 87, 'dropout': 0.7926477213188029, 'layers1': 1, 'layers2': 0, 'neurons1': 279, 'layer_norms': 0, 'noise': 0.0037597847730795894, 'disable_att': 'enabled', 'num_heads': 195}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:19:22,106]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:22:50,507]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 39.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:27:01,277]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:31:14,013]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:38:58,455]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:46:45,220]\u001b[0m Trial 150 finished with value: 0.9677066802978516 and parameters: {'neurons0': 53, 'dropout': 0.7330448806081017, 'layers1': 1, 'layers2': 0, 'neurons1': 223, 'layer_norms': 0, 'noise': 0.002593411226496204, 'disable_att': 'enabled', 'num_heads': 125}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:51:01,757]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 03:59:02,651]\u001b[0m Trial 152 finished with value: 0.8894088268280029 and parameters: {'neurons0': 57, 'dropout': 0.6926213990911866, 'layers1': 1, 'layers2': 0, 'neurons1': 227, 'layer_norms': 0, 'noise': 0.002058442898961928, 'disable_att': 'enabled', 'num_heads': 143}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:04:01,425]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 66.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:09:37,027]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 66.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:13:54,954]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 60.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:20:44,218]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:24:13,896]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 47.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:30:04,484]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 56.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-15 04:33:38,394]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:42:00,698]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:48:32,662]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 55.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:52:55,614]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 04:56:50,805]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 42.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:01:04,089]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:04:44,545]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 34.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:10:46,202]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 57.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:16:26,471]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 64.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:21:19,441]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:26:13,890]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 45.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:31:14,277]\u001b[0m Trial 170 finished with value: 1.0531175136566162 and parameters: {'neurons0': 55, 'dropout': 0.7155058081151544, 'layers1': 1, 'layers2': 0, 'neurons1': 66, 'layer_norms': 0, 'noise': 0.001363598455711067, 'disable_att': 'disabled'}. Best is trial 15 with value: 0.7515884637832642.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:37:38,020]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:41:38,497]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 49.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:46:21,232]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 43.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:50:52,524]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 05:56:15,203]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 61.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 06:03:40,097]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 06:09:38,338]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 54.\u001b[0m\n",
      "\u001b[32m[I 2022-02-15 06:14:18,322]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 39.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e88016565846>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                             pruner=optuna.pruners.PatientPruner(optuna.pruners.HyperbandPruner(\n\u001b[0;32m      3\u001b[0m         min_resource=1, max_resource=max_epochs, reduction_factor=3), patience=25))\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensorBoardCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logs4/optuna/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-3d7656ac4a3b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mcooldown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     )])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    851\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2849\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3631\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3632\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m    790\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;31m# Collect metrics to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \"\"\"\n\u001b[0;32m    520\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 521\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    452\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1371\u001b[0m       \u001b[0m_ShapesFullySpecifiedAndEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001b[1;32m-> 1373\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" vs. \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6230\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6231\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 6232\u001b[1;33m         _ctx, \"Mul\", name, x, y)\n\u001b[0m\u001b[0;32m   6233\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            pruner=optuna.pruners.PatientPruner(optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=max_epochs, reduction_factor=3), patience=25))\n",
    "study.optimize(objective, callbacks=[TensorBoardCallback('logs4/optuna/','val_loss')])\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newest submission - HPO enabled attention!\n",
    "\n",
    "https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions/173841\n",
    "\n",
    "best is trial 15\n",
    "{'neurons0': 50, 'dropout': 0.46806609816933387, 'layers1': 1, 'layers2': 0, 'neurons1': 23, 'layer_norms': 0, 'noise': 0.0015606054217948873, 'disable_att': 'enabled', 'num_heads': 417}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 7s 340ms/step - loss: 1.0384 - mae: 0.4231 - mse: 0.2094 - accuracy: 0.4176 - my_f1: 0.3708 - my_acc: 0.4211 - val_loss: 0.9322 - val_mae: 0.3820 - val_mse: 0.1876 - val_accuracy: 0.6220 - val_my_f1: 0.5632 - val_my_acc: 0.6225\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 6s 314ms/step - loss: 0.8860 - mae: 0.3618 - mse: 0.1779 - accuracy: 0.6152 - my_f1: 0.6091 - my_acc: 0.6173 - val_loss: 0.7506 - val_mae: 0.3136 - val_mse: 0.1478 - val_accuracy: 0.6945 - val_my_f1: 0.6737 - val_my_acc: 0.6950\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.7741 - mae: 0.3145 - mse: 0.1559 - accuracy: 0.6512 - my_f1: 0.6336 - my_acc: 0.6490 - val_loss: 0.6551 - val_mae: 0.2874 - val_mse: 0.1294 - val_accuracy: 0.7200 - val_my_f1: 0.7076 - val_my_acc: 0.7201\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.7221 - mae: 0.2916 - mse: 0.1455 - accuracy: 0.6830 - my_f1: 0.6752 - my_acc: 0.6830 - val_loss: 0.6150 - val_mae: 0.2760 - val_mse: 0.1227 - val_accuracy: 0.7440 - val_my_f1: 0.7420 - val_my_acc: 0.7445\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.6716 - mae: 0.2781 - mse: 0.1359 - accuracy: 0.7044 - my_f1: 0.6970 - my_acc: 0.7043 - val_loss: 0.5660 - val_mae: 0.2440 - val_mse: 0.1146 - val_accuracy: 0.7475 - val_my_f1: 0.7445 - val_my_acc: 0.7471\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 6s 326ms/step - loss: 0.6405 - mae: 0.2620 - mse: 0.1301 - accuracy: 0.7132 - my_f1: 0.7115 - my_acc: 0.7146 - val_loss: 0.6201 - val_mae: 0.2548 - val_mse: 0.1273 - val_accuracy: 0.7130 - val_my_f1: 0.6964 - val_my_acc: 0.7129\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 0.6309 - mae: 0.2590 - mse: 0.1282 - accuracy: 0.7126 - my_f1: 0.7077 - my_acc: 0.7136 - val_loss: 0.5668 - val_mae: 0.2350 - val_mse: 0.1165 - val_accuracy: 0.7445 - val_my_f1: 0.7479 - val_my_acc: 0.7442\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.6057 - mae: 0.2449 - mse: 0.1224 - accuracy: 0.7282 - my_f1: 0.7253 - my_acc: 0.7291 - val_loss: 0.5406 - val_mae: 0.2302 - val_mse: 0.1106 - val_accuracy: 0.7520 - val_my_f1: 0.7382 - val_my_acc: 0.7518\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 6s 320ms/step - loss: 0.5812 - mae: 0.2377 - mse: 0.1170 - accuracy: 0.7476 - my_f1: 0.7436 - my_acc: 0.7478 - val_loss: 0.5299 - val_mae: 0.2254 - val_mse: 0.1082 - val_accuracy: 0.7625 - val_my_f1: 0.7638 - val_my_acc: 0.7621\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.5890 - mae: 0.2402 - mse: 0.1193 - accuracy: 0.7352 - my_f1: 0.7320 - my_acc: 0.7357 - val_loss: 0.5477 - val_mae: 0.2316 - val_mse: 0.1124 - val_accuracy: 0.7425 - val_my_f1: 0.7176 - val_my_acc: 0.7419\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.5762 - mae: 0.2354 - mse: 0.1163 - accuracy: 0.7472 - my_f1: 0.7414 - my_acc: 0.7462 - val_loss: 0.5173 - val_mae: 0.2130 - val_mse: 0.1059 - val_accuracy: 0.7670 - val_my_f1: 0.7627 - val_my_acc: 0.7668\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 0.5665 - mae: 0.2322 - mse: 0.1142 - accuracy: 0.7524 - my_f1: 0.7482 - my_acc: 0.7539 - val_loss: 0.5374 - val_mae: 0.2093 - val_mse: 0.1095 - val_accuracy: 0.7625 - val_my_f1: 0.7553 - val_my_acc: 0.7621\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 6s 296ms/step - loss: 0.5580 - mae: 0.2249 - mse: 0.1126 - accuracy: 0.7658 - my_f1: 0.7614 - my_acc: 0.7642 - val_loss: 0.5290 - val_mae: 0.2236 - val_mse: 0.1081 - val_accuracy: 0.7535 - val_my_f1: 0.7446 - val_my_acc: 0.7531\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 6s 297ms/step - loss: 0.5645 - mae: 0.2304 - mse: 0.1141 - accuracy: 0.7584 - my_f1: 0.7525 - my_acc: 0.7579 - val_loss: 0.5594 - val_mae: 0.2197 - val_mse: 0.1130 - val_accuracy: 0.7600 - val_my_f1: 0.7634 - val_my_acc: 0.7601\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.5801 - mae: 0.2373 - mse: 0.1180 - accuracy: 0.7414 - my_f1: 0.7365 - my_acc: 0.7414 - val_loss: 0.5274 - val_mae: 0.2124 - val_mse: 0.1073 - val_accuracy: 0.7670 - val_my_f1: 0.7661 - val_my_acc: 0.7669\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 6s 295ms/step - loss: 0.5311 - mae: 0.2197 - mse: 0.1060 - accuracy: 0.7818 - my_f1: 0.7801 - my_acc: 0.7831 - val_loss: 0.5283 - val_mae: 0.1948 - val_mse: 0.1067 - val_accuracy: 0.7720 - val_my_f1: 0.7713 - val_my_acc: 0.7716\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.5278 - mae: 0.2124 - mse: 0.1055 - accuracy: 0.7782 - my_f1: 0.7753 - my_acc: 0.7782 - val_loss: 0.5734 - val_mae: 0.2135 - val_mse: 0.1136 - val_accuracy: 0.7620 - val_my_f1: 0.7637 - val_my_acc: 0.7623\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.5206 - mae: 0.2099 - mse: 0.1031 - accuracy: 0.7934 - my_f1: 0.7894 - my_acc: 0.7922 - val_loss: 0.5041 - val_mae: 0.2002 - val_mse: 0.1036 - val_accuracy: 0.7690 - val_my_f1: 0.7632 - val_my_acc: 0.7679\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 6s 295ms/step - loss: 0.5051 - mae: 0.2058 - mse: 0.1009 - accuracy: 0.7982 - my_f1: 0.7941 - my_acc: 0.7981 - val_loss: 0.5077 - val_mae: 0.2010 - val_mse: 0.1037 - val_accuracy: 0.7770 - val_my_f1: 0.7763 - val_my_acc: 0.7763\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.5086 - mae: 0.2083 - mse: 0.1022 - accuracy: 0.7912 - my_f1: 0.7877 - my_acc: 0.7914 - val_loss: 0.5106 - val_mae: 0.1940 - val_mse: 0.1043 - val_accuracy: 0.7765 - val_my_f1: 0.7779 - val_my_acc: 0.7764\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.4998 - mae: 0.2036 - mse: 0.0999 - accuracy: 0.7994 - my_f1: 0.7954 - my_acc: 0.7991 - val_loss: 0.5141 - val_mae: 0.2119 - val_mse: 0.1056 - val_accuracy: 0.7645 - val_my_f1: 0.7654 - val_my_acc: 0.7639\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.4857 - mae: 0.2009 - mse: 0.0969 - accuracy: 0.7994 - my_f1: 0.7953 - my_acc: 0.7982 - val_loss: 0.5009 - val_mae: 0.1916 - val_mse: 0.1025 - val_accuracy: 0.7835 - val_my_f1: 0.7839 - val_my_acc: 0.7833\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.4845 - mae: 0.1942 - mse: 0.0962 - accuracy: 0.8034 - my_f1: 0.8005 - my_acc: 0.8028 - val_loss: 0.4983 - val_mae: 0.1971 - val_mse: 0.1017 - val_accuracy: 0.7830 - val_my_f1: 0.7825 - val_my_acc: 0.7825\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4676 - mae: 0.1931 - mse: 0.0929 - accuracy: 0.8126 - my_f1: 0.8087 - my_acc: 0.8118 - val_loss: 0.5021 - val_mae: 0.1890 - val_mse: 0.1030 - val_accuracy: 0.7755 - val_my_f1: 0.7728 - val_my_acc: 0.7749\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4690 - mae: 0.1910 - mse: 0.0931 - accuracy: 0.8082 - my_f1: 0.8069 - my_acc: 0.8091 - val_loss: 0.4990 - val_mae: 0.1926 - val_mse: 0.1020 - val_accuracy: 0.7805 - val_my_f1: 0.7791 - val_my_acc: 0.7800\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4787 - mae: 0.1928 - mse: 0.0950 - accuracy: 0.8092 - my_f1: 0.8068 - my_acc: 0.8099 - val_loss: 0.5021 - val_mae: 0.1929 - val_mse: 0.1029 - val_accuracy: 0.7775 - val_my_f1: 0.7775 - val_my_acc: 0.7772\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4586 - mae: 0.1886 - mse: 0.0912 - accuracy: 0.8174 - my_f1: 0.8150 - my_acc: 0.8179 - val_loss: 0.5091 - val_mae: 0.1892 - val_mse: 0.1033 - val_accuracy: 0.7795 - val_my_f1: 0.7785 - val_my_acc: 0.7790\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4657 - mae: 0.1875 - mse: 0.0915 - accuracy: 0.8200 - my_f1: 0.8172 - my_acc: 0.8197 - val_loss: 0.4976 - val_mae: 0.1910 - val_mse: 0.1016 - val_accuracy: 0.7860 - val_my_f1: 0.7857 - val_my_acc: 0.7855\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 6s 297ms/step - loss: 0.4482 - mae: 0.1824 - mse: 0.0891 - accuracy: 0.8176 - my_f1: 0.8147 - my_acc: 0.8165 - val_loss: 0.5074 - val_mae: 0.1823 - val_mse: 0.1029 - val_accuracy: 0.7805 - val_my_f1: 0.7797 - val_my_acc: 0.7802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "20/20 [==============================] - 6s 297ms/step - loss: 0.4548 - mae: 0.1862 - mse: 0.0902 - accuracy: 0.8146 - my_f1: 0.8118 - my_acc: 0.8150 - val_loss: 0.4970 - val_mae: 0.1878 - val_mse: 0.1014 - val_accuracy: 0.7785 - val_my_f1: 0.7745 - val_my_acc: 0.7779\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4537 - mae: 0.1834 - mse: 0.0893 - accuracy: 0.8184 - my_f1: 0.8159 - my_acc: 0.8183 - val_loss: 0.4994 - val_mae: 0.1915 - val_mse: 0.1019 - val_accuracy: 0.7845 - val_my_f1: 0.7849 - val_my_acc: 0.7841\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4461 - mae: 0.1832 - mse: 0.0892 - accuracy: 0.8168 - my_f1: 0.8141 - my_acc: 0.8164 - val_loss: 0.5351 - val_mae: 0.1869 - val_mse: 0.1070 - val_accuracy: 0.7730 - val_my_f1: 0.7739 - val_my_acc: 0.7725\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 6s 312ms/step - loss: 0.4541 - mae: 0.1855 - mse: 0.0900 - accuracy: 0.8212 - my_f1: 0.8198 - my_acc: 0.8219 - val_loss: 0.5006 - val_mae: 0.1865 - val_mse: 0.1025 - val_accuracy: 0.7765 - val_my_f1: 0.7688 - val_my_acc: 0.7758\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 7s 334ms/step - loss: 0.4487 - mae: 0.1799 - mse: 0.0886 - accuracy: 0.8234 - my_f1: 0.8201 - my_acc: 0.8232 - val_loss: 0.5146 - val_mae: 0.1900 - val_mse: 0.1053 - val_accuracy: 0.7675 - val_my_f1: 0.7693 - val_my_acc: 0.7672\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 0.4428 - mae: 0.1770 - mse: 0.0874 - accuracy: 0.8192 - my_f1: 0.8149 - my_acc: 0.8171 - val_loss: 0.5003 - val_mae: 0.1839 - val_mse: 0.1022 - val_accuracy: 0.7795 - val_my_f1: 0.7761 - val_my_acc: 0.7790\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 6s 327ms/step - loss: 0.4447 - mae: 0.1854 - mse: 0.0889 - accuracy: 0.8196 - my_f1: 0.8174 - my_acc: 0.8204 - val_loss: 0.5038 - val_mae: 0.1866 - val_mse: 0.1024 - val_accuracy: 0.7815 - val_my_f1: 0.7808 - val_my_acc: 0.7809\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 6s 320ms/step - loss: 0.4388 - mae: 0.1779 - mse: 0.0873 - accuracy: 0.8158 - my_f1: 0.8136 - my_acc: 0.8158 - val_loss: 0.5054 - val_mae: 0.1827 - val_mse: 0.1028 - val_accuracy: 0.7810 - val_my_f1: 0.7777 - val_my_acc: 0.7804\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 6s 325ms/step - loss: 0.4468 - mae: 0.1841 - mse: 0.0892 - accuracy: 0.8166 - my_f1: 0.8157 - my_acc: 0.8183 - val_loss: 0.5022 - val_mae: 0.1868 - val_mse: 0.1020 - val_accuracy: 0.7875 - val_my_f1: 0.7860 - val_my_acc: 0.7867\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 7s 331ms/step - loss: 0.4385 - mae: 0.1739 - mse: 0.0863 - accuracy: 0.8228 - my_f1: 0.8210 - my_acc: 0.8226 - val_loss: 0.5015 - val_mae: 0.1865 - val_mse: 0.1019 - val_accuracy: 0.7815 - val_my_f1: 0.7774 - val_my_acc: 0.7809\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 7s 335ms/step - loss: 0.4487 - mae: 0.1814 - mse: 0.0883 - accuracy: 0.8216 - my_f1: 0.8173 - my_acc: 0.8206 - val_loss: 0.5111 - val_mae: 0.1919 - val_mse: 0.1035 - val_accuracy: 0.7790 - val_my_f1: 0.7773 - val_my_acc: 0.7782\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 7s 338ms/step - loss: 0.4410 - mae: 0.1813 - mse: 0.0870 - accuracy: 0.8202 - my_f1: 0.8165 - my_acc: 0.8187 - val_loss: 0.5077 - val_mae: 0.1819 - val_mse: 0.1033 - val_accuracy: 0.7845 - val_my_f1: 0.7819 - val_my_acc: 0.7840\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 7s 334ms/step - loss: 0.4285 - mae: 0.1724 - mse: 0.0844 - accuracy: 0.8288 - my_f1: 0.8270 - my_acc: 0.8290 - val_loss: 0.5035 - val_mae: 0.1835 - val_mse: 0.1022 - val_accuracy: 0.7815 - val_my_f1: 0.7797 - val_my_acc: 0.7810\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 6s 325ms/step - loss: 0.4264 - mae: 0.1744 - mse: 0.0846 - accuracy: 0.8280 - my_f1: 0.8260 - my_acc: 0.8279 - val_loss: 0.5043 - val_mae: 0.1835 - val_mse: 0.1022 - val_accuracy: 0.7830 - val_my_f1: 0.7811 - val_my_acc: 0.7825\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 6s 323ms/step - loss: 0.4291 - mae: 0.1737 - mse: 0.0848 - accuracy: 0.8306 - my_f1: 0.8303 - my_acc: 0.8322 - val_loss: 0.5063 - val_mae: 0.1815 - val_mse: 0.1025 - val_accuracy: 0.7850 - val_my_f1: 0.7825 - val_my_acc: 0.7845\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 0.4261 - mae: 0.1721 - mse: 0.0840 - accuracy: 0.8286 - my_f1: 0.8270 - my_acc: 0.8295 - val_loss: 0.5076 - val_mae: 0.1828 - val_mse: 0.1027 - val_accuracy: 0.7815 - val_my_f1: 0.7805 - val_my_acc: 0.7809\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.4213 - mae: 0.1723 - mse: 0.0832 - accuracy: 0.8362 - my_f1: 0.8339 - my_acc: 0.8357 - val_loss: 0.5067 - val_mae: 0.1850 - val_mse: 0.1026 - val_accuracy: 0.7815 - val_my_f1: 0.7812 - val_my_acc: 0.7806\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4227 - mae: 0.1731 - mse: 0.0833 - accuracy: 0.8292 - my_f1: 0.8289 - my_acc: 0.8306 - val_loss: 0.5148 - val_mae: 0.1839 - val_mse: 0.1033 - val_accuracy: 0.7810 - val_my_f1: 0.7794 - val_my_acc: 0.7804\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.4213 - mae: 0.1726 - mse: 0.0836 - accuracy: 0.8308 - my_f1: 0.8273 - my_acc: 0.8293 - val_loss: 0.5100 - val_mae: 0.1821 - val_mse: 0.1027 - val_accuracy: 0.7855 - val_my_f1: 0.7837 - val_my_acc: 0.7849\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.4149 - mae: 0.1694 - mse: 0.0822 - accuracy: 0.8318 - my_f1: 0.8294 - my_acc: 0.8320 - val_loss: 0.5121 - val_mae: 0.1809 - val_mse: 0.1029 - val_accuracy: 0.7835 - val_my_f1: 0.7820 - val_my_acc: 0.7828\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4206 - mae: 0.1704 - mse: 0.0833 - accuracy: 0.8298 - my_f1: 0.8289 - my_acc: 0.8305 - val_loss: 0.5069 - val_mae: 0.1836 - val_mse: 0.1023 - val_accuracy: 0.7835 - val_my_f1: 0.7818 - val_my_acc: 0.7829\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4147 - mae: 0.1735 - mse: 0.0818 - accuracy: 0.8354 - my_f1: 0.8347 - my_acc: 0.8363 - val_loss: 0.5127 - val_mae: 0.1824 - val_mse: 0.1030 - val_accuracy: 0.7820 - val_my_f1: 0.7802 - val_my_acc: 0.7815\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 6s 304ms/step - loss: 0.4191 - mae: 0.1691 - mse: 0.0831 - accuracy: 0.8268 - my_f1: 0.8247 - my_acc: 0.8266 - val_loss: 0.5130 - val_mae: 0.1780 - val_mse: 0.1031 - val_accuracy: 0.7830 - val_my_f1: 0.7793 - val_my_acc: 0.7827\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 0.4151 - mae: 0.1705 - mse: 0.0822 - accuracy: 0.8366 - my_f1: 0.8342 - my_acc: 0.8365 - val_loss: 0.5046 - val_mae: 0.1825 - val_mse: 0.1021 - val_accuracy: 0.7860 - val_my_f1: 0.7845 - val_my_acc: 0.7854\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4163 - mae: 0.1706 - mse: 0.0825 - accuracy: 0.8280 - my_f1: 0.8264 - my_acc: 0.8282 - val_loss: 0.5066 - val_mae: 0.1825 - val_mse: 0.1026 - val_accuracy: 0.7860 - val_my_f1: 0.7856 - val_my_acc: 0.7855\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.4126 - mae: 0.1686 - mse: 0.0822 - accuracy: 0.8312 - my_f1: 0.8279 - my_acc: 0.8296 - val_loss: 0.5118 - val_mae: 0.1803 - val_mse: 0.1034 - val_accuracy: 0.7825 - val_my_f1: 0.7788 - val_my_acc: 0.7819\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4095 - mae: 0.1686 - mse: 0.0810 - accuracy: 0.8330 - my_f1: 0.8312 - my_acc: 0.8330 - val_loss: 0.5102 - val_mae: 0.1799 - val_mse: 0.1026 - val_accuracy: 0.7830 - val_my_f1: 0.7806 - val_my_acc: 0.7826\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4135 - mae: 0.1697 - mse: 0.0817 - accuracy: 0.8320 - my_f1: 0.8301 - my_acc: 0.8321 - val_loss: 0.5091 - val_mae: 0.1811 - val_mse: 0.1027 - val_accuracy: 0.7865 - val_my_f1: 0.7851 - val_my_acc: 0.7859\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4103 - mae: 0.1678 - mse: 0.0815 - accuracy: 0.8294 - my_f1: 0.8269 - my_acc: 0.8287 - val_loss: 0.5347 - val_mae: 0.1822 - val_mse: 0.1060 - val_accuracy: 0.7805 - val_my_f1: 0.7818 - val_my_acc: 0.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4195 - mae: 0.1698 - mse: 0.0828 - accuracy: 0.8314 - my_f1: 0.8294 - my_acc: 0.8314 - val_loss: 0.5141 - val_mae: 0.1853 - val_mse: 0.1034 - val_accuracy: 0.7805 - val_my_f1: 0.7808 - val_my_acc: 0.7798\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 6s 292ms/step - loss: 0.4072 - mae: 0.1687 - mse: 0.0811 - accuracy: 0.8332 - my_f1: 0.8317 - my_acc: 0.8333 - val_loss: 0.5160 - val_mae: 0.1803 - val_mse: 0.1034 - val_accuracy: 0.7810 - val_my_f1: 0.7794 - val_my_acc: 0.7802\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.4142 - mae: 0.1676 - mse: 0.0819 - accuracy: 0.8342 - my_f1: 0.8310 - my_acc: 0.8329 - val_loss: 0.5074 - val_mae: 0.1837 - val_mse: 0.1026 - val_accuracy: 0.7860 - val_my_f1: 0.7848 - val_my_acc: 0.7854\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 6s 314ms/step - loss: 0.4064 - mae: 0.1688 - mse: 0.0799 - accuracy: 0.8372 - my_f1: 0.8357 - my_acc: 0.8371 - val_loss: 0.5119 - val_mae: 0.1816 - val_mse: 0.1029 - val_accuracy: 0.7840 - val_my_f1: 0.7828 - val_my_acc: 0.7834\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 6s 304ms/step - loss: 0.4095 - mae: 0.1682 - mse: 0.0813 - accuracy: 0.8316 - my_f1: 0.8285 - my_acc: 0.8304 - val_loss: 0.5122 - val_mae: 0.1816 - val_mse: 0.1031 - val_accuracy: 0.7840 - val_my_f1: 0.7831 - val_my_acc: 0.7833\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4071 - mae: 0.1686 - mse: 0.0809 - accuracy: 0.8356 - my_f1: 0.8334 - my_acc: 0.8350 - val_loss: 0.5131 - val_mae: 0.1809 - val_mse: 0.1031 - val_accuracy: 0.7835 - val_my_f1: 0.7821 - val_my_acc: 0.7828\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.4055 - mae: 0.1661 - mse: 0.0802 - accuracy: 0.8386 - my_f1: 0.8365 - my_acc: 0.8381 - val_loss: 0.5138 - val_mae: 0.1809 - val_mse: 0.1031 - val_accuracy: 0.7840 - val_my_f1: 0.7830 - val_my_acc: 0.7833\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.4076 - mae: 0.1659 - mse: 0.0798 - accuracy: 0.8382 - my_f1: 0.8357 - my_acc: 0.8373 - val_loss: 0.5144 - val_mae: 0.1815 - val_mse: 0.1032 - val_accuracy: 0.7825 - val_my_f1: 0.7818 - val_my_acc: 0.7819\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4074 - mae: 0.1671 - mse: 0.0809 - accuracy: 0.8398 - my_f1: 0.8382 - my_acc: 0.8401 - val_loss: 0.5148 - val_mae: 0.1816 - val_mse: 0.1033 - val_accuracy: 0.7840 - val_my_f1: 0.7834 - val_my_acc: 0.7831\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.4048 - mae: 0.1662 - mse: 0.0803 - accuracy: 0.8354 - my_f1: 0.8331 - my_acc: 0.8348 - val_loss: 0.5153 - val_mae: 0.1814 - val_mse: 0.1033 - val_accuracy: 0.7840 - val_my_f1: 0.7833 - val_my_acc: 0.7831\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.4101 - mae: 0.1684 - mse: 0.0816 - accuracy: 0.8326 - my_f1: 0.8301 - my_acc: 0.8314 - val_loss: 0.5137 - val_mae: 0.1815 - val_mse: 0.1032 - val_accuracy: 0.7850 - val_my_f1: 0.7847 - val_my_acc: 0.7844\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 6s 304ms/step - loss: 0.4050 - mae: 0.1662 - mse: 0.0803 - accuracy: 0.8330 - my_f1: 0.8300 - my_acc: 0.8323 - val_loss: 0.5139 - val_mae: 0.1807 - val_mse: 0.1031 - val_accuracy: 0.7835 - val_my_f1: 0.7826 - val_my_acc: 0.7828\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 7s 323ms/step - loss: 0.3994 - mae: 0.1666 - mse: 0.0796 - accuracy: 0.8354 - my_f1: 0.8353 - my_acc: 0.8367 - val_loss: 0.5141 - val_mae: 0.1806 - val_mse: 0.1032 - val_accuracy: 0.7850 - val_my_f1: 0.7843 - val_my_acc: 0.7844\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.4059 - mae: 0.1661 - mse: 0.0802 - accuracy: 0.8352 - my_f1: 0.8347 - my_acc: 0.8363 - val_loss: 0.5176 - val_mae: 0.1800 - val_mse: 0.1035 - val_accuracy: 0.7835 - val_my_f1: 0.7830 - val_my_acc: 0.7827\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 0.4029 - mae: 0.1638 - mse: 0.0792 - accuracy: 0.8374 - my_f1: 0.8365 - my_acc: 0.8379 - val_loss: 0.5156 - val_mae: 0.1797 - val_mse: 0.1033 - val_accuracy: 0.7840 - val_my_f1: 0.7828 - val_my_acc: 0.7833\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.4051 - mae: 0.1659 - mse: 0.0804 - accuracy: 0.8356 - my_f1: 0.8355 - my_acc: 0.8369 - val_loss: 0.5129 - val_mae: 0.1802 - val_mse: 0.1030 - val_accuracy: 0.7845 - val_my_f1: 0.7828 - val_my_acc: 0.7839\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.4113 - mae: 0.1659 - mse: 0.0811 - accuracy: 0.8332 - my_f1: 0.8319 - my_acc: 0.8340 - val_loss: 0.5132 - val_mae: 0.1816 - val_mse: 0.1032 - val_accuracy: 0.7845 - val_my_f1: 0.7840 - val_my_acc: 0.7839\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.4045 - mae: 0.1663 - mse: 0.0803 - accuracy: 0.8370 - my_f1: 0.8352 - my_acc: 0.8367 - val_loss: 0.5130 - val_mae: 0.1807 - val_mse: 0.1031 - val_accuracy: 0.7835 - val_my_f1: 0.7822 - val_my_acc: 0.7831\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4011 - mae: 0.1654 - mse: 0.0798 - accuracy: 0.8400 - my_f1: 0.8383 - my_acc: 0.8398 - val_loss: 0.5140 - val_mae: 0.1808 - val_mse: 0.1032 - val_accuracy: 0.7835 - val_my_f1: 0.7823 - val_my_acc: 0.7828\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 6s 304ms/step - loss: 0.3969 - mae: 0.1643 - mse: 0.0792 - accuracy: 0.8356 - my_f1: 0.8342 - my_acc: 0.8357 - val_loss: 0.5211 - val_mae: 0.1791 - val_mse: 0.1038 - val_accuracy: 0.7835 - val_my_f1: 0.7819 - val_my_acc: 0.7828\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4013 - mae: 0.1647 - mse: 0.0793 - accuracy: 0.8362 - my_f1: 0.8361 - my_acc: 0.8381 - val_loss: 0.5178 - val_mae: 0.1806 - val_mse: 0.1036 - val_accuracy: 0.7835 - val_my_f1: 0.7829 - val_my_acc: 0.7828\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.4009 - mae: 0.1651 - mse: 0.0790 - accuracy: 0.8426 - my_f1: 0.8420 - my_acc: 0.8434 - val_loss: 0.5173 - val_mae: 0.1796 - val_mse: 0.1036 - val_accuracy: 0.7820 - val_my_f1: 0.7809 - val_my_acc: 0.7814\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.4038 - mae: 0.1641 - mse: 0.0799 - accuracy: 0.8332 - my_f1: 0.8308 - my_acc: 0.8326 - val_loss: 0.5218 - val_mae: 0.1803 - val_mse: 0.1042 - val_accuracy: 0.7855 - val_my_f1: 0.7858 - val_my_acc: 0.7849\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.3980 - mae: 0.1642 - mse: 0.0788 - accuracy: 0.8410 - my_f1: 0.8402 - my_acc: 0.8409 - val_loss: 0.5220 - val_mae: 0.1799 - val_mse: 0.1041 - val_accuracy: 0.7850 - val_my_f1: 0.7848 - val_my_acc: 0.7843\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 6s 304ms/step - loss: 0.4080 - mae: 0.1660 - mse: 0.0806 - accuracy: 0.8356 - my_f1: 0.8337 - my_acc: 0.8351 - val_loss: 0.5189 - val_mae: 0.1792 - val_mse: 0.1038 - val_accuracy: 0.7840 - val_my_f1: 0.7832 - val_my_acc: 0.7834\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.4082 - mae: 0.1658 - mse: 0.0806 - accuracy: 0.8334 - my_f1: 0.8336 - my_acc: 0.8351 - val_loss: 0.5182 - val_mae: 0.1797 - val_mse: 0.1036 - val_accuracy: 0.7835 - val_my_f1: 0.7825 - val_my_acc: 0.7827\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.4032 - mae: 0.1650 - mse: 0.0800 - accuracy: 0.8354 - my_f1: 0.8348 - my_acc: 0.8362 - val_loss: 0.5182 - val_mae: 0.1802 - val_mse: 0.1035 - val_accuracy: 0.7830 - val_my_f1: 0.7821 - val_my_acc: 0.7823\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 7s 334ms/step - loss: 0.4033 - mae: 0.1650 - mse: 0.0797 - accuracy: 0.8394 - my_f1: 0.8369 - my_acc: 0.8389 - val_loss: 0.5175 - val_mae: 0.1802 - val_mse: 0.1035 - val_accuracy: 0.7840 - val_my_f1: 0.7830 - val_my_acc: 0.7832\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 6s 301ms/step - loss: 0.4022 - mae: 0.1665 - mse: 0.0800 - accuracy: 0.8348 - my_f1: 0.8330 - my_acc: 0.8349 - val_loss: 0.5171 - val_mae: 0.1803 - val_mse: 0.1035 - val_accuracy: 0.7835 - val_my_f1: 0.7825 - val_my_acc: 0.7827\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.3979 - mae: 0.1627 - mse: 0.0784 - accuracy: 0.8392 - my_f1: 0.8383 - my_acc: 0.8395 - val_loss: 0.5177 - val_mae: 0.1800 - val_mse: 0.1035 - val_accuracy: 0.7835 - val_my_f1: 0.7825 - val_my_acc: 0.7828\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.93215012550354,\n",
       "  0.7506144642829895,\n",
       "  0.6550961136817932,\n",
       "  0.6149912476539612,\n",
       "  0.5660004019737244,\n",
       "  0.6200670003890991,\n",
       "  0.5667563080787659,\n",
       "  0.5406185984611511,\n",
       "  0.5298784971237183,\n",
       "  0.5477474331855774,\n",
       "  0.5173028111457825,\n",
       "  0.537368893623352,\n",
       "  0.5290323495864868,\n",
       "  0.5593916773796082,\n",
       "  0.5274007320404053,\n",
       "  0.5282717347145081,\n",
       "  0.5734229683876038,\n",
       "  0.5041447281837463,\n",
       "  0.5077146887779236,\n",
       "  0.5105924010276794,\n",
       "  0.5141319036483765,\n",
       "  0.5009227395057678,\n",
       "  0.498345285654068,\n",
       "  0.5021173357963562,\n",
       "  0.4989565908908844,\n",
       "  0.5020665526390076,\n",
       "  0.5090712308883667,\n",
       "  0.49760156869888306,\n",
       "  0.5073554515838623,\n",
       "  0.4969843327999115,\n",
       "  0.4994041919708252,\n",
       "  0.5351067185401917,\n",
       "  0.5006476640701294,\n",
       "  0.5146024823188782,\n",
       "  0.5003334879875183,\n",
       "  0.5038415193557739,\n",
       "  0.505352258682251,\n",
       "  0.5022417902946472,\n",
       "  0.5014651417732239,\n",
       "  0.5110684633255005,\n",
       "  0.5076795816421509,\n",
       "  0.503508448600769,\n",
       "  0.50431889295578,\n",
       "  0.5063230395317078,\n",
       "  0.5075604915618896,\n",
       "  0.5066820383071899,\n",
       "  0.5147585272789001,\n",
       "  0.5100329518318176,\n",
       "  0.5121321082115173,\n",
       "  0.5068501830101013,\n",
       "  0.5126939415931702,\n",
       "  0.5129689574241638,\n",
       "  0.5045886039733887,\n",
       "  0.5065906047821045,\n",
       "  0.5118205547332764,\n",
       "  0.5102180242538452,\n",
       "  0.5090974569320679,\n",
       "  0.5346963405609131,\n",
       "  0.5141304731369019,\n",
       "  0.516045331954956,\n",
       "  0.5073544979095459,\n",
       "  0.5119008421897888,\n",
       "  0.5121898055076599,\n",
       "  0.5131430625915527,\n",
       "  0.51375812292099,\n",
       "  0.5144346356391907,\n",
       "  0.5148255228996277,\n",
       "  0.5153083205223083,\n",
       "  0.5137432813644409,\n",
       "  0.5139403343200684,\n",
       "  0.5140535831451416,\n",
       "  0.5176076292991638,\n",
       "  0.5155524015426636,\n",
       "  0.512941300868988,\n",
       "  0.5132262110710144,\n",
       "  0.5130143761634827,\n",
       "  0.5140359997749329,\n",
       "  0.5210979580879211,\n",
       "  0.5177580118179321,\n",
       "  0.5172846913337708,\n",
       "  0.5217795372009277,\n",
       "  0.5219936966896057,\n",
       "  0.5189111232757568,\n",
       "  0.5182347893714905,\n",
       "  0.5181889533996582,\n",
       "  0.5174967646598816,\n",
       "  0.5171175003051758,\n",
       "  0.5177128314971924],\n",
       " 0.93215012550354)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs=100\n",
    "neurons0 = 50\n",
    "lr = 1e-2 #trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True)\n",
    "dropout = 0.46806609816933387\n",
    "layers1 = 1\n",
    "layers2 = 0\n",
    "\n",
    "if layers1>0:\n",
    "    neurons1 = 23\n",
    "else:\n",
    "    neurons1=0\n",
    "\n",
    "if layers2>0:\n",
    "#     neurons2 = trial.suggest_int(\"neurons2\", 128, 2048, log=False)\n",
    "    pass\n",
    "else:\n",
    "    neurons2=0\n",
    "ln = 0\n",
    "batch_size = 256#trial.suggest_int(\"batch_size\", 8, 1024)\n",
    "noise = 0.0015606054217948873\n",
    "\n",
    "disable_att = 'enabled'\n",
    "if disable_att=='disabled':\n",
    "    num_heads=0\n",
    "else:\n",
    "    num_heads = 417\n",
    "\n",
    "model = getModel(neurons0=neurons0,\n",
    "                 neurons1=neurons1,\n",
    "                 neurons2=neurons2,\n",
    "                 layers1=layers1,\n",
    "                 layers2=layers2,\n",
    "                 dropout=dropout,\n",
    "                 lr=lr,\n",
    "                 ln=ln,\n",
    "                 noise=noise,\n",
    "                 num_heads=num_heads)\n",
    "\n",
    "history = model.fit(X/10.0,y,\n",
    "          validation_data=(X_val/10.0,y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          verbose=1,\n",
    "         callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir=\"logs4/optuna-best/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                        histogram_freq=1,\n",
    "                        write_graph=True,\n",
    "                        update_freq=\"epoch\"),\n",
    "\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                                monitor=\"val_my_f1\",\n",
    "                                patience=50,\n",
    "                                verbose=1,\n",
    "                                mode=\"max\",\n",
    "                                restore_best_weights=True,\n",
    "                            ),\n",
    "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.3,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-10,\n",
    "\n",
    ")])\n",
    "\n",
    "history.history['val_loss'], max(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score : 0.7866055237424707\n",
      "Accuracy Score : 0.7875\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val/10.0)\n",
    "# y_pred.shape\n",
    "print(f\"F1 Score : {f1_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1), average='weighted')}\")\n",
    "print(f\"Accuracy Score : {accuracy_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below is pretty ok\n",
    "\n",
    "https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions/173578\n",
    "\n",
    "F1 SCORE 0.795\n",
    "\n",
    "ACUCRACY SCORE 0.794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neurons0 = 1277\n",
    "neurons1 = 116\n",
    "neurons2 = 54\n",
    "lr = 1.6895e-7\n",
    "dropout = 0.75541\n",
    "layers1 = 2\n",
    "layers2 = 1\n",
    "ln = 0\n",
    "batch_size = 175\n",
    "noise = 0\n",
    "num_heads = 4\n",
    "num_atts = 0\n",
    "\n",
    "model = getModel(neurons0=neurons0,\n",
    "                 neurons1=neurons1,\n",
    "                 neurons2=neurons2,\n",
    "                 layers1=layers1,\n",
    "                 layers2=layers2,\n",
    "                 dropout=dropout,\n",
    "                 lr=lr,\n",
    "                 ln=ln,\n",
    "                 noise=noise,\n",
    "                 num_heads=num_heads,\n",
    "                 num_atts=num_atts)\n",
    "\n",
    "history = model.fit(X/10.0,y,\n",
    "          validation_data=(X_val/10.0,y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          verbose=1,\n",
    "         callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir=\"logs/optuna-att-12/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                        histogram_freq=1,\n",
    "                        write_graph=True,\n",
    "                        update_freq=\"epoch\"),\n",
    "\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                                monitor=\"val_my_f1\",\n",
    "                                patience=50,\n",
    "                                verbose=1,\n",
    "                                mode=\"max\",\n",
    "                                restore_best_weights=True,\n",
    "                            ),                        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_my_f1\",\n",
    "    factor=0.3,\n",
    "    patience=20,\n",
    "    verbose=0,\n",
    "    mode=\"max\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-10,\n",
    ")])\n",
    "    \n",
    "history.history['val_my_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val/10.0)\n",
    "# y_pred.shape\n",
    "print(f\"F1 Score : {f1_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1), average='weighted')}\")\n",
    "print(f\"Accuracy Score : {accuracy_score(tf.argmax(y_val,axis=1), tf.argmax(y_pred,axis=1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huber (trial 181) = sÅ‚abo\n",
    "https://www.aicrowd.com/challenges/ai-blitz-xiii/problems/sentiment-classification/submissions/173742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons0 = 16\n",
    "neurons1 = 174\n",
    "neurons2 = 828\n",
    "lr = 0.000017281\n",
    "dropout = 0.15381\n",
    "layers1 = 2\n",
    "layers2 = 2\n",
    "ln = 1\n",
    "batch_size = 24\n",
    "noise = 1\n",
    "num_heads = 6\n",
    "num_atts = 0\n",
    "\n",
    "model = getModelHuber(neurons0=neurons0,\n",
    "                 neurons1=neurons1,\n",
    "                 neurons2=neurons2,\n",
    "                 layers1=layers1,\n",
    "                 layers2=layers2,\n",
    "                 dropout=dropout,\n",
    "                 lr=lr,\n",
    "                 ln=ln,\n",
    "                 noise=noise,\n",
    "                 num_heads=num_heads,\n",
    "                 num_atts=num_atts)\n",
    "\n",
    "history = model.fit(X/10.0,y,\n",
    "          validation_data=(X_val/10.0,y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          verbose=1,\n",
    "         callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "                        log_dir=\"logs/optuna-huber2-best/\"+str(datetime.now()).replace(' ','_').replace(':','-')+'/',\n",
    "                        histogram_freq=1,\n",
    "                        write_graph=True,\n",
    "                        update_freq=\"epoch\"),\n",
    "\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                                monitor=\"val_mse\",\n",
    "                                patience=50,\n",
    "                                verbose=1,\n",
    "                                mode=\"max\",\n",
    "                                restore_best_weights=True,\n",
    "                            ),                    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_mse\",\n",
    "    factor=0.3,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-10,\n",
    "\n",
    ")])\n",
    "\n",
    "max(history.history['val_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_val/10.0)+0.5).astype(np.uint8)[:,0]\n",
    "# y_pred.shape\n",
    "print(f\"F1 Score : {f1_score(y_val, y_pred, average='weighted')}\")\n",
    "print(f\"Accuracy Score : {accuracy_score(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[:10],y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqVzEIs4P7X1"
   },
   "source": [
    "## Generating the Predictions\n",
    "\n",
    "Generating Predictions from test data to make submission in the puzzle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1643711867290,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "WHNi9e7TP8pz",
    "outputId": "4dc030f1-eb3b-4c34-92f2-87c304e78d5f"
   },
   "outputs": [],
   "source": [
    "submission_embeddings = [literal_eval(embedding)  for embedding in submission['embeddings'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ARGMAX (one hot)\n",
    "predictions = np.argmax(model.predict(np.array(submission_embeddings)/10.0),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(np.array(submission_embeddings)/10.0)+0.5).astype(np.uint8)[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):\n",
    "    if a==0:\n",
    "        return 'negative'\n",
    "    if a==1:\n",
    "        return 'neutral'\n",
    "    if a==2:\n",
    "        return 'positive'\n",
    "\n",
    "result = list(map(convert, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['negative', 'neutral', 'positive'], dtype='<U8'),\n",
       " array([1000,  964, 1037], dtype=int64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1643711867292,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "J4vBe0mAQDJv",
    "outputId": "65e20e41-bfcf-4ab6-bb49-90569b52d2b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.08109518140554428, 0.3090009093284607, 1.36...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.6809610724449158, 1.1909409761428833, 0.892...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.14851869642734528, 0.7872061133384705, 0.89...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.44697386026382446, 0.36429283022880554, 0.7...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.8009324073791504, 0.26081395149230957, 0.40...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[0.9138844609260559, 0.9460961222648621, 0.571...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[0.7667452096939087, 0.7896291613578796, 0.648...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[0.8158280849456787, 2.404792070388794, 0.9924...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[0.4161085784435272, 0.3146701455116272, 1.139...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>[0.7037264108657837, 0.6421875357627869, 1.215...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings     label\n",
       "0     [0.08109518140554428, 0.3090009093284607, 1.36...  positive\n",
       "1     [0.6809610724449158, 1.1909409761428833, 0.892...   neutral\n",
       "2     [0.14851869642734528, 0.7872061133384705, 0.89...   neutral\n",
       "3     [0.44697386026382446, 0.36429283022880554, 0.7...   neutral\n",
       "4     [1.8009324073791504, 0.26081395149230957, 0.40...  negative\n",
       "...                                                 ...       ...\n",
       "2996  [0.9138844609260559, 0.9460961222648621, 0.571...  negative\n",
       "2997  [0.7667452096939087, 0.7896291613578796, 0.648...  negative\n",
       "2998  [0.8158280849456787, 2.404792070388794, 0.9924...   neutral\n",
       "2999  [0.4161085784435272, 0.3146701455116272, 1.139...  positive\n",
       "3000  [0.7037264108657837, 0.6421875357627869, 1.215...  negative\n",
       "\n",
       "[3001 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['label'] = result\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30oDKdd7HV8R"
   },
   "source": [
    "### Saving the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Qv7xSbHQHVPg"
   },
   "outputs": [],
   "source": [
    "# Saving the predictions\n",
    "# !rm -rf assets\n",
    "# !mkdir assets\n",
    "submission.to_csv(os.path.join(\"assets\", \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaFShaKnHH7s"
   },
   "source": [
    "## Submitting our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aicrowd.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login here: https://api.aicrowd.com/auth/GK_bp202k1ZZm_H3yzEIaHUMYINBXXJIb_uoTFE3NI4\n",
      "API Key valid\n",
      "Gitlab access token valid\n",
      "Saved details successfully!\n"
     ]
    }
   ],
   "source": [
    "%aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357,
     "referenced_widgets": [
      "4660207a213e42b799859c22675d2476",
      "45f6d3e90b9f46f29b8cdc49f069bcc5"
     ]
    },
    "executionInfo": {
     "elapsed": 38827,
     "status": "ok",
     "timestamp": 1643713380919,
     "user": {
      "displayName": "Shubham Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhS5-iRa3vVUuZiX_Z7V-1UnZGucABACRmCr-oI5w=s64",
      "userId": "17522365767953126894"
     },
     "user_tz": -330
    },
    "id": "JyrIU1uXHMjb",
    "outputId": "867e512d-72b1-4b5a-a584-4f0d9c9c6f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
      "WARNING: Got more than 1 jupyter server, selecting the latest session\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using notebook: age_cls.ipynb for submission...\n",
      "Removing existing files from submission directory...\n",
      "Scrubbing API keys from the notebook...\n",
      "Collecting notebook...\n",
      "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
      "An unexpected error occured!\n",
      "cannot unpack non-iterable NoneType object\n",
      "To get more information, you can run this command with -v.\n",
      "To increase level of verbosity, you can go upto -vvvvv\n"
     ]
    }
   ],
   "source": [
    "%aicrowd notebook submit -c sentiment-classification -a assets --no-verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "! cd assets/ ; zip submission.zip submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYxDSoFLHy-9"
   },
   "source": [
    "Congratulations to making your first submission in the puzzle ðŸŽ‰  . Let's continue with the journey by improving the baseline & making submission! Don't be shy to ask question related to any errors you are getting or doubts in any part of this notebook in discussion forum or in AIcrowd Discord sever, AIcrew will be happy to help you :)\n",
    "\n",
    "Have a cool new idea that you want to see in the next blitz ? Let us know!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[Baseline] Sentiment Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0aa4ed5fb03448ef84d3a135c16ec784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "170d0d740db442d3905be5531b06a61f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23736fb1fe9941d39e74c528bfb42b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d6465e7dcc14b028433dafa2a19425e",
       "IPY_MODEL_f5ed31c8977c497cbfec64e30da03832",
       "IPY_MODEL_f2c058254a184182afcd4863966fe3b0"
      ],
      "layout": "IPY_MODEL_356bb9aeb3d942789fb47d03ee959004"
     }
    },
    "2827392c9da7413ab6b243fd889f2898": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9ce6366369440cb2a718a99e319ac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_785c99db6c094914b3a68ee18f271e8d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_93b4a902120d4088a6b2af9901271e9e",
      "value": "val.csv: 100%"
     }
    },
    "32cfaa5a941d4d00b3cbfbe11752219f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "356bb9aeb3d942789fb47d03ee959004": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f6d3e90b9f46f29b8cdc49f069bcc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4635077ae52e421e962eb0073daab11a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6970f61c501447fadf6ea6f41fccf97",
       "IPY_MODEL_6e131d04bbcb43568745f77b9841fdd9",
       "IPY_MODEL_5007344417f848afb17cafc21c1318e7"
      ],
      "layout": "IPY_MODEL_2827392c9da7413ab6b243fd889f2898"
     }
    },
    "4660207a213e42b799859c22675d2476": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_45f6d3e90b9f46f29b8cdc49f069bcc5",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">submission.zip</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #800080; text-decoration-color: #800080\">100.0%</span> â€¢ <span style=\"color: #008000; text-decoration-color: #008000\">13.7/13.7 MB</span> â€¢ <span style=\"color: #800000; text-decoration-color: #800000\">577.6 kB/s</span> â€¢ <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
         "text/plain": "\u001b[1;34msubmission.zip\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100.0%\u001b[0m â€¢ \u001b[32m13.7/13.7 MB\u001b[0m â€¢ \u001b[31m577.6 kB/s\u001b[0m â€¢ \u001b[36m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5007344417f848afb17cafc21c1318e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd77e70c4b134b85b2932d58453f5a68",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d311dd0574cb403d9715060713cf75cd",
      "value": " 51.5M/51.5M [00:07&lt;00:00, 7.25MB/s]"
     }
    },
    "6d6465e7dcc14b028433dafa2a19425e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d84b10f328b34c2faed9a043df506299",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bd3b2ca98236429696a87022959d0801",
      "value": "sample_submission.csv: 100%"
     }
    },
    "6e131d04bbcb43568745f77b9841fdd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75ed77729b3742f4bde159b2b98b9668",
      "max": 51491549,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32cfaa5a941d4d00b3cbfbe11752219f",
      "value": 51491549
     }
    },
    "75ed77729b3742f4bde159b2b98b9668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "785c99db6c094914b3a68ee18f271e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f04cb429d2846b7975ee2f755f124d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8547805f4cd64e43808e0872b2fb0bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ad49a922f5d4340840e874bbbfe7b0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bd929029c0f4114a7ef0c8d1fd00617": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93b4a902120d4088a6b2af9901271e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fd78fe2d4e24537939c8b4410d33cd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ad49a922f5d4340840e874bbbfe7b0d",
      "max": 20596780,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8547805f4cd64e43808e0872b2fb0bc6",
      "value": 20596780
     }
    },
    "a6970f61c501447fadf6ea6f41fccf97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_170d0d740db442d3905be5531b06a61f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b507f431b4f34a3bb1b3bb857d999537",
      "value": "train.csv: 100%"
     }
    },
    "acf1c7050df144f09ae546fedb526c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b507f431b4f34a3bb1b3bb857d999537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b83309f18f984170950a161640014ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bd929029c0f4114a7ef0c8d1fd00617",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0aa4ed5fb03448ef84d3a135c16ec784",
      "value": " 20.6M/20.6M [00:02&lt;00:00, 8.56MB/s]"
     }
    },
    "bd3b2ca98236429696a87022959d0801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c19725d50f074ec6bd8ab3cc0ae57e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a9ce6366369440cb2a718a99e319ac3",
       "IPY_MODEL_9fd78fe2d4e24537939c8b4410d33cd4",
       "IPY_MODEL_b83309f18f984170950a161640014ea1"
      ],
      "layout": "IPY_MODEL_acf1c7050df144f09ae546fedb526c56"
     }
    },
    "cac22b36b89f447da218aa89ada9e7dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d311dd0574cb403d9715060713cf75cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d84b10f328b34c2faed9a043df506299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2083b61e874577883492c7afbc846c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd77e70c4b134b85b2932d58453f5a68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c058254a184182afcd4863966fe3b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f04cb429d2846b7975ee2f755f124d3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cac22b36b89f447da218aa89ada9e7dd",
      "value": " 30.9M/30.9M [00:02&lt;00:00, 11.2MB/s]"
     }
    },
    "f2c198b39f67459da417208e66229249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5ed31c8977c497cbfec64e30da03832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd2083b61e874577883492c7afbc846c",
      "max": 30904133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2c198b39f67459da417208e66229249",
      "value": 30904133
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
